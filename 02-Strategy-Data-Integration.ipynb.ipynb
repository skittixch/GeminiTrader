{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f733d654-4703-44f9-bd6d-b6e92dde9912",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Cell 1: Helper Functions (with corrected adjust_quantity_to_step) Defined ---\n"
     ]
    }
   ],
   "source": [
    "# --- Helper Functions (Update adjust_quantity_to_step in Cell 1) ---\n",
    "\n",
    "def format_price_correctly(price, tick_size_str):\n",
    "     \"\"\"Formats price string EXACTLY to the tickSize precision using quantize.\"\"\"\n",
    "     # No changes needed here, assuming the f-string version is already in Cell 1\n",
    "     tick_size = Decimal(tick_size_str)\n",
    "     price_decimal = Decimal(str(price))\n",
    "     # Determine decimal places based on tickSize exponent\n",
    "     decimal_places = abs(tick_size.as_tuple().exponent)\n",
    "     # Create a quantizer for rounding down\n",
    "     # E.g., if tick_size is 0.01, quantizer is 0.01. If 0.00000100, quantizer is 0.000001\n",
    "     quantizer = tick_size # Use tick_size directly as the quantizer unit\n",
    "     # Use ROUND_DOWN as required by Binance for prices/quantities usually\n",
    "     adjusted_price_decimal = price_decimal.quantize(quantizer, rounding=ROUND_DOWN)\n",
    "     # Format to fixed decimal places, avoiding scientific notation\n",
    "     return f\"{adjusted_price_decimal:.{decimal_places}f}\"\n",
    "\n",
    "# --- THIS IS THE CORRECTED FUNCTION ---\n",
    "def adjust_quantity_to_step(quantity, step_size_str):\n",
    "    \"\"\"\n",
    "    Adjusts quantity down to the nearest valid step size and returns a\n",
    "    formatted string suitable for the Binance API, avoiding scientific notation.\n",
    "    \"\"\"\n",
    "    step_size = Decimal(step_size_str)\n",
    "    quantity_decimal = Decimal(str(quantity))\n",
    "\n",
    "    # Calculate adjusted quantity using Decimal floor division\n",
    "    adjusted_quantity_decimal = (quantity_decimal // step_size) * step_size\n",
    "\n",
    "    # Determine the number of decimal places required from step_size_str\n",
    "    # Handles cases like \"1\", \"0.1\", \"0.00001\" correctly\n",
    "    if '.' in step_size_str:\n",
    "        # Count digits after the decimal point\n",
    "        decimal_places = len(step_size_str.split('.')[-1])\n",
    "    else:\n",
    "        # No decimal point, so 0 decimal places\n",
    "        decimal_places = 0\n",
    "\n",
    "    # Format the Decimal result to a string with the correct fixed precision\n",
    "    # Using '.{decimal_places}f' ensures standard decimal notation (not scientific)\n",
    "    formatted_quantity_str = f\"{adjusted_quantity_decimal:.{decimal_places}f}\"\n",
    "\n",
    "    return formatted_quantity_str\n",
    "# --- END OF CORRECTED FUNCTION ---\n",
    "\n",
    "def get_current_balances(api_client):\n",
    "    # Assume this function from Cell 1 is correct\n",
    "    \"\"\"\n",
    "    Fetches account balances from Binance.US and returns non-zero balances\n",
    "    as a Pandas DataFrame.\n",
    "    (Copied from previous notebook)\n",
    "    \"\"\"\n",
    "    if not api_client:\n",
    "        print(\"API Client is not available for get_current_balances.\")\n",
    "        return pd.DataFrame(columns=['Free', 'Locked'], index=pd.Index([], name='Asset'))\n",
    "\n",
    "    try:\n",
    "        account_info = api_client.get_account()\n",
    "        balances_raw = account_info.get('balances', [])\n",
    "\n",
    "        processed_balances = []\n",
    "        for asset_info in balances_raw:\n",
    "            free = float(asset_info['free'])\n",
    "            locked = float(asset_info['locked'])\n",
    "            if free > 0 or locked > 0:\n",
    "                processed_balances.append({\n",
    "                    'Asset': asset_info['asset'],\n",
    "                    'Free': free,\n",
    "                    'Locked': locked\n",
    "                })\n",
    "\n",
    "        if not processed_balances:\n",
    "            print(\"No assets with non-zero balance found.\")\n",
    "            return pd.DataFrame(columns=['Free', 'Locked'], index=pd.Index([], name='Asset'))\n",
    "\n",
    "        balances_df = pd.DataFrame(processed_balances)\n",
    "        balances_df.set_index('Asset', inplace=True)\n",
    "        return balances_df\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching account balances: {e}\")\n",
    "        return pd.DataFrame(columns=['Free', 'Locked'], index=pd.Index([], name='Asset'))\n",
    "\n",
    "def fetch_and_process_klines(api_client, symbol, interval, start_date_str, end_date_str=None):\n",
    "    # Assume this function from Cell 1 is correct\n",
    "    \"\"\"\n",
    "    Fetches historical klines for a symbol/interval/date range, processes\n",
    "    them into a pandas DataFrame, and handles potential API limits.\n",
    "    \"\"\"\n",
    "    if not api_client: print(\"API Client not available for fetch_and_process_klines.\"); return None\n",
    "    print(f\"Fetching klines for {symbol}, interval {interval}, starting {start_date_str}...\")\n",
    "    try:\n",
    "        klines_generator = api_client.get_historical_klines_generator(\n",
    "            symbol, interval, start_date_str, end_str=end_date_str )\n",
    "        all_klines = list(klines_generator)\n",
    "        if not all_klines: print(f\"No kline data found for {symbol}.\"); return pd.DataFrame()\n",
    "        print(f\"Fetched {len(all_klines)} klines.\")\n",
    "        columns = ['Open Time', 'Open', 'High', 'Low', 'Close', 'Volume', 'Close Time',\n",
    "                   'Quote Asset Volume', 'Number of Trades', 'Taker Buy Base Asset Volume',\n",
    "                   'Taker Buy Quote Asset Volume', 'Ignore']\n",
    "        klines_df = pd.DataFrame(all_klines, columns=columns)\n",
    "        klines_df['Open Time'] = pd.to_datetime(klines_df['Open Time'], unit='ms', utc=True)\n",
    "        klines_df['Close Time'] = pd.to_datetime(klines_df['Close Time'], unit='ms', utc=True)\n",
    "        numeric_cols = ['Open', 'High', 'Low', 'Close', 'Volume', 'Quote Asset Volume',\n",
    "                        'Taker Buy Base Asset Volume', 'Taker Buy Quote Asset Volume']\n",
    "        for col in numeric_cols: klines_df[col] = pd.to_numeric(klines_df[col])\n",
    "        klines_df.drop('Ignore', axis=1, inplace=True)\n",
    "        klines_df.set_index('Open Time', inplace=True)\n",
    "        print(f\"Processed klines for {symbol} ({interval}).\")\n",
    "        return klines_df\n",
    "    except Exception as e: print(f\"Error fetching/processing {symbol} ({interval}): {e}\"); return None\n",
    "\n",
    "# --- Also include necessary imports in the corrected Cell 1 ---\n",
    "import pandas as pd\n",
    "import os\n",
    "from binance.client import Client\n",
    "from dotenv import load_dotenv\n",
    "from decimal import Decimal, ROUND_DOWN, getcontext # Make sure getcontext is imported if you use it elsewhere, otherwise optional here\n",
    "import json\n",
    "import math\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "print(\"--- Cell 1: Helper Functions (with corrected adjust_quantity_to_step) Defined ---\")\n",
    "# You would still have the client initialization logic below this in the actual Cell 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "705d5500-0eb1-4784-a492-085b9a054df4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fetching Comprehensive Portfolio State ---\n",
      "Fetching account balances...\n",
      "✅ Balances fetched successfully.\n",
      "Fetching open orders...\n",
      "Fetched 5 open order(s).\n",
      "✅ Open orders fetched and processed successfully.\n",
      "\n",
      "--- Portfolio State Summary ---\n",
      "Balances (Free/Locked):\n",
      "             Free       Locked\n",
      "Asset                         \n",
      "BTC    0.00000710   0.00008000\n",
      "USDT   0.10189178  26.60000000\n",
      "BUSD   0.14956400   0.00000000\n",
      "WAVES  0.01000000   0.00000000\n",
      "\n",
      "Open Orders:\n",
      "    symbol     orderId  side         type status           price     origQty  \\\n",
      "0  BTCUSDT  1466046736  SELL  LIMIT_MAKER    NEW  91000.00000000  0.00004000   \n",
      "1  BTCUSDT  1466046691  SELL  LIMIT_MAKER    NEW  87000.00000000  0.00004000   \n",
      "2  BTCUSDT  1466045855   BUY  LIMIT_MAKER    NEW  50000.00000000  0.00018000   \n",
      "3  BTCUSDT  1466045747   BUY  LIMIT_MAKER    NEW  64000.00000000  0.00014000   \n",
      "4  BTCUSDT  1466045383   BUY  LIMIT_MAKER    NEW  72000.00000000  0.00012000   \n",
      "\n",
      "  executedQty                             time  \n",
      "0  0.00000000 2025-04-08 14:56:09.811000+00:00  \n",
      "1  0.00000000 2025-04-08 14:55:57.421000+00:00  \n",
      "2  0.00000000 2025-04-08 14:54:36.094000+00:00  \n",
      "3  0.00000000 2025-04-08 14:54:24.970000+00:00  \n",
      "4  0.00000000 2025-04-08 14:53:47.150000+00:00  \n",
      "\n",
      "✅ State captured in 'portfolio_state' dictionary (with original Decimal types).\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Get Comprehensive Portfolio State (Balances & Open Orders) - CORRECTED DISPLAY v2\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "from binance.client import Client\n",
    "from dotenv import load_dotenv\n",
    "from decimal import Decimal, ROUND_DOWN # Use Decimal for precision\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "\n",
    "# Suppress specific Pandas warnings if desired, use cautiously\n",
    "# warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# --- Configuration ---\n",
    "QUOTE_ASSET = 'USDT' # Define your quote asset\n",
    "DISPLAY_PRECISION = 8 # How many decimal places to show\n",
    "\n",
    "# --- Check Prerequisites ---\n",
    "if 'client' not in locals() or client is None:\n",
    "    raise RuntimeError(\"Binance client is not initialized. Please run Cell 1 first.\")\n",
    "if 'get_current_balances_detailed' not in locals() or 'get_open_orders_detailed' not in locals():\n",
    "     # Define functions locally if Cell 1 wasn't run (not ideal but for completeness)\n",
    "    print(\"⚠️ Defining state-fetching functions locally. Run Cell 1 for canonical versions.\")\n",
    "    def get_current_balances_detailed(api_client):\n",
    "        if not api_client: return pd.DataFrame(columns=['Free', 'Locked'], index=pd.Index([], name='Asset'), dtype=object)\n",
    "        try:\n",
    "            account_info = api_client.get_account(); balances_raw = account_info.get('balances', [])\n",
    "            processed = [{'Asset':i['asset'],'Free':Decimal(i['free']),'Locked':Decimal(i['locked'])} for i in balances_raw if Decimal(i['free'])>0 or Decimal(i['locked'])>0]\n",
    "            if not processed: return pd.DataFrame(columns=['Free', 'Locked'], index=pd.Index([], name='Asset'), dtype=object)\n",
    "            df = pd.DataFrame(processed); df.set_index('Asset', inplace=True); return df\n",
    "        except Exception as e: print(f\"❌ Error balances: {e}\"); return pd.DataFrame(columns=['Free', 'Locked'], index=pd.Index([], name='Asset'), dtype=object)\n",
    "    def get_open_orders_detailed(api_client):\n",
    "        if not api_client: return pd.DataFrame()\n",
    "        try:\n",
    "            orders = api_client.get_open_orders()\n",
    "            if not orders: return pd.DataFrame()\n",
    "            df = pd.DataFrame(orders)\n",
    "            for col in ['price','origQty','executedQty','cummulativeQuoteQty','stopPrice']:\n",
    "                if col in df.columns: df[col] = df[col].apply(lambda x: Decimal(str(x)) if x is not None else Decimal('0'))\n",
    "            for col in ['time','updateTime']:\n",
    "                if col in df.columns: df[col] = pd.to_datetime(df[col], unit='ms', utc=True, errors='coerce')\n",
    "            return df.sort_values(by=['symbol', 'time'], ascending=[True, False]).reset_index(drop=True)\n",
    "        except Exception as e: print(f\"❌ Error orders: {e}\"); return pd.DataFrame()\n",
    "\n",
    "# --- Main Execution Logic ---\n",
    "print(\"--- Fetching Comprehensive Portfolio State ---\")\n",
    "portfolio_state = {\n",
    "    \"balances\": pd.DataFrame(columns=['Free', 'Locked'], index=pd.Index([], name='Asset'), dtype=object),\n",
    "    \"open_orders\": pd.DataFrame()\n",
    "}\n",
    "\n",
    "portfolio_state[\"balances\"] = get_current_balances_detailed(client)\n",
    "portfolio_state[\"open_orders\"] = get_open_orders_detailed(client)\n",
    "\n",
    "print(\"\\n--- Portfolio State Summary ---\")\n",
    "\n",
    "# --- Format Balances DataFrame for Display ---\n",
    "if not portfolio_state[\"balances\"].empty:\n",
    "    print(\"Balances (Free/Locked):\")\n",
    "    # Create a copy for display formatting\n",
    "    balances_display_df = portfolio_state[\"balances\"].copy()\n",
    "    # Apply string formatting to Decimal columns\n",
    "    formatter = f'{{:.{DISPLAY_PRECISION}f}}' # e.g., '{:.8f}'\n",
    "    balances_display_df['Free'] = balances_display_df['Free'].apply(lambda x: formatter.format(x) if isinstance(x, Decimal) else x)\n",
    "    balances_display_df['Locked'] = balances_display_df['Locked'].apply(lambda x: formatter.format(x) if isinstance(x, Decimal) else x)\n",
    "    print(balances_display_df)\n",
    "else:\n",
    "    print(\"Balances: None found or error.\")\n",
    "\n",
    "# --- Format Open Orders DataFrame for Display ---\n",
    "if not portfolio_state[\"open_orders\"].empty:\n",
    "    print(\"\\nOpen Orders:\")\n",
    "    # Create a copy for display formatting\n",
    "    orders_display_df = portfolio_state[\"open_orders\"].copy()\n",
    "    cols_to_format = ['price', 'origQty', 'executedQty']\n",
    "    cols_to_display = ['symbol','orderId','side','type','status','price','origQty','executedQty','time']\n",
    "    cols_to_display = [c for c in cols_to_display if c in orders_display_df.columns]\n",
    "    formatter = f'{{:.{DISPLAY_PRECISION}f}}'\n",
    "\n",
    "    for col in cols_to_format:\n",
    "        if col in orders_display_df.columns:\n",
    "             orders_display_df[col] = orders_display_df[col].apply(lambda x: formatter.format(x) if isinstance(x, Decimal) else x)\n",
    "\n",
    "    # Print the formatted copy\n",
    "    print(orders_display_df[cols_to_display])\n",
    "else:\n",
    "    print(\"Open Orders: None found.\")\n",
    "\n",
    "print(\"\\n✅ State captured in 'portfolio_state' dictionary (with original Decimal types).\")\n",
    "# Note: portfolio_state['balances'] and portfolio_state['open_orders'] still contain the precise Decimal objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "84c505a1-9d29-4166-9435-d31938114bed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Identifying Top 10 Assets by 24hr USDT Volume ---\n",
      "Processing 188 USDT pairs...\n",
      "Top 10 Assets (by USDT Volume): ['XRP', 'ETH', 'BTC', 'SOL', 'ADA', 'HBAR', 'DOGE', 'LTC', 'SUI', 'BNB']\n",
      "✅ Top 10 symbols identified: ['XRPUSDT', 'ETHUSDT', 'BTCUSDT', 'SOLUSDT', 'ADAUSDT', 'HBARUSDT', 'DOGEUSDT', 'LTCUSDT', 'SUIUSDT', 'BNBUSDT']\n",
      "   Volume ranking data stored in 'volume_ranking_df'.\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Identify Top N Assets by Volume\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "from decimal import Decimal # Use Decimal for price/volume if needed later\n",
    "\n",
    "# --- Configuration ---\n",
    "N = 10 # Number of top crypto assets to target\n",
    "QUOTE_ASSET_FILTER = 'USDT' # Should match QUOTE_ASSET usually\n",
    "STABLECOIN_ASSETS = ['USDT', 'USDC', 'BUSD', 'TUSD', 'USDP', 'FDUSD'] # Define stablecoins to exclude\n",
    "\n",
    "# --- Check Prerequisites ---\n",
    "if 'client' not in locals() or client is None:\n",
    "    raise RuntimeError(\"Binance client is not initialized. Please run Cell 1 first.\")\n",
    "\n",
    "# --- Initialize ---\n",
    "top_n_assets = []\n",
    "top_n_symbols = []\n",
    "volume_ranking_df = pd.DataFrame() # Will store detailed volume info\n",
    "\n",
    "# --- Main Logic ---\n",
    "print(f\"\\n--- Identifying Top {N} Assets by 24hr {QUOTE_ASSET_FILTER} Volume ---\")\n",
    "try:\n",
    "    all_tickers = client.get_ticker() # Fetch all symbol tickers\n",
    "    # Filter for pairs ending with the quote asset (e.g., 'USDT')\n",
    "    usdt_tickers = [t for t in all_tickers if t.get('symbol', '').endswith(QUOTE_ASSET_FILTER)]\n",
    "    print(f\"Processing {len(usdt_tickers)} {QUOTE_ASSET_FILTER} pairs...\")\n",
    "\n",
    "    volume_data = []\n",
    "    for ticker in usdt_tickers:\n",
    "        symbol = ticker.get('symbol')\n",
    "        if not symbol: continue # Skip if symbol key is missing\n",
    "\n",
    "        # Derive base asset (e.g., 'BTC' from 'BTCUSDT')\n",
    "        base_asset = symbol[:-len(QUOTE_ASSET_FILTER)] # More robust than replace\n",
    "\n",
    "        # Skip if the base asset is a known stablecoin\n",
    "        if base_asset in STABLECOIN_ASSETS: continue\n",
    "\n",
    "        try:\n",
    "             # Extract quote volume and last price, convert safely\n",
    "             volume_str = ticker.get('quoteVolume', '0.0')\n",
    "             price_str = ticker.get('lastPrice', '0.0')\n",
    "             volume = Decimal(volume_str)\n",
    "             last_price = Decimal(price_str)\n",
    "\n",
    "             # Only include assets with positive volume and price\n",
    "             if volume > 0 and last_price > 0:\n",
    "                  volume_data.append({\n",
    "                      'Asset': base_asset,\n",
    "                      'Symbol': symbol,\n",
    "                      f'Volume_{QUOTE_ASSET_FILTER}': volume, # Store as Decimal\n",
    "                      'LastPrice': last_price # Store as Decimal\n",
    "                  })\n",
    "        except Exception as e:\n",
    "             # Log ticker processing errors if needed, otherwise skip problematic tickers\n",
    "             # print(f\"  Warning: Skipping {symbol} due to data error: {e}\")\n",
    "             pass # Continue to the next ticker\n",
    "\n",
    "    if not volume_data:\n",
    "         print(\"⚠️ Warning: No valid volume data found after filtering.\")\n",
    "    else:\n",
    "         # Create DataFrame from collected data\n",
    "         volume_ranking_df = pd.DataFrame(volume_data)\n",
    "         # Sort by volume (descending)\n",
    "         volume_ranking_df.sort_values(by=f'Volume_{QUOTE_ASSET_FILTER}', ascending=False, inplace=True)\n",
    "         # Select the top N rows\n",
    "         top_n_df = volume_ranking_df.head(N)\n",
    "         # Extract asset names and symbols\n",
    "         top_n_assets = top_n_df['Asset'].tolist()\n",
    "         top_n_symbols = top_n_df['Symbol'].tolist()\n",
    "         print(f\"Top {N} Assets (by USDT Volume): {top_n_assets}\")\n",
    "         # Uncomment below to see the volume details of the top N\n",
    "         # with pd.option_context('display.float_format', '{:,.2f}'.format): # Format volume nicely\n",
    "         #    print(top_n_df[['Asset', 'Symbol', f'Volume_{QUOTE_ASSET_FILTER}']])\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"❌ An error occurred fetching/processing ticker data: {e}\")\n",
    "    # Reset variables to ensure clean state on error\n",
    "    top_n_assets, top_n_symbols, volume_ranking_df = [], [], pd.DataFrame()\n",
    "\n",
    "# --- Final Check ---\n",
    "if not top_n_symbols:\n",
    "    print(\"⚠️ Top N symbols list is empty. Subsequent steps might fail.\")\n",
    "    # Consider raising an error if this is critical\n",
    "    # raise ValueError(\"Failed to identify Top N symbols.\")\n",
    "else:\n",
    "    print(f\"✅ Top {len(top_n_symbols)} symbols identified: {top_n_symbols}\")\n",
    "    print(f\"   Volume ranking data stored in 'volume_ranking_df'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "262ddde0-1103-442a-a1db-446155102323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing Kline Data for Top 10 Symbols ---\n",
      "Intervals: ['1d', '1h', '5m', '1m']. Will LOAD local first.\n",
      "✅ Kline data processing complete. Data stored in 'top_n_klines' dictionary.\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Fetch/Load Historical Data for Top N Symbols - CORRECTED Timezone Handling\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "from binance.client import Client # For interval constants\n",
    "from datetime import datetime, timezone # Import timezone specifically\n",
    "\n",
    "# --- Configuration ---\n",
    "INTERVALS_TO_PROCESS = ['1d', '1h', '5m', '1m'] # Timeframes needed for analysis\n",
    "INTERVAL_API_MAP = {\n",
    "    '1d': Client.KLINE_INTERVAL_1DAY, '1h': Client.KLINE_INTERVAL_1HOUR,\n",
    "    '5m': Client.KLINE_INTERVAL_5MINUTE, '1m': Client.KLINE_INTERVAL_1MINUTE\n",
    "}\n",
    "START_DATES_FETCH = {\n",
    "    '1d': \"90 days ago UTC\", '1h': \"7 days ago UTC\",\n",
    "    '5m': \"3 days ago UTC\", '1m': \"1 day ago UTC\"\n",
    "}\n",
    "START_DATES_SAVE_IDS = {\n",
    "    '1d': \"90_days_ago_UTC\", '1h': \"7_days_ago_UTC\",\n",
    "    '5m': \"3_days_ago_UTC\", '1m': \"1_day_ago_UTC\"\n",
    "}\n",
    "DATA_DIRECTORY = \"data\"\n",
    "FORCE_FETCH_FRESH = False\n",
    "\n",
    "# --- Check Prerequisites ---\n",
    "if 'client' not in locals() or client is None:\n",
    "    raise RuntimeError(\"Binance client not initialized. Run Cell 1.\")\n",
    "if 'fetch_and_process_klines' not in locals():\n",
    "     raise RuntimeError(\"Helper function 'fetch_and_process_klines' not defined. Run Cell 1.\")\n",
    "if 'top_n_symbols' not in locals() or not top_n_symbols:\n",
    "    raise ValueError(\"'top_n_symbols' list not found or empty. Run Cell 3.\")\n",
    "\n",
    "# --- Initialization ---\n",
    "top_n_klines = {}\n",
    "os.makedirs(DATA_DIRECTORY, exist_ok=True)\n",
    "fetch_errors = 0\n",
    "load_errors = 0\n",
    "save_errors = 0\n",
    "\n",
    "print(f\"\\n--- Processing Kline Data for Top {len(top_n_symbols)} Symbols ---\")\n",
    "print(f\"Intervals: {INTERVALS_TO_PROCESS}. Will {'FETCH FRESH' if FORCE_FETCH_FRESH else 'LOAD local first'}.\")\n",
    "\n",
    "for symbol in top_n_symbols:\n",
    "    top_n_klines[symbol] = {}\n",
    "    symbol_fetch_errors = 0\n",
    "\n",
    "    for interval_key in INTERVALS_TO_PROCESS:\n",
    "        interval_value = INTERVAL_API_MAP.get(interval_key)\n",
    "        if not interval_value: continue\n",
    "\n",
    "        df = None\n",
    "        loaded_from_csv = False\n",
    "        source_msg = \"\"\n",
    "\n",
    "        # --- 1. Attempt to Load from CSV ---\n",
    "        if not FORCE_FETCH_FRESH:\n",
    "            start_id = START_DATES_SAVE_IDS.get(interval_key)\n",
    "            if start_id:\n",
    "                filename = os.path.join(DATA_DIRECTORY, f\"{symbol}_{interval_key}_{start_id}.csv\")\n",
    "                if os.path.exists(filename):\n",
    "                    try:\n",
    "                        # Read CSV, set index, parse dates\n",
    "                        df = pd.read_csv(filename, index_col='Open Time', parse_dates=True)\n",
    "\n",
    "                        # --- CORRECTED Timezone Handling ---\n",
    "                        if df.index.tz is None:\n",
    "                            # If no timezone info, assume UTC and localize\n",
    "                            df.index = df.index.tz_localize('UTC')\n",
    "                            # print(f\"  Localized {filename} to UTC.\") # Optional debug log\n",
    "                        # Check if the existing timezone is NOT equivalent to UTC\n",
    "                        # This handles both pytz objects and datetime.timezone objects robustly\n",
    "                        elif df.index.tz != timezone.utc:\n",
    "                             print(f\"  Warning: Timezone for {filename} is {df.index.tz}, attempting conversion to UTC.\")\n",
    "                             try:\n",
    "                                 # Attempt to convert to UTC if it's something else\n",
    "                                 df.index = df.index.tz_convert('UTC')\n",
    "                             except Exception as tz_convert_err:\n",
    "                                 # Log error if conversion fails unexpectedly\n",
    "                                 print(f\"  ⚠️ Error converting timezone for {filename}: {tz_convert_err}. Skipping file.\")\n",
    "                                 load_errors += 1\n",
    "                                 df = None # Set df to None to trigger fetch\n",
    "                        # --- End CORRECTED Timezone Handling ---\n",
    "\n",
    "                        # If df is still valid after timezone check/conversion\n",
    "                        if df is not None:\n",
    "                             loaded_from_csv = True\n",
    "                             source_msg = f\"Loaded {symbol} {interval_key} from CSV.\"\n",
    "\n",
    "                    except Exception as e:\n",
    "                        # Catch other potential loading errors (parsing issues etc.)\n",
    "                        print(f\"  ⚠️ Error loading {filename}: {e}. Will try fetching.\")\n",
    "                        load_errors += 1\n",
    "                        df = None # Ensure df is None if loading fails\n",
    "\n",
    "        # --- 2. Fetch Fresh if Not Loaded or if Forcing ---\n",
    "        if df is None: # Fetch if df is None (due to not existing, load error, or FORCE_FETCH_FRESH)\n",
    "            start_str = START_DATES_FETCH.get(interval_key, \"7 days ago UTC\")\n",
    "            print(f\"  Fetching {symbol} {interval_key} data starting {start_str}...\")\n",
    "            df = fetch_and_process_klines(client, symbol, interval_value, start_str)\n",
    "            source_msg = f\"Fetched {symbol} {interval_key} from API.\"\n",
    "\n",
    "            # --- 3. Optionally Save Freshly Fetched Data ---\n",
    "            if df is not None and not df.empty:\n",
    "                 save_id = START_DATES_SAVE_IDS.get(interval_key)\n",
    "                 if save_id:\n",
    "                      save_filename = os.path.join(DATA_DIRECTORY, f\"{symbol}_{interval_key}_{save_id}.csv\")\n",
    "                      try:\n",
    "                           df.to_csv(save_filename)\n",
    "                           source_msg += \" Saved to CSV.\"\n",
    "                      except Exception as e:\n",
    "                           print(f\"  ⚠️ Error SAVING {save_filename}: {e}\")\n",
    "                           save_errors += 1\n",
    "                 else:\n",
    "                      print(f\"  ⚠️ Cannot determine save filename for {interval_key}. Data not saved.\")\n",
    "            elif df is None: # Error during fetch/process\n",
    "                 symbol_fetch_errors += 1\n",
    "                 source_msg += \" Fetch/Process FAILED.\"\n",
    "\n",
    "        # --- 4. Store the final DataFrame ---\n",
    "        if df is not None and not df.empty:\n",
    "             top_n_klines[symbol][interval_key] = df\n",
    "        elif not loaded_from_csv: # Only flag error if fetch failed\n",
    "             print(f\"  ⚠️ No data obtained or processed for {symbol} {interval_key}.\")\n",
    "\n",
    "    # --- End of interval loop ---\n",
    "    if symbol_fetch_errors > 0:\n",
    "        fetch_errors += symbol_fetch_errors\n",
    "\n",
    "# --- End of symbol loop ---\n",
    "\n",
    "# --- Final Summary ---\n",
    "if load_errors > 0: print(f\"⚠️ Encountered {load_errors} error(s) loading existing CSV data.\")\n",
    "if fetch_errors > 0: print(f\"⚠️ Encountered {fetch_errors} error(s) fetching/processing fresh data.\")\n",
    "if save_errors > 0: print(f\"⚠️ Encountered {save_errors} error(s) saving fetched data.\")\n",
    "\n",
    "missing_data_symbols = []\n",
    "for symbol, intervals in top_n_klines.items():\n",
    "     loaded_intervals = list(intervals.keys())\n",
    "     if len(loaded_intervals) < len(INTERVALS_TO_PROCESS):\n",
    "          missing = set(INTERVALS_TO_PROCESS) - set(loaded_intervals)\n",
    "          missing_data_symbols.append(f\"{symbol} (missing: {', '.join(missing)})\")\n",
    "if missing_data_symbols:\n",
    "     print(f\"⚠️ Symbols potentially missing required interval data: {'; '.join(missing_data_symbols)}\")\n",
    "\n",
    "print(f\"✅ Kline data processing complete. Data stored in 'top_n_klines' dictionary.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "216724cb-aca0-46dd-9967-c77f9f977ffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Calculating Technical Indicators ---\n",
      "✅ Indicator calculation complete for all symbols and intervals.\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Calculate Technical Indicators for Top N Symbols\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np # Needed for manual calculations\n",
    "\n",
    "# --- Configuration ---\n",
    "SMA_PERIODS = [20, 50]      # Periods for Simple Moving Averages\n",
    "RSI_PERIOD = 14             # Period for Relative Strength Index\n",
    "MACD_FAST = 12              # Fast EMA period for MACD\n",
    "MACD_SLOW = 26              # Slow EMA period for MACD\n",
    "MACD_SIGNAL = 9             # Signal Line EMA period for MACD\n",
    "\n",
    "# --- Check Prerequisites ---\n",
    "if 'top_n_klines' not in locals() or not top_n_klines:\n",
    "    raise ValueError(\"'top_n_klines' dictionary not found or empty. Run Cell 4 first.\")\n",
    "\n",
    "print(\"\\n--- Calculating Technical Indicators ---\")\n",
    "calculation_errors = 0\n",
    "\n",
    "# Loop through each symbol in the main dictionary\n",
    "for symbol, interval_dict in top_n_klines.items():\n",
    "    symbol_errors = 0\n",
    "    # Loop through each interval ('1d', '1h', etc.) for the current symbol\n",
    "    for interval, df in interval_dict.items():\n",
    "        # Ensure DataFrame is not empty and has the 'Close' column needed\n",
    "        if df.empty or 'Close' not in df.columns:\n",
    "            # Silently skip empty DFs or those missing essential data\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            # --- Calculate SMAs ---\n",
    "            for period in SMA_PERIODS:\n",
    "                # Ensure enough data points for the rolling window\n",
    "                if len(df) >= period:\n",
    "                    # Use min_periods=period to avoid partial calculations at the start\n",
    "                    df[f'SMA_{period}'] = df['Close'].rolling(window=period, min_periods=period).mean()\n",
    "                else:\n",
    "                    df[f'SMA_{period}'] = np.nan # Assign NaN if not enough data\n",
    "\n",
    "            # --- Calculate RSI ---\n",
    "            if len(df) >= RSI_PERIOD + 1: # Need at least period+1 for diff()\n",
    "                delta = df['Close'].diff()\n",
    "                gain = delta.where(delta > 0, 0.0)\n",
    "                loss = -delta.where(delta < 0, 0.0)\n",
    "                # Use Exponential Moving Average for RSI smoothing\n",
    "                avg_gain = gain.ewm(com=RSI_PERIOD - 1, min_periods=RSI_PERIOD).mean()\n",
    "                avg_loss = loss.ewm(com=RSI_PERIOD - 1, min_periods=RSI_PERIOD).mean()\n",
    "\n",
    "                # Calculate Relative Strength (RS) - handle division by zero\n",
    "                rs = np.where(avg_loss == 0, np.inf, avg_gain / avg_loss) # Avoid division by zero warning\n",
    "\n",
    "                # Calculate RSI\n",
    "                rsi = 100.0 - (100.0 / (1.0 + rs))\n",
    "                rsi[rs == np.inf] = 100.0 # Set RSI to 100 where avg_loss was 0 (infinite RS)\n",
    "\n",
    "                # If avg_gain and avg_loss are both 0 (e.g., flat price), RSI is undefined (NaN).\n",
    "                # Fill initial NaNs, potentially assigning a neutral 50.\n",
    "                rsi = pd.Series(rsi, index=df.index).fillna(50.0)\n",
    "\n",
    "                df[f'RSI_{RSI_PERIOD}'] = rsi\n",
    "            else:\n",
    "                df[f'RSI_{RSI_PERIOD}'] = np.nan # Assign NaN if not enough data\n",
    "\n",
    "\n",
    "            # --- Calculate MACD ---\n",
    "            # Need enough data for slow EMA calculation\n",
    "            if len(df) >= MACD_SLOW:\n",
    "                ema_fast = df['Close'].ewm(span=MACD_FAST, adjust=False).mean()\n",
    "                ema_slow = df['Close'].ewm(span=MACD_SLOW, adjust=False).mean()\n",
    "                macd_line = ema_fast - ema_slow\n",
    "                # Need enough data points for signal line calculation on macd_line\n",
    "                if len(macd_line.dropna()) >= MACD_SIGNAL:\n",
    "                     signal_line = macd_line.ewm(span=MACD_SIGNAL, adjust=False).mean()\n",
    "                     histogram = macd_line - signal_line\n",
    "                else:\n",
    "                     signal_line = np.nan\n",
    "                     histogram = np.nan\n",
    "\n",
    "                df[f'MACD_{MACD_FAST}_{MACD_SLOW}_{MACD_SIGNAL}'] = macd_line\n",
    "                df[f'MACDs_{MACD_FAST}_{MACD_SLOW}_{MACD_SIGNAL}'] = signal_line\n",
    "                df[f'MACDh_{MACD_FAST}_{MACD_SLOW}_{MACD_SIGNAL}'] = histogram\n",
    "            else:\n",
    "                 # Assign NaN if not enough data for MACD calculation\n",
    "                 df[f'MACD_{MACD_FAST}_{MACD_SLOW}_{MACD_SIGNAL}'] = np.nan\n",
    "                 df[f'MACDs_{MACD_FAST}_{MACD_SLOW}_{MACD_SIGNAL}'] = np.nan\n",
    "                 df[f'MACDh_{MACD_FAST}_{MACD_SLOW}_{MACD_SIGNAL}'] = np.nan\n",
    "\n",
    "\n",
    "            # DataFrames are modified in-place within the dictionary\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"  ❌ Error calculating indicators for {symbol} {interval}: {e}\")\n",
    "            symbol_errors += 1\n",
    "            # Attempt to remove potentially partially added columns to avoid downstream errors\n",
    "            potential_new_cols = [f'SMA_{p}' for p in SMA_PERIODS] + \\\n",
    "                                 [f'RSI_{RSI_PERIOD}', f'MACD_{MACD_FAST}_{MACD_SLOW}_{MACD_SIGNAL}', \\\n",
    "                                  f'MACDs_{MACD_FAST}_{MACD_SLOW}_{MACD_SIGNAL}', f'MACDh_{MACD_FAST}_{MACD_SLOW}_{MACD_SIGNAL}']\n",
    "            for col in potential_new_cols:\n",
    "                 if col in df.columns:\n",
    "                      try: df.drop(columns=[col], inplace=True)\n",
    "                      except Exception: pass # Ignore errors during cleanup\n",
    "\n",
    "\n",
    "    if symbol_errors > 0:\n",
    "        calculation_errors += symbol_errors\n",
    "\n",
    "if calculation_errors > 0:\n",
    "     print(f\"⚠️ Indicator calculation completed with {calculation_errors} total errors.\")\n",
    "\n",
    "# --- Optional: Display sample data to verify ---\n",
    "# symbol_to_show = top_n_symbols[0] if top_n_symbols else None\n",
    "# interval_to_show = '1h'\n",
    "# if symbol_to_show and interval_to_show in top_n_klines.get(symbol_to_show, {}):\n",
    "#     print(f\"\\n--- Sample {symbol_to_show} {interval_to_show} Data with Indicators (Last 5 Rows) ---\")\n",
    "#     df_sample = top_n_klines[symbol_to_show][interval_to_show]\n",
    "#     cols = ['Close', f'SMA_{SMA_PERIODS[0]}', f'SMA_{SMA_PERIODS[1]}',\n",
    "#             f'RSI_{RSI_PERIOD}', f'MACD_{MACD_FAST}_{MACD_SLOW}_{MACD_SIGNAL}']\n",
    "#     cols = [c for c in cols if c in df_sample.columns] # Only include columns that exist\n",
    "#     with pd.option_context('display.float_format', '{:.4f}'.format): # Format display\n",
    "#         print(df_sample[cols].tail())\n",
    "\n",
    "print(\"✅ Indicator calculation complete for all symbols and intervals.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a7a100e5-9b3c-4d33-8c0c-104464823174",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Calculating Dynamic Target Allocations ---\n",
      "Total 24hr Volume for Top 10 crypto assets: 5,053,850.07 USDT\n",
      "Target Allocations Sum: 100.00%\n",
      "✅ Dynamic target allocations calculated ('dynamic_target_allocations_pct').\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Calculate Dynamic Target Allocations\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from decimal import Decimal # Use Decimal if dealing with volume/prices from DF\n",
    "\n",
    "# --- Configuration ---\n",
    "# Ensure N matches the number of assets selected in Cell 3\n",
    "TOP_N_ASSETS_COUNT = 10\n",
    "STABLECOIN_RESERVE_PCT = Decimal('20.0') # Target reserve percentage as Decimal\n",
    "STABLECOIN_ASSETS = ['USDT', 'USDC', 'BUSD', 'TUSD', 'USDP', 'FDUSD']\n",
    "# Primary quote/stablecoin, should match filter used in Cell 3\n",
    "QUOTE_ASSET = 'USDT'\n",
    "\n",
    "# --- Check Prerequisites ---\n",
    "if 'volume_ranking_df' not in locals() or volume_ranking_df.empty:\n",
    "    # Attempt to regenerate volume_ranking_df if it's missing (e.g., error in Cell 3)\n",
    "    print(\"⚠️ 'volume_ranking_df' missing, attempting regeneration from tickers...\")\n",
    "    try:\n",
    "        # Minimal regeneration logic (assumes client exists from Cell 1)\n",
    "        if 'client' not in locals() or client is None: raise RuntimeError(\"Client missing for regen\")\n",
    "        all_tickers = client.get_ticker()\n",
    "        usdt_tickers = [t for t in all_tickers if t.get('symbol', '').endswith(QUOTE_ASSET)]\n",
    "        volume_data = []\n",
    "        for ticker in usdt_tickers:\n",
    "            symbol=ticker.get('symbol'); base=symbol[:-len(QUOTE_ASSET)]; vol_str=ticker.get('quoteVolume','0'); price_str=ticker.get('lastPrice','0')\n",
    "            if base not in STABLECOIN_ASSETS:\n",
    "                try: # Convert safely\n",
    "                    vol=Decimal(vol_str); price=Decimal(price_str)\n",
    "                    if vol > 0 and price > 0: volume_data.append({'Asset':base,'Symbol':symbol,f'Volume_{QUOTE_ASSET}':vol})\n",
    "                except Exception: pass # Skip invalid tickers\n",
    "        if volume_data:\n",
    "            volume_ranking_df = pd.DataFrame(volume_data)\n",
    "            volume_ranking_df.sort_values(f'Volume_{QUOTE_ASSET}',ascending=False,inplace=True)\n",
    "        else:\n",
    "            volume_ranking_df = pd.DataFrame() # Ensure empty if still no data\n",
    "\n",
    "        if volume_ranking_df.empty: raise ValueError(\"Could not regenerate volume data.\")\n",
    "        print(\"✅ Volume ranking regenerated.\")\n",
    "    except Exception as e:\n",
    "        # If regeneration fails, targets cannot be calculated dynamically\n",
    "        raise ValueError(f\"Volume data unavailable and regeneration failed: {e}. Cannot calculate targets. Check Cell 3.\")\n",
    "\n",
    "if f'Volume_{QUOTE_ASSET}' not in volume_ranking_df.columns:\n",
    "     raise KeyError(f\"Required volume column 'Volume_{QUOTE_ASSET}' not found in volume_ranking_df. Check Cell 3.\")\n",
    "\n",
    "\n",
    "# --- Initialize ---\n",
    "# Stores target allocation percentages as Decimals\n",
    "dynamic_target_allocations_pct = {}\n",
    "\n",
    "print(\"\\n--- Calculating Dynamic Target Allocations ---\")\n",
    "try:\n",
    "    # Filter out stablecoins again just in case, and get top N\n",
    "    crypto_volume_df = volume_ranking_df[~volume_ranking_df['Asset'].isin(STABLECOIN_ASSETS)].copy()\n",
    "    top_n_crypto_df = crypto_volume_df.head(TOP_N_ASSETS_COUNT)\n",
    "\n",
    "    # Calculate total volume of the Top N crypto assets (ensure Decimal)\n",
    "    total_top_n_volume = top_n_crypto_df[f'Volume_{QUOTE_ASSET}'].sum()\n",
    "    if not isinstance(total_top_n_volume, Decimal):\n",
    "         total_top_n_volume = Decimal(str(total_top_n_volume)) # Convert if needed\n",
    "\n",
    "    if total_top_n_volume <= 0:\n",
    "        print(\"⚠️ Warning: Total volume for Top N crypto assets is zero or negative. Assigning 0% target weights to crypto.\")\n",
    "        total_top_n_volume = Decimal('0') # Prevent division by zero\n",
    "    else:\n",
    "         print(f\"Total 24hr Volume for Top {TOP_N_ASSETS_COUNT} crypto assets: {total_top_n_volume:,.2f} {QUOTE_ASSET}\")\n",
    "\n",
    "    # --- Calculate Dynamic Crypto Allocations ---\n",
    "    # Percentage available for non-stablecoins\n",
    "    crypto_allocation_pct = Decimal('100.0') - STABLECOIN_RESERVE_PCT\n",
    "\n",
    "    if total_top_n_volume > 0:\n",
    "        # Calculate weight based on volume contribution to the Top N total\n",
    "        for index, row in top_n_crypto_df.iterrows():\n",
    "            asset = row['Asset']\n",
    "            # Ensure volume is Decimal\n",
    "            volume = row[f'Volume_{QUOTE_ASSET}']\n",
    "            if not isinstance(volume, Decimal): volume = Decimal(str(volume))\n",
    "\n",
    "            # Calculate target percentage for this asset\n",
    "            target_pct = (volume / total_top_n_volume) * crypto_allocation_pct\n",
    "            dynamic_target_allocations_pct[asset] = target_pct\n",
    "    else:\n",
    "         # If total volume is zero, assign 0% target to all Top N crypto assets\n",
    "         for asset in top_n_crypto_df['Asset'].tolist():\n",
    "              dynamic_target_allocations_pct[asset] = Decimal('0.0')\n",
    "\n",
    "\n",
    "    # --- Add Stablecoin Allocation ---\n",
    "    # Assign the reserve percentage to the primary quote asset\n",
    "    if QUOTE_ASSET in dynamic_target_allocations_pct:\n",
    "         # This case should be rare if QUOTE_ASSET is in STABLECOIN_ASSETS and excluded above\n",
    "         dynamic_target_allocations_pct[QUOTE_ASSET] += STABLECOIN_RESERVE_PCT\n",
    "         print(f\"Warning: Primary quote asset {QUOTE_ASSET} was already in crypto targets?\")\n",
    "    else:\n",
    "         dynamic_target_allocations_pct[QUOTE_ASSET] = STABLECOIN_RESERVE_PCT\n",
    "\n",
    "    # --- Ensure all target assets (Top N + Stablecoins) are in the dict ---\n",
    "    # Create a set of all assets that *should* have a target (even if 0%)\n",
    "    all_intended_target_assets = set(top_n_crypto_df['Asset'].tolist() + STABLECOIN_ASSETS)\n",
    "    for asset in all_intended_target_assets:\n",
    "         if asset not in dynamic_target_allocations_pct:\n",
    "              dynamic_target_allocations_pct[asset] = Decimal('0.0') # Assign 0% if missing\n",
    "\n",
    "    # --- Verify Sum ---\n",
    "    total_dynamic_pct = sum(dynamic_target_allocations_pct.values())\n",
    "    print(f\"Target Allocations Sum: {total_dynamic_pct:.2f}%\") # Display with 2 decimal places\n",
    "    # Use Decimal for comparison threshold\n",
    "    if abs(total_dynamic_pct - Decimal('100.0')) > Decimal('0.01'):\n",
    "        print(\"⚠️ WARNING: Target Sum is not 100%!\")\n",
    "\n",
    "    # --- Optional: Print sorted targets for review ---\n",
    "    # print(\"\\nCalculated Target Allocations (%):\")\n",
    "    # sorted_targets = dict(sorted(dynamic_target_allocations_pct.items(), key=lambda item: item[1], reverse=True))\n",
    "    # for asset, pct in sorted_targets.items():\n",
    "    #     if pct > 0: print(f\"  {asset}: {pct:.2f}%\") # Show non-zero targets with 2 decimals\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"❌ An error occurred during dynamic target calculation: {e}\")\n",
    "    dynamic_target_allocations_pct = {} # Reset on error\n",
    "\n",
    "if not dynamic_target_allocations_pct:\n",
    "    print(\"⚠️ Dynamic target allocation dictionary is empty.\")\n",
    "else:\n",
    "    print(\"✅ Dynamic target allocations calculated ('dynamic_target_allocations_pct').\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "625bbb71-6019-44ee-800b-04c7296303fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Defining Helper Function: find_simple_sr ---\n",
      "✅ Helper function 'find_simple_sr' defined.\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Define Support/Resistance Helper Function\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# --- Check Prerequisites ---\n",
    "# This function relies on pandas DataFrames having 'Low' and 'High' columns.\n",
    "# No external variables needed besides the DataFrame passed in.\n",
    "\n",
    "print(\"\\n--- Defining Helper Function: find_simple_sr ---\")\n",
    "\n",
    "def find_simple_sr(df, lookback=20):\n",
    "    \"\"\"\n",
    "    Identifies simple recent swing lows (support) and highs (resistance).\n",
    "    Looks for the min Low and max High over a rolling lookback period.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Kline DataFrame with 'Low' and 'High' columns.\n",
    "        lookback (int): How many recent periods (rows) to consider.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (recent_support, recent_resistance) as floats or Decimals\n",
    "               Returns (None, None) if not enough data or columns missing.\n",
    "    \"\"\"\n",
    "    required_cols = ['Low', 'High']\n",
    "    if df is None or df.empty or len(df) < lookback or not all(c in df.columns for c in required_cols):\n",
    "        # print(f\"  Debug SR: DataFrame empty, too short, or missing columns. Len={len(df) if df is not None else 'None'}, Lookback={lookback}\")\n",
    "        return None, None # Not enough data or required columns missing\n",
    "\n",
    "    try:\n",
    "        # Get the 'Low' and 'High' series for the lookback period\n",
    "        recent_lows = df['Low'].tail(lookback)\n",
    "        recent_highs = df['High'].tail(lookback)\n",
    "\n",
    "        # Find the minimum low (support) and maximum high (resistance)\n",
    "        support = recent_lows.min()\n",
    "        resistance = recent_highs.max()\n",
    "\n",
    "        # Return the values (will be float or Decimal depending on df input type)\n",
    "        return support, resistance\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"  ❌ Error finding S/R: {e}\")\n",
    "        return None, None\n",
    "\n",
    "print(\"✅ Helper function 'find_simple_sr' defined.\")\n",
    "# --- Example Test (Optional - Uncomment to run) ---\n",
    "# if 'top_n_klines' in locals() and top_n_klines and top_n_symbols:\n",
    "#     test_symbol = top_n_symbols[0]\n",
    "#     test_interval = '1d'\n",
    "#     if test_symbol in top_n_klines and test_interval in top_n_klines[test_symbol]:\n",
    "#         test_df = top_n_klines[test_symbol][test_interval]\n",
    "#         sup, res = find_simple_sr(test_df, lookback=30) # Example lookback\n",
    "#         print(f\"\\nExample {test_symbol} Daily S/R (lookback 30):\")\n",
    "#         if sup is not None and res is not None:\n",
    "#             print(f\"  Support: {sup:.4f}, Resistance: {res:.4f}\")\n",
    "#             last_close = test_df['Close'].iloc[-1]\n",
    "#             print(f\"  Last Close: {last_close:.4f}\")\n",
    "#             print(f\"  Dist to Support: {(last_close - sup):.4f}\")\n",
    "#             print(f\"  Dist to Resistance: {(res - last_close):.4f}\")\n",
    "#         else:\n",
    "#             print(\"  Could not calculate S/R (check data).\")\n",
    "#     else:\n",
    "#         print(f\"\\nCannot run example S/R test: {test_symbol} {test_interval} data missing.\")\n",
    "# else:\n",
    "#     print(\"\\nCannot run example S/R test: Prerequisite data missing.\")\n",
    "# --- End Example Test ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e37def6a-8761-459c-bdd4-e69268dbf0c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Analyzing Market State (TA) for Top N Symbols ---\n",
      "\n",
      "--- Market State Analysis Summary ---\n",
      "Attempted analysis for 10 symbols.\n",
      "  10 symbols analyzed successfully.\n",
      "\n",
      "✅ Analysis results stored in 'full_market_state' dictionary.\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: Analyze Market State (TA) for Top N Symbols\n",
    "\n",
    "import numpy as np\n",
    "import json\n",
    "from decimal import Decimal # Import Decimal\n",
    "\n",
    "# --- Configuration ---\n",
    "SR_LOOKBACK_DAILY = 30\n",
    "SR_LOOKBACK_HOURLY = 50\n",
    "RSI_OVERSOLD_THRESHOLD = Decimal('30.0') # Use Decimal for comparison consistency\n",
    "NEAR_SUPPORT_PROXIMITY_PCT = Decimal('1.0') # Within 1% *above* hourly support\n",
    "\n",
    "# --- Check Prerequisites ---\n",
    "if 'top_n_klines' not in locals() or not top_n_klines:\n",
    "    raise ValueError(\"'top_n_klines' dictionary not found or empty. Run Cell 5.\")\n",
    "if 'find_simple_sr' not in locals():\n",
    "     raise RuntimeError(\"Helper function 'find_simple_sr' not defined. Run Cell 7.\")\n",
    "\n",
    "print(\"\\n--- Analyzing Market State (TA) for Top N Symbols ---\")\n",
    "\n",
    "def analyze_top_n_state(klines_data_dict, sr_lookback_d=30, sr_lookback_h=50, rsi_period=14, rsi_oversold=Decimal('30.0'), proximity_pct=Decimal('1.0')):\n",
    "    \"\"\"\n",
    "    Performs multi-timeframe technical analysis including S/R for multiple symbols.\n",
    "\n",
    "    Args:\n",
    "        klines_data_dict (dict): Nested dict {'SYMBOL': {'interval': DataFrame}}. Kline data should include indicators.\n",
    "        sr_lookback_d (int): Lookback period for daily S/R.\n",
    "        sr_lookback_h (int): Lookback period for hourly S/R.\n",
    "        rsi_period (int): The period used for RSI calculation (for key lookup).\n",
    "        rsi_oversold (Decimal): The threshold below which RSI is considered oversold.\n",
    "        proximity_pct (Decimal): The percentage above support to consider 'near'.\n",
    "\n",
    "    Returns:\n",
    "        dict: Nested dict {'SYMBOL': {'analysis_key': value}}. Contains analysis results or error messages.\n",
    "    \"\"\"\n",
    "    all_analysis = {}\n",
    "    analysis_errors = 0\n",
    "\n",
    "    required_intervals = ['1d', '1h', '5m'] # Intervals needed for this specific analysis logic\n",
    "\n",
    "    # Define expected indicator column names dynamically\n",
    "    sma50_col = 'SMA_50'\n",
    "    sma20_col = 'SMA_20'\n",
    "    rsi_col = f'RSI_{rsi_period}'\n",
    "    macd_col = f'MACD_{MACD_FAST}_{MACD_SLOW}_{MACD_SIGNAL}' # Example, adjust if needed elsewhere\n",
    "\n",
    "    for symbol, interval_dict in klines_data_dict.items():\n",
    "        analysis = {} # Analysis results for this symbol\n",
    "        all_analysis[symbol] = analysis # Add symbol's dict to the main results dict\n",
    "\n",
    "        # --- Check for necessary data & minimum lengths ---\n",
    "        if not all(k in interval_dict for k in required_intervals):\n",
    "            analysis['error'] = \"Missing Interval Data (1d, 1h, or 5m)\"\n",
    "            analysis_errors += 1\n",
    "            continue # Skip this symbol if essential intervals are missing\n",
    "\n",
    "        df_1d = interval_dict['1d']\n",
    "        df_1h = interval_dict['1h']\n",
    "        df_5m = interval_dict['5m']\n",
    "\n",
    "        # Check for required columns in specific dataframes and minimum lengths\n",
    "        required_cols_1d = ['Close', 'Low', 'High', sma50_col]\n",
    "        required_cols_1h = ['Close', 'Low', 'High', sma20_col]\n",
    "        required_cols_5m = ['Close', rsi_col]\n",
    "\n",
    "        if not all(c in df_1d.columns for c in required_cols_1d) or len(df_1d) < sr_lookback_d:\n",
    "             analysis['error'] = f\"Missing 1d columns ({required_cols_1d}) or insufficient length (<{sr_lookback_d})\"\n",
    "             analysis_errors += 1; continue\n",
    "        if not all(c in df_1h.columns for c in required_cols_1h) or len(df_1h) < sr_lookback_h:\n",
    "             analysis['error'] = f\"Missing 1h columns ({required_cols_1h}) or insufficient length (<{sr_lookback_h})\"\n",
    "             analysis_errors += 1; continue\n",
    "        if not all(c in df_5m.columns for c in required_cols_5m) or len(df_5m) < rsi_period + 1: # Need enough for RSI calc\n",
    "             analysis['error'] = f\"Missing 5m columns ({required_cols_5m}) or insufficient length (<{rsi_period+1})\"\n",
    "             analysis_errors += 1; continue\n",
    "\n",
    "        # --- Get Latest Valid Close Price ---\n",
    "        # Use hourly close for most recent price, ensure it's not NaN\n",
    "        try:\n",
    "            last_close = df_1h['Close'].iloc[-1]\n",
    "            if pd.isna(last_close): raise ValueError(\"Last hourly close is NaN\")\n",
    "            analysis['last_close'] = Decimal(str(last_close)) # Store as Decimal\n",
    "        except (IndexError, ValueError) as e:\n",
    "            analysis['error'] = f\"Could not get valid last hourly close: {e}\"\n",
    "            analysis_errors += 1; continue # Cannot proceed without a price\n",
    "\n",
    "        # --- Perform Analysis Steps ---\n",
    "        try:\n",
    "            # 1. Daily Trend (Close vs SMA50) - Check for NaN\n",
    "            last_daily_close = df_1d['Close'].iloc[-1]\n",
    "            last_daily_sma50 = df_1d[sma50_col].iloc[-1]\n",
    "            if pd.isna(last_daily_close) or pd.isna(last_daily_sma50): analysis['daily_trend_up'] = None\n",
    "            else: analysis['daily_trend_up'] = last_daily_close > last_daily_sma50\n",
    "\n",
    "            # 2. Hourly Position (Close vs SMA20) - Check for NaN\n",
    "            last_hourly_sma20 = df_1h[sma20_col].iloc[-1]\n",
    "            if pd.isna(last_hourly_sma20): analysis['hourly_below_sma'] = None\n",
    "            else: analysis['hourly_below_sma'] = last_close < last_hourly_sma20 # Use hourly close\n",
    "\n",
    "            # 3. 5-Minute RSI State - Check for NaN\n",
    "            last_5m_rsi = df_5m[rsi_col].iloc[-1]\n",
    "            if pd.isna(last_5m_rsi):\n",
    "                analysis[f'last_5m_{rsi_col}'] = None # Store actual value as None\n",
    "                analysis['5m_rsi_oversold'] = None\n",
    "            else:\n",
    "                analysis[f'last_5m_{rsi_col}'] = Decimal(str(last_5m_rsi)) # Store actual RSI value as Decimal\n",
    "                analysis['5m_rsi_oversold'] = analysis[f'last_5m_{rsi_col}'] < rsi_oversold\n",
    "\n",
    "            # 4. Support/Resistance Check (Using helper from Cell 7)\n",
    "            daily_sup, daily_res = find_simple_sr(df_1d, lookback=sr_lookback_d)\n",
    "            hourly_sup, hourly_res = find_simple_sr(df_1h, lookback=sr_lookback_h)\n",
    "            analysis['daily_support'] = Decimal(str(daily_sup)) if daily_sup is not None else None\n",
    "            analysis['daily_resistance'] = Decimal(str(daily_res)) if daily_res is not None else None\n",
    "            analysis['hourly_support'] = Decimal(str(hourly_sup)) if hourly_sup is not None else None\n",
    "            analysis['hourly_resistance'] = Decimal(str(hourly_res)) if hourly_res is not None else None\n",
    "\n",
    "            # 5. Proximity to Hourly Support Check\n",
    "            analysis['near_hourly_support'] = None\n",
    "            if analysis['last_close'] is not None and analysis['hourly_support'] is not None:\n",
    "                 lower_bound = analysis['hourly_support']\n",
    "                 # Calculate upper bound: support * (1 + pct/100)\n",
    "                 upper_bound = analysis['hourly_support'] * (Decimal('1.0') + proximity_pct / Decimal('100.0'))\n",
    "                 # Check if last close is between support and support + proximity %\n",
    "                 analysis['near_hourly_support'] = (lower_bound <= analysis['last_close'] <= upper_bound)\n",
    "\n",
    "        except IndexError:\n",
    "             # Handles cases where iloc[-1] fails unexpectedly (should be caught by length checks earlier)\n",
    "             analysis['error'] = \"Not enough data points for indicator/price lookup (IndexError).\"\n",
    "             analysis_errors += 1\n",
    "        except Exception as e:\n",
    "             analysis['error'] = f\"Unexpected error during analysis: {e}\"\n",
    "             analysis_errors += 1\n",
    "\n",
    "\n",
    "    if analysis_errors > 0:\n",
    "         print(f\"⚠️ Analysis completed with errors for {analysis_errors} symbol(s).\")\n",
    "\n",
    "    return all_analysis\n",
    "\n",
    "\n",
    "# --- Run the multi-asset analysis ---\n",
    "full_market_state = analyze_top_n_state(\n",
    "    top_n_klines,\n",
    "    sr_lookback_d=SR_LOOKBACK_DAILY,\n",
    "    sr_lookback_h=SR_LOOKBACK_HOURLY,\n",
    "    rsi_period=RSI_PERIOD, # Pass the RSI period used\n",
    "    rsi_oversold=RSI_OVERSOLD_THRESHOLD,\n",
    "    proximity_pct=NEAR_SUPPORT_PROXIMITY_PCT\n",
    ")\n",
    "\n",
    "print(\"\\n--- Market State Analysis Summary ---\")\n",
    "# Optionally print a compact summary or just confirm completion\n",
    "analyzed_count = len(full_market_state)\n",
    "error_count = sum(1 for state in full_market_state.values() if 'error' in state)\n",
    "success_count = analyzed_count - error_count\n",
    "\n",
    "print(f\"Attempted analysis for {analyzed_count} symbols.\")\n",
    "if error_count > 0:\n",
    "    print(f\"  {error_count} symbols had errors during analysis.\")\n",
    "    # Optionally list symbols with errors:\n",
    "    # errors = {sym: state['error'] for sym, state in full_market_state.items() if 'error' in state}\n",
    "    # print(f\"  Errors: {errors}\")\n",
    "print(f\"  {success_count} symbols analyzed successfully.\")\n",
    "print(\"\\n✅ Analysis results stored in 'full_market_state' dictionary.\")\n",
    "\n",
    "# --- Optional: Display Full State for one symbol ---\n",
    "# test_symbol_state = 'BTCUSDT'\n",
    "# if test_symbol_state in full_market_state:\n",
    "#     print(f\"\\n--- Detailed State for {test_symbol_state} ---\")\n",
    "#     # Use jsonumps for pretty printing, converting Decimals to strings\n",
    "#     print(json.dumps(full_market_state[test_symbol_state], indent=4, default=str))\n",
    "# else:\n",
    "#      print(f\"\\nState for {test_symbol_state} not available.\")\n",
    "# --- End Optional Display ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2c626daa-6b2c-44c6-b593-7f9d261d66d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Determining Ideal Rebalancing Trades (Based on Total Value Deviation) ---\n",
      "Calculating current portfolio value...\n",
      "Total Portfolio Value (Free+Locked): 33.67 USDT\n",
      "  Attempting price re-fetch for BUY ADA...\n",
      "    Re-fetched price: 0.57730000\n",
      "  Attempting price re-fetch for BUY DOGE...\n",
      "    Re-fetched price: 0.14708000\n",
      "  Attempting price re-fetch for BUY ETH...\n",
      "    Re-fetched price: 1493.50000000\n",
      "  Attempting price re-fetch for BUY HBAR...\n",
      "    Re-fetched price: 0.15410000\n",
      "  Attempting price re-fetch for BUY LTC...\n",
      "    Re-fetched price: 70.04000000\n",
      "  Attempting price re-fetch for BUY SOL...\n",
      "    Re-fetched price: 104.54000000\n",
      "  Attempting price re-fetch for BUY XRP...\n",
      "    Re-fetched price: 1.86560000\n",
      "\n",
      "--- Ideal Rebalancing Trades Proposed (Ignoring Free/Locked Status for now) ---\n",
      "  Action Asset    IdealQuantity                  IdealValueUSDT   CurrentPrice\n",
      "0   SELL   BTC   0.000033521895   2.611459875111559997139675196       77903.11\n",
      "1   SELL  USDT  19.967891386760            19.96789138676000000            1.0\n",
      "2    BUY   ADA   1.717182474100  0.9913294422981006875462582266     0.57730000\n",
      "3    BUY  DOGE   5.471361688923  0.8047278772068667656359017231     0.14708000\n",
      "4    BUY   ETH   0.003317110798   4.954104976210199004644967914  1493.50000000\n",
      "5    BUY  HBAR   5.967747556833  0.9196298985080235823115699750     0.15410000\n",
      "6    BUY   LTC   0.010236900293  0.7169924965449780674539101721    70.04000000\n",
      "7    BUY   SOL   0.028004185228   2.927557523764871950244568291   104.54000000\n",
      "8    BUY   XRP   5.698647814710   10.63139736312359179709797877     1.86560000\n",
      "\n",
      "✅ Ideal trades calculation complete. Found 9 potential trades.\n",
      "   Stored results in 'trades_df'. Next step: Check feasibility against free balances.\n"
     ]
    }
   ],
   "source": [
    "# Cell 9: Determine Ideal Rebalancing Trades (Based on Total Value Deviation)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from decimal import Decimal, ROUND_DOWN, DivisionByZero # Import Decimal and specific exceptions\n",
    "\n",
    "# --- Configuration ---\n",
    "QUOTE_ASSET = 'USDT'\n",
    "# Minimum trade value threshold to consider a rebalance trade significant\n",
    "TRADE_THRESHOLD_USDT = Decimal('0.50') # Example: $0.50\n",
    "\n",
    "# --- Check Prerequisites ---\n",
    "if 'portfolio_state' not in locals() or 'balances' not in portfolio_state or portfolio_state['balances'].empty:\n",
    "     raise ValueError(\"Portfolio balances ('portfolio_state['balances']') not found or empty. Run Cell 2.\")\n",
    "if 'dynamic_target_allocations_pct' not in locals() or not dynamic_target_allocations_pct:\n",
    "     raise ValueError(\"Target allocations ('dynamic_target_allocations_pct') not found or empty. Run Cell 6.\")\n",
    "if 'full_market_state' not in locals() or not full_market_state:\n",
    "     raise ValueError(\"Market state analysis ('full_market_state') not found or empty. Run Cell 8.\")\n",
    "if 'client' not in locals() or client is None: # Needed for fetching prices if missing\n",
    "    raise RuntimeError(\"Binance client is not initialized. Run Cell 1.\")\n",
    "\n",
    "\n",
    "print(\"\\n--- Determining Ideal Rebalancing Trades (Based on Total Value Deviation) ---\")\n",
    "\n",
    "# --- 1. Calculate Current Total Value of Each Asset ---\n",
    "current_portfolio_details = {}\n",
    "total_portfolio_value_usdt = Decimal('0.0')\n",
    "\n",
    "print(\"Calculating current portfolio value...\")\n",
    "balances_df = portfolio_state['balances'] # From Cell 2\n",
    "\n",
    "for asset, balance_info in balances_df.iterrows():\n",
    "    # Total quantity = Free + Locked\n",
    "    total_quantity = balance_info['Free'] + balance_info['Locked']\n",
    "    if total_quantity <= 0: continue # Skip zero-balance assets\n",
    "\n",
    "    current_price = Decimal('0.0')\n",
    "    usdt_value = Decimal('0.0')\n",
    "    price_source = \"Unknown\"\n",
    "\n",
    "    # Get price: Prioritize analysis state, then fetch if needed\n",
    "    symbol = f\"{asset}{QUOTE_ASSET}\"\n",
    "    if asset == QUOTE_ASSET:\n",
    "        current_price = Decimal('1.0')\n",
    "        price_source = \"Assumed 1.0\"\n",
    "    elif symbol in full_market_state and 'last_close' in full_market_state[symbol] and full_market_state[symbol]['last_close'] is not None:\n",
    "        # Use price from TA results (should be Decimal already)\n",
    "        current_price = full_market_state[symbol]['last_close']\n",
    "        price_source = \"TA Result\"\n",
    "    else:\n",
    "        # Fallback: Fetch current ticker price if not found in TA or if TA failed for symbol\n",
    "        try:\n",
    "            # print(f\"  Fetching price for {symbol}...\") # Uncomment for debug\n",
    "            ticker_info = client.get_symbol_ticker(symbol=symbol)\n",
    "            current_price = Decimal(ticker_info['price'])\n",
    "            price_source = \"API Fetch\"\n",
    "        except Exception as e:\n",
    "            print(f\"  ⚠️ Warning: Could not get price for {symbol}: {e}. Value will be 0.\")\n",
    "            current_price = Decimal('0.0') # Assign 0 if price unavailable\n",
    "            price_source = \"Fetch Failed\"\n",
    "\n",
    "    # Calculate USDT value for the asset\n",
    "    usdt_value = total_quantity * current_price\n",
    "    total_portfolio_value_usdt += usdt_value\n",
    "\n",
    "    current_portfolio_details[asset] = {\n",
    "        'TotalQuantity': total_quantity,\n",
    "        'CurrentPrice': current_price,\n",
    "        'CurrentValueUSDT': usdt_value,\n",
    "        'PriceSource': price_source\n",
    "    }\n",
    "\n",
    "print(f\"Total Portfolio Value (Free+Locked): {total_portfolio_value_usdt:,.2f} {QUOTE_ASSET}\")\n",
    "\n",
    "# --- 2. Create Combined DataFrame for Deviation Analysis ---\n",
    "# Convert details dict to DataFrame\n",
    "current_values_df = pd.DataFrame.from_dict(current_portfolio_details, orient='index')\n",
    "# Convert target percentages dict to Series\n",
    "target_alloc_series = pd.Series(dynamic_target_allocations_pct, name='Target%').apply(Decimal) # Ensure Decimal\n",
    "\n",
    "# Combine current values and targets\n",
    "# Use outer join to include assets in targets but not currently held, or vice-versa\n",
    "combined_df = current_values_df.join(target_alloc_series, how='outer')\n",
    "\n",
    "# Fill NaNs resulting from the join\n",
    "combined_df['TotalQuantity'] = combined_df['TotalQuantity'].fillna(Decimal('0.0'))\n",
    "combined_df['CurrentPrice'] = combined_df['CurrentPrice'].fillna(Decimal('0.0'))\n",
    "combined_df['CurrentValueUSDT'] = combined_df['CurrentValueUSDT'].fillna(Decimal('0.0'))\n",
    "combined_df['Target%'] = combined_df['Target%'].fillna(Decimal('0.0'))\n",
    "combined_df['PriceSource'] = combined_df['PriceSource'].fillna('N/A')\n",
    "\n",
    "# Recalculate total value from combined DF to ensure consistency after outer join\n",
    "total_portfolio_value_final = combined_df['CurrentValueUSDT'].sum()\n",
    "\n",
    "# --- 3. Calculate Allocations and Deviations ---\n",
    "if total_portfolio_value_final > 0:\n",
    "    combined_df['CurrentAllocation%'] = (combined_df['CurrentValueUSDT'] / total_portfolio_value_final) * Decimal('100.0')\n",
    "else:\n",
    "    combined_df['CurrentAllocation%'] = Decimal('0.0') # Avoid division by zero\n",
    "\n",
    "combined_df['TargetValueUSDT'] = (combined_df['Target%'] / Decimal('100.0')) * total_portfolio_value_final\n",
    "combined_df['DeviationValueUSDT'] = combined_df['CurrentValueUSDT'] - combined_df['TargetValueUSDT']\n",
    "combined_df['Deviation%'] = combined_df['CurrentAllocation%'] - combined_df['Target%']\n",
    "\n",
    "# --- 4. Determine Initial BUY/SELL Trades based on Deviation Value Threshold ---\n",
    "proposed_trades_list = []\n",
    "# Iterate through assets with significant deviation\n",
    "for asset, row in combined_df.iterrows():\n",
    "    deviation_value = row['DeviationValueUSDT']\n",
    "    action = None\n",
    "    trade_value = Decimal('0.0')\n",
    "    trade_quantity = Decimal('0.0')\n",
    "\n",
    "    # Propose SELL if significantly over-allocated\n",
    "    if deviation_value > TRADE_THRESHOLD_USDT:\n",
    "        action = 'SELL'\n",
    "        trade_value = deviation_value # Amount to sell in USDT value\n",
    "        # Calculate quantity to sell\n",
    "        current_price = row['CurrentPrice']\n",
    "        if current_price > 0:\n",
    "             try:\n",
    "                 trade_quantity = (trade_value / current_price).quantize(Decimal('1e-12')) # Use high precision intermediate\n",
    "             except DivisionByZero:\n",
    "                 print(f\"  ⚠️ Warning: Price is zero for {asset}. Cannot calculate sell quantity.\")\n",
    "                 continue # Skip this trade\n",
    "        else:\n",
    "             print(f\"  ⚠️ Warning: Price is zero for {asset}. Cannot calculate sell quantity.\")\n",
    "             continue # Skip this trade\n",
    "\n",
    "    # Propose BUY if significantly under-allocated\n",
    "    elif deviation_value < -TRADE_THRESHOLD_USDT:\n",
    "        action = 'BUY'\n",
    "        trade_value = abs(deviation_value) # Amount to buy in USDT value\n",
    "        # Calculate quantity to buy\n",
    "        current_price = row['CurrentPrice']\n",
    "        # Special case for buying stablecoins (use value as quantity)\n",
    "        if asset == QUOTE_ASSET:\n",
    "             trade_quantity = trade_value\n",
    "             current_price = Decimal('1.0') # Assume price 1 for calculation consistency\n",
    "        elif current_price > 0:\n",
    "             try:\n",
    "                 trade_quantity = (trade_value / current_price).quantize(Decimal('1e-12')) # Use high precision intermediate\n",
    "             except DivisionByZero:\n",
    "                  print(f\"  ⚠️ Warning: Price is zero for {asset}. Cannot calculate buy quantity.\")\n",
    "                  continue # Skip this trade\n",
    "        else:\n",
    "             # Try fetching price again if it was missing/zero earlier\n",
    "             symbol = f\"{asset}{QUOTE_ASSET}\"\n",
    "             print(f\"  Attempting price re-fetch for BUY {asset}...\")\n",
    "             try:\n",
    "                 ticker_info = client.get_symbol_ticker(symbol=symbol)\n",
    "                 current_price = Decimal(ticker_info['price'])\n",
    "                 if current_price > 0:\n",
    "                      trade_quantity = (trade_value / current_price).quantize(Decimal('1e-12'))\n",
    "                      print(f\"    Re-fetched price: {current_price}\")\n",
    "                      # Update price in combined_df for reference? Optional.\n",
    "                      # combined_df.loc[asset, 'CurrentPrice'] = current_price\n",
    "                 else:\n",
    "                      print(f\"    ⚠️ Re-fetched price is zero for {asset}. Cannot calculate buy quantity.\")\n",
    "                      continue\n",
    "             except Exception as e:\n",
    "                  print(f\"    ⚠️ Re-fetch failed for {symbol}: {e}. Cannot calculate buy quantity.\")\n",
    "                  continue # Skip this trade\n",
    "\n",
    "\n",
    "    # Add valid proposed trades to the list\n",
    "    if action and trade_quantity > 0:\n",
    "        proposed_trades_list.append({\n",
    "            'Action': action,\n",
    "            'Asset': asset,\n",
    "            # Store intermediate high-precision quantity. Final formatting happens later.\n",
    "            'IdealQuantity': trade_quantity,\n",
    "            'IdealValueUSDT': trade_value,\n",
    "            'CurrentPrice': current_price # Store price used for calculation\n",
    "        })\n",
    "\n",
    "# --- 5. Create Final DataFrame of Proposed Trades ---\n",
    "trades_df = pd.DataFrame() # Initialize empty\n",
    "if proposed_trades_list:\n",
    "    trades_df = pd.DataFrame(proposed_trades_list)\n",
    "    # Sort for clarity (e.g., Sells first, then Buys)\n",
    "    trades_df.sort_values(by=['Action','Asset'], ascending=[False, True], inplace=True)\n",
    "    trades_df = trades_df.reset_index(drop=True) # Reset index after sort\n",
    "\n",
    "    print(\"\\n--- Ideal Rebalancing Trades Proposed (Ignoring Free/Locked Status for now) ---\")\n",
    "    # Display with formatting\n",
    "    display_cols = ['Action', 'Asset', 'IdealQuantity', 'IdealValueUSDT', 'CurrentPrice']\n",
    "    with pd.option_context('display.float_format', '{:.8f}'.format): # Show more precision for quantity\n",
    "        print(trades_df[display_cols])\n",
    "\n",
    "else:\n",
    "    print(\"\\n--- No significant deviations found requiring ideal rebalancing trades. ---\")\n",
    "\n",
    "\n",
    "# Result: 'trades_df' DataFrame contains the ideal trades based on total value deviation.\n",
    "print(f\"\\n✅ Ideal trades calculation complete. Found {len(trades_df)} potential trades.\")\n",
    "print(\"   Stored results in 'trades_df'. Next step: Check feasibility against free balances.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b5570c5c-e372-4ca3-97d0-ca42485b83db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Checking Trade Feasibility Against Free Balances & Open Orders ---\n",
      "Available Free USDT: 0.10189178\n",
      "\n",
      "Feasibility Check Summary:\n",
      "  0 trade(s) appear feasible with current free balances.\n",
      "  9 trade(s) have conflicts (insufficient free balance/USDT).\n",
      "\n",
      "--- Conflicting Trades Details ---\n",
      "  Action Asset    IdealQuantity                  IdealValueUSDT  \\\n",
      "0   SELL   BTC   0.000033521895   2.611459875111559997139675196   \n",
      "1   SELL  USDT  19.967891386760            19.96789138676000000   \n",
      "2    BUY   ADA   1.717182474100  0.9913294422981006875462582266   \n",
      "3    BUY  DOGE   5.471361688923  0.8047278772068667656359017231   \n",
      "4    BUY   ETH   0.003317110798   4.954104976210199004644967914   \n",
      "5    BUY  HBAR   5.967747556833  0.9196298985080235823115699750   \n",
      "6    BUY   LTC   0.010236900293  0.7169924965449780674539101721   \n",
      "7    BUY   SOL   0.028004185228   2.927557523764871950244568291   \n",
      "8    BUY   XRP   5.698647814710   10.63139736312359179709797877   \n",
      "\n",
      "                ConflictType                      BlockingOrderIDs  \n",
      "0  Insufficient Free Balance              [1466046736, 1466046691]  \n",
      "1  Insufficient Free Balance                                    []  \n",
      "2     Insufficient Free USDT  [1466045855, 1466045747, 1466045383]  \n",
      "3     Insufficient Free USDT  [1466045855, 1466045747, 1466045383]  \n",
      "4     Insufficient Free USDT  [1466045855, 1466045747, 1466045383]  \n",
      "5     Insufficient Free USDT  [1466045855, 1466045747, 1466045383]  \n",
      "6     Insufficient Free USDT  [1466045855, 1466045747, 1466045383]  \n",
      "7     Insufficient Free USDT  [1466045855, 1466045747, 1466045383]  \n",
      "8     Insufficient Free USDT  [1466045855, 1466045747, 1466045383]  \n",
      "\n",
      "✅ Feasibility check complete. Results stored in 'feasible_trades_df'.\n"
     ]
    }
   ],
   "source": [
    "# Cell 10: Check Trade Feasibility & Identify Conflicts\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from decimal import Decimal\n",
    "\n",
    "# --- Configuration ---\n",
    "QUOTE_ASSET = 'USDT'\n",
    "\n",
    "# --- Check Prerequisites ---\n",
    "if 'trades_df' not in locals():\n",
    "     # If trades_df is empty or doesn't exist, there's nothing to check\n",
    "     print(\"\\n'trades_df' not found or empty. Skipping feasibility check.\")\n",
    "     # Ensure feasible_trades_df exists and is empty for subsequent steps\n",
    "     feasible_trades_df = pd.DataFrame()\n",
    "elif 'portfolio_state' not in locals() or 'balances' not in portfolio_state or 'open_orders' not in portfolio_state:\n",
    "     raise ValueError(\"Portfolio state ('portfolio_state' with 'balances' and 'open_orders') not found. Run Cell 2.\")\n",
    "else:\n",
    "    print(\"\\n--- Checking Trade Feasibility Against Free Balances & Open Orders ---\")\n",
    "\n",
    "    # Make a copy to add feasibility columns\n",
    "    feasible_trades_df = trades_df.copy()\n",
    "\n",
    "    # Add new columns to track status\n",
    "    feasible_trades_df['Feasible'] = True # Assume feasible initially\n",
    "    feasible_trades_df['ConflictType'] = '' # e.g., 'Insufficient Free Balance', 'Insufficient Free USDT'\n",
    "    feasible_trades_df['BlockingOrderIDs'] = [[] for _ in range(len(feasible_trades_df))] # List to hold conflicting order IDs\n",
    "\n",
    "    balances = portfolio_state['balances'] # DataFrame with 'Free', 'Locked' (Index: Asset)\n",
    "    open_orders = portfolio_state['open_orders'] # DataFrame of open orders\n",
    "\n",
    "    # Get free balance of the quote asset (USDT) for checking BUYs\n",
    "    free_usdt = balances.loc[QUOTE_ASSET, 'Free'] if QUOTE_ASSET in balances.index else Decimal('0.0')\n",
    "    print(f\"Available Free {QUOTE_ASSET}: {free_usdt:.8f}\")\n",
    "\n",
    "    # Iterate through the proposed trades\n",
    "    for index, trade in feasible_trades_df.iterrows():\n",
    "        asset = trade['Asset']\n",
    "        action = trade['Action']\n",
    "        ideal_qty = trade['IdealQuantity'] # This is Decimal\n",
    "        ideal_value = trade['IdealValueUSDT'] # This is Decimal\n",
    "\n",
    "        # --- Check SELL Feasibility ---\n",
    "        if action == 'SELL':\n",
    "            # Check if we hold this asset and get its free balance\n",
    "            if asset in balances.index:\n",
    "                free_balance = balances.loc[asset, 'Free']\n",
    "                # Compare ideal quantity to sell with free balance\n",
    "                if ideal_qty > free_balance:\n",
    "                    feasible_trades_df.loc[index, 'Feasible'] = False\n",
    "                    feasible_trades_df.loc[index, 'ConflictType'] = 'Insufficient Free Balance'\n",
    "                    # Find open SELL orders for this asset that are locking the balance\n",
    "                    blocking_orders = open_orders[\n",
    "                        (open_orders['symbol'] == f\"{asset}{QUOTE_ASSET}\") &\n",
    "                        (open_orders['side'] == 'SELL') &\n",
    "                        (open_orders['status'].isin(['NEW', 'PARTIALLY_FILLED'])) # Consider active statuses\n",
    "                    ]['orderId'].tolist()\n",
    "                    feasible_trades_df.at[index, 'BlockingOrderIDs'] = blocking_orders # Use .at for list assignment\n",
    "            else:\n",
    "                # Trying to sell an asset we don't have at all (should be rare if logic is correct)\n",
    "                feasible_trades_df.loc[index, 'Feasible'] = False\n",
    "                feasible_trades_df.loc[index, 'ConflictType'] = 'Asset Not Held'\n",
    "\n",
    "        # --- Check BUY Feasibility ---\n",
    "        elif action == 'BUY':\n",
    "            # Compare ideal value to buy with free USDT\n",
    "            if ideal_value > free_usdt:\n",
    "                feasible_trades_df.loc[index, 'Feasible'] = False\n",
    "                feasible_trades_df.loc[index, 'ConflictType'] = f'Insufficient Free {QUOTE_ASSET}'\n",
    "                # Find open BUY orders that might be locking USDT\n",
    "                # Note: Estimating locked USDT by open BUY orders is complex as it depends on price.\n",
    "                # We'll just list *all* open BUY orders as potentially contributing.\n",
    "                blocking_orders = open_orders[\n",
    "                    (open_orders['side'] == 'BUY') &\n",
    "                    (open_orders['status'].isin(['NEW', 'PARTIALLY_FILLED']))\n",
    "                ]['orderId'].tolist()\n",
    "                feasible_trades_df.at[index, 'BlockingOrderIDs'] = blocking_orders # Use .at for list assignment\n",
    "\n",
    "\n",
    "    # --- Report Summary ---\n",
    "    feasible_count = feasible_trades_df['Feasible'].sum()\n",
    "    conflicting_count = len(feasible_trades_df) - feasible_count\n",
    "\n",
    "    print(f\"\\nFeasibility Check Summary:\")\n",
    "    print(f\"  {feasible_count} trade(s) appear feasible with current free balances.\")\n",
    "    print(f\"  {conflicting_count} trade(s) have conflicts (insufficient free balance/USDT).\")\n",
    "\n",
    "    if conflicting_count > 0:\n",
    "        print(\"\\n--- Conflicting Trades Details ---\")\n",
    "        conflict_cols = ['Action', 'Asset', 'IdealQuantity', 'IdealValueUSDT', 'ConflictType', 'BlockingOrderIDs']\n",
    "        # Ensure columns exist before selecting\n",
    "        conflict_cols = [c for c in conflict_cols if c in feasible_trades_df.columns]\n",
    "        with pd.option_context('display.max_colwidth', 100, 'display.float_format', '{:.8f}'.format): # Show more of list/quantity\n",
    "             print(feasible_trades_df[~feasible_trades_df['Feasible']][conflict_cols])\n",
    "\n",
    "    # Result: 'feasible_trades_df' DataFrame contains original trades plus feasibility status and conflict info.\n",
    "    print(f\"\\n✅ Feasibility check complete. Results stored in 'feasible_trades_df'.\")\n",
    "\n",
    "# Ensure dataframe exists even if skipped\n",
    "if 'feasible_trades_df' not in locals():\n",
    "     feasible_trades_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e9a1b947-c50f-4e0d-b4c1-d8904fb48518",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Configuring LLM (Google AI) ---\n",
      "✅ Google AI configured.\n",
      "\n",
      "--- Performing Enhanced LLM Assessment (gemini-1.5-flash-latest) ---\n",
      "Assessing 9 trade proposals...\n",
      "  Assessing SELL BTC...\n",
      "    LLM Recommendation: SKIP\n",
      "  Assessing SELL USDT...\n",
      "    Skipping LLM: Market state not found for USDTUSDT.\n",
      "  Assessing BUY ADA...\n",
      "    LLM Recommendation: CANCEL_BLOCKERS\n",
      "  Assessing BUY DOGE...\n",
      "    LLM Recommendation: CANCEL_BLOCKERS\n",
      "  Assessing BUY ETH...\n",
      "    LLM Recommendation: SKIP\n",
      "  Assessing BUY HBAR...\n",
      "    LLM Recommendation: SKIP\n",
      "  Assessing BUY LTC...\n",
      "    LLM Recommendation: CANCEL_BLOCKERS\n",
      "  Assessing BUY SOL...\n",
      "    LLM Recommendation: CANCEL_BLOCKERS\n",
      "  Assessing BUY XRP...\n",
      "    LLM Recommendation: CANCEL_BLOCKERS\n",
      "\n",
      "--- LLM Assessment Summary ---\n",
      "  Action Asset                  IdealValueUSDT  Feasible  \\\n",
      "0   SELL   BTC   2.611459875111559997139675196     False   \n",
      "1   SELL  USDT            19.96789138676000000     False   \n",
      "2    BUY   ADA  0.9913294422981006875462582266     False   \n",
      "3    BUY  DOGE  0.8047278772068667656359017231     False   \n",
      "4    BUY   ETH   4.954104976210199004644967914     False   \n",
      "5    BUY  HBAR  0.9196298985080235823115699750     False   \n",
      "6    BUY   LTC  0.7169924965449780674539101721     False   \n",
      "7    BUY   SOL   2.927557523764871950244568291     False   \n",
      "8    BUY   XRP   10.63139736312359179709797877     False   \n",
      "\n",
      "                ConflictType LLM_Recommendation  \n",
      "0  Insufficient Free Balance               SKIP  \n",
      "1  Insufficient Free Balance               SKIP  \n",
      "2     Insufficient Free USDT    CANCEL_BLOCKERS  \n",
      "3     Insufficient Free USDT    CANCEL_BLOCKERS  \n",
      "4     Insufficient Free USDT               SKIP  \n",
      "5     Insufficient Free USDT               SKIP  \n",
      "6     Insufficient Free USDT    CANCEL_BLOCKERS  \n",
      "7     Insufficient Free USDT    CANCEL_BLOCKERS  \n",
      "8     Insufficient Free USDT    CANCEL_BLOCKERS  \n",
      "\n",
      "✅ LLM assessment complete. Results stored in 'llm_recommendations_df'.\n"
     ]
    }
   ],
   "source": [
    "# Cell 11: Enhanced LLM Assessment with Feasibility Context\n",
    "\n",
    "import google.generativeai as genai\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "import numpy as np\n",
    "from decimal import Decimal\n",
    "\n",
    "# --- Configuration ---\n",
    "LLM_MODEL_NAME = \"gemini-1.5-flash-latest\" # Or your preferred Gemini model\n",
    "QUOTE_ASSET = 'USDT' # Should match previous cells\n",
    "RSI_PERIOD = 14 # Ensure this matches the RSI period used in Cell 5/8 for key lookup\n",
    "\n",
    "# --- Load Environment Variables & Configure Google AI ---\n",
    "print(\"\\n--- Configuring LLM (Google AI) ---\")\n",
    "load_dotenv()\n",
    "google_api_key = os.environ.get('GOOGLE_API_KEY')\n",
    "genai_configured = False\n",
    "if not google_api_key:\n",
    "    print(\"⚠️ Warning: GOOGLE_API_KEY not found. LLM assessment will be skipped.\")\n",
    "else:\n",
    "    try:\n",
    "        genai.configure(api_key=google_api_key)\n",
    "        genai_configured = True\n",
    "        print(\"✅ Google AI configured.\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error configuring Google AI: {e}\")\n",
    "\n",
    "# --- Check Prerequisites ---\n",
    "if not genai_configured:\n",
    "     print(\"LLM not configured, skipping assessment.\")\n",
    "     # If LLM is skipped, create an empty DataFrame to avoid errors later\n",
    "     llm_recommendations_df = pd.DataFrame()\n",
    "elif 'feasible_trades_df' not in locals() or feasible_trades_df.empty:\n",
    "    print(\"\\nNo feasible/conflicting trades found in 'feasible_trades_df' to assess. Skipping LLM.\")\n",
    "    llm_recommendations_df = pd.DataFrame() # Ensure variable exists and is empty\n",
    "elif 'full_market_state' not in locals() or not full_market_state:\n",
    "     raise ValueError(\"Market state analysis ('full_market_state') not found or empty. Run Cell 8.\")\n",
    "else:\n",
    "    print(f\"\\n--- Performing Enhanced LLM Assessment ({LLM_MODEL_NAME}) ---\")\n",
    "\n",
    "    # --- LLM Interaction Function (Modified) ---\n",
    "    def get_llm_trade_assessment_enhanced(trade_info, symbol_state):\n",
    "        \"\"\"\n",
    "        Generates a prompt including feasibility and asks LLM for nuanced recommendation.\n",
    "        \"\"\"\n",
    "        if not genai_configured: return \"LLM_SKIP\", \"LLM Not Configured\"\n",
    "        if not symbol_state or symbol_state.get('error'): return \"ERROR\", f\"Invalid Symbol State Input: {symbol_state.get('error', 'Unknown error')}\"\n",
    "\n",
    "        # --- Extract data safely from inputs ---\n",
    "        action = trade_info.get('Action', 'N/A')\n",
    "        asset = trade_info.get('Asset', 'N/A')\n",
    "        symbol = f\"{asset}{QUOTE_ASSET}\"\n",
    "        ideal_value_str = f\"{trade_info.get('IdealValueUSDT', Decimal('0')):,.2f}\" # Format value nicely\n",
    "        ideal_qty_str = f\"{trade_info.get('IdealQuantity', Decimal('0')):.8f}\" # Show quantity precisely\n",
    "\n",
    "        # Feasibility Info\n",
    "        is_feasible = trade_info.get('Feasible', False)\n",
    "        conflict_type = trade_info.get('ConflictType', '')\n",
    "        blocking_orders = trade_info.get('BlockingOrderIDs', [])\n",
    "\n",
    "        # TA Info - with safe defaults and formatting\n",
    "        last_close = symbol_state.get('last_close') # Should be Decimal\n",
    "        last_close_str = f\"{last_close:.4f}\" if last_close is not None else \"N/A\"\n",
    "\n",
    "        daily_trend_val = symbol_state.get('daily_trend_up')\n",
    "        daily_trend_str = 'UP' if daily_trend_val is True else 'DOWN/SIDEWAYS' if daily_trend_val is False else 'Unknown'\n",
    "\n",
    "        hourly_below_val = symbol_state.get('hourly_below_sma')\n",
    "        hourly_pos_str = 'BELOW SMA20 (Dip?)' if hourly_below_val is True else 'ABOVE SMA20' if hourly_below_val is False else 'Unknown'\n",
    "\n",
    "        rsi_key = f'last_5m_RSI_{RSI_PERIOD}' # Construct the key dynamically\n",
    "        last_rsi_val = symbol_state.get(rsi_key) # Should be Decimal\n",
    "        last_rsi_str = f\"{last_rsi_val:.2f}\" if last_rsi_val is not None else \"N/A\"\n",
    "\n",
    "        rsi_oversold_val = symbol_state.get('5m_rsi_oversold')\n",
    "        rsi_state_str = 'OVERSOLD (<30)' if rsi_oversold_val is True else 'NOT OVERSOLD' if rsi_oversold_val is False else 'Unknown'\n",
    "\n",
    "        # S/R Info - format Decimals if they exist\n",
    "        daily_sup = symbol_state.get('daily_support'); daily_res = symbol_state.get('daily_resistance')\n",
    "        hourly_sup = symbol_state.get('hourly_support'); hourly_res = symbol_state.get('hourly_resistance')\n",
    "        daily_sup_str = f\"{daily_sup:.4f}\" if daily_sup is not None else \"N/A\"\n",
    "        daily_res_str = f\"{daily_res:.4f}\" if daily_res is not None else \"N/A\"\n",
    "        hourly_sup_str = f\"{hourly_sup:.4f}\" if hourly_sup is not None else \"N/A\"\n",
    "        hourly_res_str = f\"{hourly_res:.4f}\" if hourly_res is not None else \"N/A\"\n",
    "\n",
    "        near_support_val = symbol_state.get('near_hourly_support')\n",
    "        near_support_str = 'YES' if near_support_val is True else 'NO' if near_support_val is False else 'Unknown'\n",
    "\n",
    "        # --- Construct Feasibility Statement ---\n",
    "        if is_feasible:\n",
    "            feasibility_str = f\"This {action} trade appears **FEASIBLE** based on current free balances.\"\n",
    "        else:\n",
    "            feasibility_str = f\"This {action} trade is **CONFLICTING**: {conflict_type}.\"\n",
    "            if blocking_orders:\n",
    "                feasibility_str += f\" Potentially blocked by open order(s): {blocking_orders}.\"\n",
    "\n",
    "        # --- Construct Prompt ---\n",
    "        prompt = f\"\"\"\n",
    "        Analyze the following cryptocurrency market state and proposed rebalancing trade for {symbol}.\n",
    "        My goal is long-term portfolio growth via dynamic allocation. I prefer maker orders and buying dips.\n",
    "\n",
    "        PROPOSED TRADE:\n",
    "        * Action: {action}\n",
    "        * Asset: {asset}\n",
    "        * Ideal Quantity: {ideal_qty_str}\n",
    "        * Ideal Value: approx ${ideal_value_str} {QUOTE_ASSET}\n",
    "        * Feasibility: {feasibility_str}\n",
    "\n",
    "        CURRENT TECHNICAL STATE ({symbol}):\n",
    "        * Last Hourly Close: {last_close_str} {QUOTE_ASSET}\n",
    "        * Daily Trend (vs SMA50): {daily_trend_str}\n",
    "        * Hourly Position (vs SMA20): {hourly_pos_str}\n",
    "        * 5min RSI ({RSI_PERIOD}) State: {rsi_state_str} (Value: {last_rsi_str})\n",
    "        * Recent Daily Support / Resistance: {daily_sup_str} / {daily_res_str}\n",
    "        * Recent Hourly Support / Resistance: {hourly_sup_str} / {hourly_res_str}\n",
    "        * Price Near Hourly Support (within {NEAR_SUPPORT_PROXIMITY_PCT}%): {near_support_str}\n",
    "\n",
    "        ASSESSMENT TASK:\n",
    "        Based *only* on the technical state and feasibility provided:\n",
    "        1. Assess the technical picture (e.g., Is it a good dip buy? Is downside likely? Is there reason to delay a sell?).\n",
    "        2. Consider the feasibility/conflict information.\n",
    "        3. Provide a brief rationale (1-2 sentences).\n",
    "        4. Conclude with ONE of the following specific recommendations:\n",
    "           - PROCEED (If technically reasonable AND feasible)\n",
    "           - HOLD (If technically unclear/risky, or if waiting seems prudent)\n",
    "           - MODIFY_SIZE (If technically okay but maybe quantity is too large, or feasible amount is smaller)\n",
    "           - CANCEL_BLOCKERS (If technically okay but blocked by specific orders you might want to cancel)\n",
    "           - SKIP (If technically poor setup or unresolvable conflict)\n",
    "\n",
    "        Example Output:\n",
    "        Rationale: [Your brief analysis considering TA and feasibility]. Recommendation: PROCEED\n",
    "        \"\"\"\n",
    "\n",
    "        # --- Call LLM API ---\n",
    "        try:\n",
    "            # print(f\"    Sending prompt to Gemini for {symbol} {action}...\") # Uncomment for debug\n",
    "            model = genai.GenerativeModel(LLM_MODEL_NAME)\n",
    "            # Configure safety settings to be less restrictive if needed, use with caution\n",
    "            safety_settings=[ {\"category\": c, \"threshold\": \"BLOCK_NONE\"} for c in [\n",
    "                \"HARM_CATEGORY_HARASSMENT\", \"HARM_CATEGORY_HATE_SPEECH\",\n",
    "                \"HARM_CATEGORY_SEXUALLY_EXPLICIT\", \"HARM_CATEGORY_DANGEROUS_CONTENT\", ] ]\n",
    "\n",
    "            response = model.generate_content(prompt, safety_settings=safety_settings)\n",
    "\n",
    "            # Handle potential blocks or empty responses\n",
    "            if not response.candidates or (response.prompt_feedback and response.prompt_feedback.block_reason):\n",
    "                reason = response.prompt_feedback.block_reason if response.prompt_feedback else \"Unknown\"\n",
    "                print(f\"    LLM WARNING for {symbol}: Prompt/Response BLOCKED: {reason}\")\n",
    "                return \"ERROR\", f\"LLM Response Blocked: {reason}\"\n",
    "\n",
    "            raw_text = response.text.strip()\n",
    "            # print(f\"    LLM Raw Response: {raw_text}\") # Uncomment for debug\n",
    "\n",
    "            # --- Parse Recommendation ---\n",
    "            # Look for the recommendation keyword at the end or after \"Recommendation:\"\n",
    "            recommendation = \"HOLD\" # Default if parsing fails\n",
    "            keywords = [\"PROCEED\", \"HOLD\", \"MODIFY_SIZE\", \"CANCEL_BLOCKERS\", \"SKIP\"]\n",
    "            lower_text = raw_text.lower()\n",
    "            # Find the last occurrence of \"recommendation:\"\n",
    "            rec_marker = lower_text.rfind(\"recommendation:\")\n",
    "            search_area = lower_text[rec_marker:] if rec_marker != -1 else lower_text\n",
    "\n",
    "            found_rec = None\n",
    "            # Check from longest keyword to shortest to avoid partial matches if possible\n",
    "            for keyword in sorted(keywords, key=len, reverse=True):\n",
    "                if keyword.lower() in search_area.split()[-2:]: # Check last few words\n",
    "                    found_rec = keyword\n",
    "                    break\n",
    "            if found_rec:\n",
    "                 recommendation = found_rec\n",
    "\n",
    "            return recommendation, raw_text # Return parsed recommendation and full text\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"    ❌ Error calling/parsing LLM for {symbol}: {e}\")\n",
    "            return \"ERROR\", f\"LLM API Error: {e}\"\n",
    "\n",
    "    # --- Iterate Through Trades and Get Assessments ---\n",
    "    llm_results = []\n",
    "    print(f\"Assessing {len(feasible_trades_df)} trade proposals...\")\n",
    "    for index, trade in feasible_trades_df.iterrows():\n",
    "        symbol_ws = f\"{trade['Asset']}{QUOTE_ASSET}\"\n",
    "        asset_state = full_market_state.get(symbol_ws) # Get TA state\n",
    "\n",
    "        print(f\"  Assessing {trade['Action']} {trade['Asset']}...\")\n",
    "\n",
    "        if not asset_state:\n",
    "             print(f\"    Skipping LLM: Market state not found for {symbol_ws}.\")\n",
    "             rec = \"SKIP\"\n",
    "             reason = \"Missing market state data\"\n",
    "        elif asset_state.get('error'):\n",
    "             print(f\"    Skipping LLM: Error in market state for {symbol_ws}: {asset_state['error']}\")\n",
    "             rec = \"SKIP\"\n",
    "             reason = f\"Market state error: {asset_state['error']}\"\n",
    "        else:\n",
    "            # Call the enhanced function\n",
    "            rec, reason = get_llm_trade_assessment_enhanced(trade.to_dict(), asset_state)\n",
    "            print(f\"    LLM Recommendation: {rec}\")\n",
    "            # if rec == 'ERROR': print(f\"      LLM Reason/Error: {reason}\") # Uncomment for details on errors\n",
    "\n",
    "        llm_results.append({\n",
    "            'LLM_Recommendation': rec,\n",
    "            'LLM_Rationale': reason\n",
    "        })\n",
    "\n",
    "    # --- Combine Recommendations with Trades DataFrame ---\n",
    "    llm_df = pd.DataFrame(llm_results, index=feasible_trades_df.index)\n",
    "    llm_recommendations_df = feasible_trades_df.join(llm_df)\n",
    "\n",
    "    print(\"\\n--- LLM Assessment Summary ---\")\n",
    "    print(llm_recommendations_df[['Action', 'Asset', 'IdealValueUSDT', 'Feasible', 'ConflictType', 'LLM_Recommendation']].round(2))\n",
    "    print(\"\\n✅ LLM assessment complete. Results stored in 'llm_recommendations_df'.\")\n",
    "\n",
    "\n",
    "# Ensure the final DataFrame variable exists even if LLM was skipped\n",
    "if 'llm_recommendations_df' not in locals():\n",
    "     llm_recommendations_df = pd.DataFrame()\n",
    "     print(\"\\nLLM assessment was skipped. 'llm_recommendations_df' is empty.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1f277a3c-2592-48f5-855a-fb14ceefb92b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Filtering for LLM 'PROCEED' Recommendations on Feasible Trades ---\n",
      "Out of 9 assessed trades:\n",
      "  - 0 trade(s) marked 'PROCEED' by LLM and are feasible.\n",
      "  - 9 trade(s) filtered out (HOLD, SKIP, MODIFY, CANCEL_BLOCKERS, or Not Feasible).\n",
      "\n",
      "✅ Filtering complete. No trades marked 'PROCEED' and feasible found.\n"
     ]
    }
   ],
   "source": [
    "# Cell 12: Filter for Proceedable Trades & Final Check\n",
    "\n",
    "import pandas as pd\n",
    "from decimal import Decimal # Import if needed for type checking\n",
    "\n",
    "# --- Check Prerequisites ---\n",
    "if 'llm_recommendations_df' not in locals():\n",
    "    print(\"⚠️ 'llm_recommendations_df' not found. Skipping filtering.\")\n",
    "    # Ensure final_trades_to_format exists and is empty\n",
    "    final_trades_to_format_df = pd.DataFrame()\n",
    "elif llm_recommendations_df.empty:\n",
    "    print(\"ℹ️ 'llm_recommendations_df' is empty. No trades to filter.\")\n",
    "    final_trades_to_format_df = pd.DataFrame()\n",
    "else:\n",
    "    print(\"\\n--- Filtering for LLM 'PROCEED' Recommendations on Feasible Trades ---\")\n",
    "\n",
    "    # Filter conditions:\n",
    "    # 1. LLM_Recommendation must be 'PROCEED'\n",
    "    # 2. Feasible flag must be True (already checked against free balance)\n",
    "    proceed_condition = (llm_recommendations_df['LLM_Recommendation'] == 'PROCEED')\n",
    "    feasible_condition = (llm_recommendations_df['Feasible'] == True)\n",
    "\n",
    "    final_trades_to_format_df = llm_recommendations_df[proceed_condition & feasible_condition].copy()\n",
    "\n",
    "    # --- Report Summary ---\n",
    "    original_count = len(llm_recommendations_df)\n",
    "    proceed_count = len(final_trades_to_format_df)\n",
    "    hold_skip_count = original_count - proceed_count\n",
    "\n",
    "    print(f\"Out of {original_count} assessed trades:\")\n",
    "    print(f\"  - {proceed_count} trade(s) marked 'PROCEED' by LLM and are feasible.\")\n",
    "    if hold_skip_count > 0:\n",
    "        print(f\"  - {hold_skip_count} trade(s) filtered out (HOLD, SKIP, MODIFY, CANCEL_BLOCKERS, or Not Feasible).\")\n",
    "        # Optional: Show trades not proceeding\n",
    "        # print(\"\\n--- Trades NOT Proceeding to Formatting ---\")\n",
    "        # cols = ['Action', 'Asset', 'IdealValueUSDT', 'Feasible', 'ConflictType', 'LLM_Recommendation']\n",
    "        # cols = [c for c in cols if c in llm_recommendations_df.columns]\n",
    "        # with pd.option_context('display.float_format', '{:.4f}'.format):\n",
    "        #     print(llm_recommendations_df[~(proceed_condition & feasible_condition)][cols])\n",
    "\n",
    "\n",
    "    if not final_trades_to_format_df.empty:\n",
    "        print(\"\\n--- Trades Ready for Formatting ---\")\n",
    "        # Display the trades that will proceed\n",
    "        display_cols = ['Action', 'Asset', 'IdealQuantity', 'IdealValueUSDT', 'CurrentPrice', 'LLM_Recommendation']\n",
    "         # Ensure columns exist before selecting\n",
    "        display_cols = [c for c in display_cols if c in final_trades_to_format_df.columns]\n",
    "        with pd.option_context('display.float_format', '{:.8f}'.format):\n",
    "            print(final_trades_to_format_df[display_cols])\n",
    "        print(\"\\n✅ Filtering complete. Proceedable trades stored in 'final_trades_to_format_df'.\")\n",
    "    else:\n",
    "        print(\"\\n✅ Filtering complete. No trades marked 'PROCEED' and feasible found.\")\n",
    "\n",
    "\n",
    "# Ensure the final DataFrame exists, even if empty\n",
    "if 'final_trades_to_format_df' not in locals():\n",
    "     final_trades_to_format_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7a11cb49-ea83-4166-8155-d255b3025a14",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ℹ️ 'final_trades_to_format_df' is empty. No trades to format.\n",
      "\n",
      "--- Final LIMIT Orders Ready for Testing ---\n",
      "No trades were formatted (list is empty).\n"
     ]
    }
   ],
   "source": [
    "# Cell 13: Format Proceedable Trades as LIMIT Orders (Maker Strategy)\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from binance.client import Client\n",
    "from dotenv import load_dotenv\n",
    "from decimal import Decimal, ROUND_DOWN # Import Decimal for precision handling\n",
    "import json\n",
    "\n",
    "# --- Configuration ---\n",
    "QUOTE_ASSET = 'USDT'\n",
    "# Maker strategy: Place BUY orders at the best bid, SELL orders at the best ask\n",
    "# This aims to *add* liquidity and potentially get maker fees.\n",
    "PLACE_BUY_AT = 'BID' # Or 'ASK'\n",
    "PLACE_SELL_AT = 'ASK' # Or 'BID'\n",
    "\n",
    "# --- Check Prerequisites ---\n",
    "if 'client' not in locals() or client is None:\n",
    "    raise RuntimeError(\"Binance client not initialized. Run Cell 1.\")\n",
    "if 'format_price_correctly' not in locals() or 'adjust_quantity_to_step' not in locals():\n",
    "     raise RuntimeError(\"Formatting helper functions not defined. Run Cell 1.\")\n",
    "if 'final_trades_to_format_df' not in locals():\n",
    "    print(\"⚠️ 'final_trades_to_format_df' not found. Skipping order formatting.\")\n",
    "    final_limit_orders_to_test = [] # Ensure list exists\n",
    "elif final_trades_to_format_df.empty:\n",
    "    print(\"ℹ️ 'final_trades_to_format_df' is empty. No trades to format.\")\n",
    "    final_limit_orders_to_test = [] # Ensure list exists\n",
    "else:\n",
    "    print(\"\\n--- Formatting Proceedable Trades into LIMIT Orders (Maker Strategy) ---\")\n",
    "    print(f\"BUY orders target: {PLACE_BUY_AT}, SELL orders target: {PLACE_SELL_AT}\")\n",
    "\n",
    "    # --- Get Exchange Info ---\n",
    "    print(\"Fetching exchange information...\")\n",
    "    symbols_info = None\n",
    "    try:\n",
    "        exchange_info = client.get_exchange_info()\n",
    "        symbols_info = {item['symbol']: item for item in exchange_info['symbols']}\n",
    "        print(\"✅ Exchange information received.\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error fetching exchange info: {e}. Cannot format orders.\")\n",
    "\n",
    "    final_limit_orders_to_test = [] # List to hold final order parameter dictionaries\n",
    "\n",
    "    if symbols_info: # Proceed only if we have exchange rules\n",
    "        # Iterate through the DataFrame of trades ready for formatting\n",
    "        for index, trade in final_trades_to_format_df.iterrows():\n",
    "            action = trade['Action'] # 'BUY' or 'SELL'\n",
    "            asset = trade['Asset']\n",
    "            # Use the IdealQuantity calculated earlier (should be Decimal)\n",
    "            quantity_ideal = trade['IdealQuantity']\n",
    "\n",
    "            if asset == QUOTE_ASSET: continue # Skip trades involving only the quote asset\n",
    "\n",
    "            symbol = f\"{asset}{QUOTE_ASSET}\"\n",
    "            print(f\"\\nProcessing Trade {index+1}: {action} {asset} ({symbol})\")\n",
    "            print(f\"  Ideal Quantity (approx): {quantity_ideal:.8f}\")\n",
    "\n",
    "            if symbol not in symbols_info:\n",
    "                print(f\"  ⚠️ Warning: Symbol {symbol} not found in exchange info. Skipping.\")\n",
    "                continue\n",
    "\n",
    "            symbol_info = symbols_info[symbol]\n",
    "            filters = {f['filterType']: f for f in symbol_info['filters']}\n",
    "\n",
    "            # --- Get Order Book for Maker Price ---\n",
    "            best_bid = None\n",
    "            best_ask = None\n",
    "            try:\n",
    "                 depth = client.get_order_book(symbol=symbol, limit=5)\n",
    "                 if depth['bids'] and depth['asks']:\n",
    "                      best_bid = Decimal(depth['bids'][0][0])\n",
    "                      best_ask = Decimal(depth['asks'][0][0])\n",
    "                      # print(f\"  Best Bid: {best_bid}, Best Ask: {best_ask}\") # Uncomment for debug\n",
    "                 else:\n",
    "                      print(f\"  ⚠️ Warning: Order book empty/invalid for {symbol}. Skipping.\")\n",
    "                      continue\n",
    "            except Exception as e:\n",
    "                 print(f\"  ⚠️ Warning: Could not fetch order book for {symbol}: {e}. Skipping.\")\n",
    "                 continue\n",
    "\n",
    "            # --- Determine Target Limit Price (Raw Decimal) based on strategy ---\n",
    "            if action == 'BUY':\n",
    "                 limit_price_raw = best_bid if PLACE_BUY_AT == 'BID' else best_ask\n",
    "                 print(f\"  Targeting BUY Limit Price at {PLACE_BUY_AT}: {limit_price_raw}\")\n",
    "            elif action == 'SELL':\n",
    "                 limit_price_raw = best_ask if PLACE_SELL_AT == 'ASK' else best_bid\n",
    "                 print(f\"  Targeting SELL Limit Price at {PLACE_SELL_AT}: {limit_price_raw}\")\n",
    "            else: # Should not happen\n",
    "                 print(f\"  ⚠️ Unknown action '{action}'. Skipping.\")\n",
    "                 continue\n",
    "\n",
    "\n",
    "            # --- Get Filters & Adjust Price/Qty using Helper Functions ---\n",
    "            price_filter = filters.get('PRICE_FILTER', {})\n",
    "            lot_size_filter = filters.get('LOT_SIZE', {})\n",
    "            # Use NOTIONAL first, fallback to MIN_NOTIONAL\n",
    "            notional_filter = filters.get('NOTIONAL', {})\n",
    "            min_notional_str = notional_filter.get('minNotional')\n",
    "            if min_notional_str is None:\n",
    "                min_notional_filter = filters.get('MIN_NOTIONAL', {})\n",
    "                min_notional_str = min_notional_filter.get('minNotional', '0.0')\n",
    "\n",
    "            tick_size = price_filter.get('tickSize')\n",
    "            step_size = lot_size_filter.get('stepSize')\n",
    "\n",
    "            if not tick_size or not step_size or min_notional_str is None:\n",
    "                print(f\"  ⚠️ Warning: Missing critical filter info for {symbol}. Skipping.\")\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                 min_notional = Decimal(min_notional_str)\n",
    "            except Exception as dec_err:\n",
    "                 print(f\"  ⚠️ Warning: Invalid minNotional '{min_notional_str}': {dec_err}. Skipping.\")\n",
    "                 continue\n",
    "\n",
    "            # Apply formatting using Helper Functions from Cell 1\n",
    "            # These MUST return strings formatted to the exact required precision\n",
    "            try:\n",
    "                # Price formatting (e.g., using tickSize)\n",
    "                adjusted_limit_price_str = format_price_correctly(limit_price_raw, tick_size)\n",
    "                # Quantity formatting (using stepSize)\n",
    "                adjusted_quantity_str = adjust_quantity_to_step(quantity_ideal, step_size)\n",
    "\n",
    "                # Convert back to Decimal ONLY for the notional value check\n",
    "                adjusted_limit_price_dec = Decimal(adjusted_limit_price_str)\n",
    "                adjusted_quantity_dec = Decimal(adjusted_quantity_str)\n",
    "\n",
    "                print(f\"  Formatted Price Str: {adjusted_limit_price_str}\")\n",
    "                print(f\"  Adjusted Quantity Str: {adjusted_quantity_str}\")\n",
    "\n",
    "            except Exception as fmt_err:\n",
    "                 print(f\"  ❌ Error during price/quantity formatting: {fmt_err}. Skipping.\")\n",
    "                 continue\n",
    "\n",
    "            # --- Check Adjusted Quantity & MIN_NOTIONAL ---\n",
    "            if adjusted_quantity_dec <= 0:\n",
    "                 print(f\"  ⚠️ Adjusted quantity ({adjusted_quantity_dec}) is zero or less after applying step size. Skipping.\")\n",
    "                 continue\n",
    "\n",
    "            order_value = adjusted_quantity_dec * adjusted_limit_price_dec\n",
    "\n",
    "            if min_notional > 0 and order_value < min_notional:\n",
    "                 print(f\"  ⚠️ Order value ({order_value:.8f}) is below minimum notional ({min_notional:.8f}). Skipping.\")\n",
    "                 continue\n",
    "\n",
    "            print(f\"  ✅ Order meets minimum notional ({order_value:.8f} >= {min_notional:.8f}).\")\n",
    "\n",
    "            # --- Add Validated Order Parameters to List ---\n",
    "            final_limit_orders_to_test.append({\n",
    "                'symbol': symbol,\n",
    "                'side': action.upper(), # Ensure 'BUY' or 'SELL'\n",
    "                'type': 'LIMIT',\n",
    "                'timeInForce': 'GTC', # Good Till Cancelled\n",
    "                'quantity': adjusted_quantity_str, # Pass the FORMATTED STRING\n",
    "                'price': adjusted_limit_price_str   # Pass the FORMATTED STRING\n",
    "            })\n",
    "            print(f\"  ✅ Added valid LIMIT order parameters for {symbol} to list.\")\n",
    "        # End of loop through trades\n",
    "    else:\n",
    "        # This case handles if symbols_info was None due to API error\n",
    "        print(\"Skipping order formatting because exchange info could not be fetched.\")\n",
    "\n",
    "\n",
    "# --- Display Final Orders Prepared for Testing ---\n",
    "print(\"\\n--- Final LIMIT Orders Ready for Testing ---\")\n",
    "if not final_limit_orders_to_test:\n",
    "    print(\"No trades were formatted (list is empty).\")\n",
    "else:\n",
    "    # Create DataFrame for display\n",
    "    final_orders_preview_df = pd.DataFrame(final_limit_orders_to_test)\n",
    "    # Display relevant columns\n",
    "    print(final_orders_preview_df[['symbol', 'side', 'type', 'timeInForce', 'quantity', 'price']])\n",
    "    print(f\"\\nStored {len(final_limit_orders_to_test)} order(s) in 'final_limit_orders_to_test'.\")\n",
    "\n",
    "\n",
    "# Ensure list exists, even if empty\n",
    "if 'final_limit_orders_to_test' not in locals():\n",
    "     final_limit_orders_to_test = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1c2f9118-c647-4188-a0ef-498cd2e27de2",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ℹ️ No formatted orders in 'final_limit_orders_to_test'. Skipping test orders.\n"
     ]
    }
   ],
   "source": [
    "# Cell 14: Test Final LIMIT Orders (Simulation)\n",
    "\n",
    "import pandas as pd # Only needed if displaying results from non-empty list\n",
    "\n",
    "# --- Check Prerequisites ---\n",
    "if 'client' not in locals() or client is None:\n",
    "     raise RuntimeError(\"Binance client not initialized. Run Cell 1.\")\n",
    "if 'final_limit_orders_to_test' not in locals():\n",
    "     print(\"⚠️ 'final_limit_orders_to_test' list not found. Cannot test orders.\")\n",
    "elif not final_limit_orders_to_test: # Check if the list is empty\n",
    "     print(\"ℹ️ No formatted orders in 'final_limit_orders_to_test'. Skipping test orders.\")\n",
    "else:\n",
    "    # This block will only execute if final_limit_orders_to_test is NOT empty\n",
    "    print(\"\\n--- Sending FINAL LIMIT Test Orders (Simulation - No Real Trades) ---\")\n",
    "\n",
    "    successful_tests = 0\n",
    "    failed_tests = 0\n",
    "    test_results = [] # Store results for review\n",
    "\n",
    "    for order_params in final_limit_orders_to_test:\n",
    "        print(f\"Attempting TEST {order_params['side']} for {order_params['quantity']} {order_params['symbol']} at price {order_params['price']}...\")\n",
    "        result = {}\n",
    "        try:\n",
    "            # create_test_order should return an empty dict {} on success\n",
    "            test_result = client.create_test_order(\n",
    "                symbol=order_params['symbol'],\n",
    "                side=order_params['side'],\n",
    "                type=order_params['type'],\n",
    "                timeInForce=order_params['timeInForce'],\n",
    "                quantity=order_params['quantity'], # Pass the formatted string\n",
    "                price=order_params['price']         # Pass the formatted string\n",
    "            )\n",
    "            # Binance test order success is indicated by an empty dictionary response\n",
    "            if isinstance(test_result, dict) and not test_result:\n",
    "                print(f\"  ✅ SUCCESS: Test order for {order_params['symbol']} validated.\")\n",
    "                result = {**order_params, 'test_status': 'Success', 'error': None}\n",
    "                successful_tests += 1\n",
    "            else:\n",
    "                # Should not happen on successful test, indicates unexpected API behavior\n",
    "                print(f\"  ⚠️ UNEXPECTED RESULT (Expected empty dict): {test_result}\")\n",
    "                result = {**order_params, 'test_status': 'Failed', 'error': f'Unexpected Result: {test_result}'}\n",
    "                failed_tests += 1\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"  ❌ FAILED: Test order for {order_params['symbol']} failed validation.\")\n",
    "            print(f\"     Error: {e}\")\n",
    "            result = {**order_params, 'test_status': 'Failed', 'error': str(e)}\n",
    "            failed_tests += 1\n",
    "        test_results.append(result)\n",
    "\n",
    "    print(\"\\n--- FINAL LIMIT Test Order Summary ---\")\n",
    "    print(f\"Attempted Tests: {len(final_limit_orders_to_test)}\")\n",
    "    print(f\"Successful Validations: {successful_tests}\")\n",
    "    print(f\"Failed Validations    : {failed_tests}\")\n",
    "\n",
    "    if failed_tests > 0:\n",
    "        print(\"\\n--- Failed Test Order Details ---\")\n",
    "        failed_df = pd.DataFrame([r for r in test_results if r['test_status'] == 'Failed'])\n",
    "        print(failed_df[['symbol', 'side', 'quantity', 'price', 'error']])\n",
    "        print(\"\\nReview failed test orders before proceeding to real execution.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9390ca7d-1e8d-4674-a881-1c445a44a9be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ℹ️ No formatted orders passed testing. Skipping real order execution.\n"
     ]
    }
   ],
   "source": [
    "# Cell 15: Execute REAL Formatted Orders (CAUTION!)\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "import time # For potential delays or confirmation pauses\n",
    "\n",
    "# --- Configuration ---\n",
    "EXECUTE_REAL_ORDERS = True # <<< MASTER SAFETY SWITCH. Set to False to prevent execution.\n",
    "REQUIRE_CONFIRMATION = True # Set to True to require manual 'yes' input before executing.\n",
    "\n",
    "# --- Check Prerequisites ---\n",
    "if not EXECUTE_REAL_ORDERS:\n",
    "    print(\"--- REAL ORDER EXECUTION IS DISABLED (EXECUTE_REAL_ORDERS = False) ---\")\n",
    "    executed_orders_info = [] # Ensure list exists\n",
    "    failed_orders_exec = [] # Ensure list exists\n",
    "elif 'client' not in locals() or client is None:\n",
    "     raise RuntimeError(\"Binance client not initialized. Run Cell 1.\")\n",
    "elif 'final_limit_orders_to_test' not in locals():\n",
    "     print(\"⚠️ 'final_limit_orders_to_test' list not found. Cannot execute.\")\n",
    "     executed_orders_info = []\n",
    "     failed_orders_exec = []\n",
    "elif not final_limit_orders_to_test: # Check if the list is empty\n",
    "     print(\"ℹ️ No formatted orders passed testing. Skipping real order execution.\")\n",
    "     executed_orders_info = []\n",
    "     failed_orders_exec = []\n",
    "else:\n",
    "    # --- Safety Confirmation ---\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\" !!! WARNING: ABOUT TO EXECUTE REAL ORDERS !!!\")\n",
    "    print(\"=\"*50)\n",
    "    print(\"The following orders passed formatting and testing:\")\n",
    "    orders_to_exec_df = pd.DataFrame(final_limit_orders_to_test)\n",
    "    print(orders_to_exec_df[['symbol', 'side', 'type', 'quantity', 'price']])\n",
    "    print(f\"\\nTotal orders to execute: {len(orders_to_exec_df)}\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "    proceed = False\n",
    "    if REQUIRE_CONFIRMATION:\n",
    "        try:\n",
    "            # Use input() which works in notebooks\n",
    "            confirm = input(\"Type 'yes' to confirm and execute these orders: \")\n",
    "            if confirm.lower() == 'yes':\n",
    "                proceed = True\n",
    "                print(\"Confirmation received. Proceeding with execution...\")\n",
    "            else:\n",
    "                print(\"Confirmation not received. EXECUTION CANCELLED.\")\n",
    "        except EOFError:\n",
    "             # Handle environments where input() might not work (e.g., non-interactive execution)\n",
    "             print(\"Could not get confirmation (EOFError). EXECUTION CANCELLED.\")\n",
    "    else:\n",
    "        print(\"Skipping manual confirmation (REQUIRE_CONFIRMATION = False).\")\n",
    "        proceed = True # Proceed without manual input if flag is False\n",
    "\n",
    "    # --- Execute Orders if Confirmed ---\n",
    "    executed_orders_info = [] # List to store results of successful orders\n",
    "    failed_orders_exec = []   # List to store parameters and errors of failed orders\n",
    "\n",
    "    if proceed:\n",
    "        print(\"\\n--- Sending REAL LIMIT Orders ---\")\n",
    "        for order_params in final_limit_orders_to_test:\n",
    "            print(f\"\\nAttempting REAL {order_params['side']} {order_params['type']} for {order_params['quantity']} {order_params['symbol']} at {order_params['price']}...\")\n",
    "            try:\n",
    "                # --- THE ACTUAL LIVE ORDER PLACEMENT ---\n",
    "                order_result = client.create_order(\n",
    "                    symbol=order_params['symbol'],\n",
    "                    side=order_params['side'],\n",
    "                    type=order_params['type'],      # LIMIT\n",
    "                    timeInForce=order_params['timeInForce'], # GTC\n",
    "                    quantity=order_params['quantity'], # Formatted string\n",
    "                    price=order_params['price']      # Formatted string\n",
    "                )\n",
    "                # --- ORDER PLACED SUCCESSFULLY ---\n",
    "\n",
    "                print(f\"  ✅ SUCCESS: Order for {order_params['symbol']} PLACED.\")\n",
    "                print(f\"     Order ID: {order_result.get('orderId', 'N/A')}\")\n",
    "                # print(\"     Full Result:\") # Uncomment for more detail\n",
    "                # print(json.dumps(order_result, indent=4)) # Pretty print result\n",
    "                executed_orders_info.append(order_result)\n",
    "                time.sleep(0.5) # Small delay between orders to avoid rate limits\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"  ❌ FAILED: Order placement for {order_params['symbol']} failed.\")\n",
    "                print(f\"     Error: {e}\")\n",
    "                failed_orders_exec.append({**order_params, 'error': str(e)})\n",
    "\n",
    "        # --- Execution Summary ---\n",
    "        print(\"\\n--- Real Order Execution Summary ---\")\n",
    "        print(f\"Successfully placed orders: {len(executed_orders_info)}\")\n",
    "        print(f\"Failed orders           : {len(failed_orders_exec)}\")\n",
    "\n",
    "        if failed_orders_exec:\n",
    "            print(\"\\n--- Failed Order Details ---\")\n",
    "            failed_exec_df = pd.DataFrame(failed_orders_exec)\n",
    "            print(failed_exec_df[['symbol', 'side', 'quantity', 'price', 'error']])\n",
    "            print(\"\\nReview failed orders and account status.\")\n",
    "        elif executed_orders_info:\n",
    "             print(\"\\nCheck order status using Cell 2 (Get State) or the exchange interface.\")\n",
    "\n",
    "    # End of 'if proceed:' block\n",
    "    elif not proceed and REQUIRE_CONFIRMATION:\n",
    "         # This block executes if confirmation was required but not given\n",
    "         print(\"Execution skipped due to lack of confirmation.\")\n",
    "\n",
    "\n",
    "# Ensure lists exist for potential use later, even if execution was skipped/failed\n",
    "if 'executed_orders_info' not in locals(): executed_orders_info = []\n",
    "if 'failed_orders_exec' not in locals(): failed_orders_exec = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cf262956-2ee3-4f85-8d5b-4fc07b4e2549",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Initializing Client for Comprehensive State Check ---\n",
      "✅ Binance client initialized successfully.\n",
      "Fetching account balances...\n",
      "✅ Balances fetched successfully.\n",
      "Fetching open orders...\n",
      "Fetched 5 open order(s).\n",
      "✅ Open orders fetched and processed successfully.\n",
      "\n",
      "--- Comprehensive Portfolio State Summary ---\n",
      "\n",
      "Balances (Free/Locked):\n",
      "             Free       Locked\n",
      "Asset                         \n",
      "BTC    0.00000710   0.00008000\n",
      "USDT   0.10189178  26.60000000\n",
      "BUSD   0.14956400         0E-8\n",
      "WAVES  0.01000000         0E-8\n",
      "\n",
      "Open Orders:\n",
      "    symbol     orderId  side         type status           price     origQty  \\\n",
      "0  BTCUSDT  1466046736  SELL  LIMIT_MAKER    NEW  91000.00000000  0.00004000   \n",
      "1  BTCUSDT  1466046691  SELL  LIMIT_MAKER    NEW  87000.00000000  0.00004000   \n",
      "2  BTCUSDT  1466045855   BUY  LIMIT_MAKER    NEW  50000.00000000  0.00018000   \n",
      "3  BTCUSDT  1466045747   BUY  LIMIT_MAKER    NEW  64000.00000000  0.00014000   \n",
      "4  BTCUSDT  1466045383   BUY  LIMIT_MAKER    NEW  72000.00000000  0.00012000   \n",
      "\n",
      "  executedQty                             time  \n",
      "0        0E-8 2025-04-08 14:56:09.811000+00:00  \n",
      "1        0E-8 2025-04-08 14:55:57.421000+00:00  \n",
      "2        0E-8 2025-04-08 14:54:36.094000+00:00  \n",
      "3        0E-8 2025-04-08 14:54:24.970000+00:00  \n",
      "4        0E-8 2025-04-08 14:53:47.150000+00:00  \n",
      "\n",
      "--- State captured in 'portfolio_state' dictionary ---\n"
     ]
    }
   ],
   "source": [
    "# Cell 17: Get Comprehensive Portfolio State (Balances & Open Orders)\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "from binance.client import Client\n",
    "from dotenv import load_dotenv\n",
    "from decimal import Decimal, ROUND_DOWN # Use Decimal for precision\n",
    "from datetime import datetime\n",
    "\n",
    "# --- Configuration ---\n",
    "QUOTE_ASSET = 'USDT' # Define your quote asset\n",
    "\n",
    "# --- Load API Keys and Initialize Client ---\n",
    "print(\"--- Initializing Client for Comprehensive State Check ---\")\n",
    "load_dotenv()\n",
    "api_key = os.environ.get('BINANCE_API_KEY')\n",
    "api_secret = os.environ.get('BINANCE_API_SECRET')\n",
    "client = None\n",
    "if api_key and api_secret:\n",
    "    try:\n",
    "        # Ensure tld='us' for Binance.US\n",
    "        client = Client(api_key, api_secret, tld='us')\n",
    "        client.ping()\n",
    "        print(\"✅ Binance client initialized successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error initializing Binance client: {e}\")\n",
    "        client = None\n",
    "else:\n",
    "    print(\"❌ API Key or Secret not found.\")\n",
    "    client = None\n",
    "\n",
    "# --- Function to Get Balances (using Decimal) ---\n",
    "def get_current_balances_detailed(api_client):\n",
    "    \"\"\"\n",
    "    Fetches account balances from Binance.US, returns non-zero balances\n",
    "    as a Pandas DataFrame with Decimal types for precision.\n",
    "    \"\"\"\n",
    "    if not api_client:\n",
    "        print(\"API Client is not available for get_current_balances_detailed.\")\n",
    "        # Return DataFrame with correct columns and types\n",
    "        return pd.DataFrame(columns=['Free', 'Locked'], index=pd.Index([], name='Asset'), dtype=object)\n",
    "\n",
    "\n",
    "    try:\n",
    "        print(\"Fetching account balances...\")\n",
    "        account_info = api_client.get_account()\n",
    "        balances_raw = account_info.get('balances', [])\n",
    "\n",
    "        processed_balances = []\n",
    "        for asset_info in balances_raw:\n",
    "            # Use Decimal for precision\n",
    "            free = Decimal(asset_info['free'])\n",
    "            locked = Decimal(asset_info['locked'])\n",
    "            if free > 0 or locked > 0:\n",
    "                processed_balances.append({\n",
    "                    'Asset': asset_info['asset'],\n",
    "                    'Free': free,\n",
    "                    'Locked': locked\n",
    "                })\n",
    "\n",
    "        if not processed_balances:\n",
    "            print(\"No assets with non-zero balance found.\")\n",
    "            return pd.DataFrame(columns=['Free', 'Locked'], index=pd.Index([], name='Asset'), dtype=object)\n",
    "\n",
    "        balances_df = pd.DataFrame(processed_balances)\n",
    "        balances_df.set_index('Asset', inplace=True)\n",
    "        print(\"✅ Balances fetched successfully.\")\n",
    "        return balances_df\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error fetching account balances: {e}\")\n",
    "        return pd.DataFrame(columns=['Free', 'Locked'], index=pd.Index([], name='Asset'), dtype=object)\n",
    "\n",
    "# --- Function to Get Open Orders ---\n",
    "def get_open_orders_detailed(api_client):\n",
    "    \"\"\"\n",
    "    Fetches all open orders from Binance.US and returns them as a DataFrame.\n",
    "    \"\"\"\n",
    "    if not api_client:\n",
    "        print(\"API Client is not available for get_open_orders_detailed.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    try:\n",
    "        print(\"Fetching open orders...\")\n",
    "        open_orders_raw = api_client.get_open_orders()\n",
    "\n",
    "        if not open_orders_raw:\n",
    "            print(\"No open orders found.\")\n",
    "            return pd.DataFrame() # Return empty DataFrame if no orders\n",
    "\n",
    "        print(f\"Fetched {len(open_orders_raw)} open order(s).\")\n",
    "        open_orders_df = pd.DataFrame(open_orders_raw)\n",
    "\n",
    "        # Convert numeric columns (use Decimal where appropriate, float otherwise)\n",
    "        for col in ['price', 'origQty', 'executedQty', 'cummulativeQuoteQty', 'stopPrice']:\n",
    "            if col in open_orders_df.columns:\n",
    "                open_orders_df[col] = open_orders_df[col].apply(Decimal)\n",
    "\n",
    "        # Convert timestamp columns\n",
    "        for col in ['time', 'updateTime']:\n",
    "            if col in open_orders_df.columns:\n",
    "                open_orders_df[col] = pd.to_datetime(open_orders_df[col], unit='ms', utc=True, errors='coerce')\n",
    "\n",
    "        print(\"✅ Open orders fetched and processed successfully.\")\n",
    "        # Sort for consistency\n",
    "        return open_orders_df.sort_values(by=['symbol', 'time'], ascending=[True, False]).reset_index(drop=True)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error fetching or processing open orders: {e}\")\n",
    "        return pd.DataFrame() # Return empty DataFrame on error\n",
    "\n",
    "\n",
    "# --- Main Execution Logic for this Cell ---\n",
    "portfolio_state = {\n",
    "    \"balances\": pd.DataFrame(columns=['Free', 'Locked'], index=pd.Index([], name='Asset'), dtype=object),\n",
    "    \"open_orders\": pd.DataFrame()\n",
    "}\n",
    "\n",
    "if client:\n",
    "    portfolio_state[\"balances\"] = get_current_balances_detailed(client)\n",
    "    portfolio_state[\"open_orders\"] = get_open_orders_detailed(client)\n",
    "\n",
    "    print(\"\\n--- Comprehensive Portfolio State Summary ---\")\n",
    "\n",
    "    if not portfolio_state[\"balances\"].empty:\n",
    "        print(\"\\nBalances (Free/Locked):\")\n",
    "        # Display with appropriate formatting\n",
    "        with pd.option_context('display.float_format', '{:.8f}'.format):\n",
    "             print(portfolio_state[\"balances\"])\n",
    "    else:\n",
    "        print(\"\\nBalances: Could not be fetched or none found.\")\n",
    "\n",
    "    if not portfolio_state[\"open_orders\"].empty:\n",
    "        print(\"\\nOpen Orders:\")\n",
    "        display_cols = ['symbol', 'orderId', 'side', 'type', 'status', 'price', 'origQty', 'executedQty', 'time']\n",
    "        display_cols = [col for col in display_cols if col in portfolio_state[\"open_orders\"].columns]\n",
    "        with pd.option_context('display.float_format', '{:.8f}'.format):\n",
    "            print(portfolio_state[\"open_orders\"][display_cols])\n",
    "    else:\n",
    "        print(\"\\nOpen Orders: None found or could not be fetched.\")\n",
    "\n",
    "    print(\"\\n--- State captured in 'portfolio_state' dictionary ---\")\n",
    "\n",
    "else:\n",
    "    print(\"❌ Client not initialized. Cannot fetch portfolio state.\")\n",
    "\n",
    "# Result: 'portfolio_state' dictionary now holds two DataFrames:\n",
    "# portfolio_state['balances']: Index=Asset, Columns=['Free', 'Locked'] (Decimal)\n",
    "# portfolio_state['open_orders']: DataFrame of open orders with Decimal quantities/prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe19ec47-2a83-4056-ba53-eaa120f2738a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
