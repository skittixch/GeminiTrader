{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "533bcf60-56de-4270-88f8-751421287f0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-09 20:31:29,040 - INFO - --- Initializing Binance Client ---\n",
      "2025-04-09 20:31:29,041 - ERROR - Binance API Key or Secret Key not found in environment variables.\n",
      "2025-04-09 20:31:29,042 - ERROR - Please set BINANCE_API_KEY and BINANCE_SECRET_KEY in your environment or a .env file.\n",
      "2025-04-09 20:31:29,042 - WARNING - Binance client initialization failed. Cannot proceed with API calls.\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Initialize Binance Client for Binance.US (Revised)\n",
    "\n",
    "import os\n",
    "import logging\n",
    "from binance.client import Client\n",
    "from binance.exceptions import BinanceAPIException, BinanceRequestException\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# --- Configuration ---\n",
    "# Load environment variables from a .env file if present\n",
    "load_dotenv()\n",
    "\n",
    "# Ensure your API keys are stored securely, e.g., as environment variables\n",
    "API_KEY = os.environ.get('BINANCE_API_KEY')\n",
    "SECRET_KEY = os.environ.get('BINANCE_SECRET_KEY') # Using SECRET_KEY as in my original example, adjust if you use BINANCE_API_SECRET\n",
    "TARGET_TLD = 'us' # Use 'us' for Binance.US\n",
    "\n",
    "# Setup basic logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# --- Initialize Client ---\n",
    "client = None\n",
    "logging.info(\"--- Initializing Binance Client ---\")\n",
    "if not API_KEY or not SECRET_KEY:\n",
    "    logging.error(\"Binance API Key or Secret Key not found in environment variables.\")\n",
    "    logging.error(\"Please set BINANCE_API_KEY and BINANCE_SECRET_KEY in your environment or a .env file.\")\n",
    "else:\n",
    "    try:\n",
    "        client = Client(API_KEY, SECRET_KEY, tld=TARGET_TLD)\n",
    "        # Test connectivity using ping\n",
    "        client.ping()\n",
    "        logging.info(f\"✅ Binance client initialized and connection verified successfully for tld='{TARGET_TLD}'.\")\n",
    "\n",
    "        # Optional: Perform a quick check to confirm account access\n",
    "        account_status = client.get_account_status()\n",
    "        logging.info(f\"Account status check: {account_status.get('data', 'N/A')}\")\n",
    "\n",
    "    except BinanceAPIException as e:\n",
    "        logging.error(f\"❌ Binance API Exception during initialization or ping: {e}\")\n",
    "        client = None # Ensure client is None if connection failed\n",
    "    except BinanceRequestException as e:\n",
    "        logging.error(f\"❌ Binance Request Exception during initialization or ping: {e}\")\n",
    "        client = None # Ensure client is None if connection failed\n",
    "    except Exception as e:\n",
    "        logging.error(f\"❌ An unexpected error occurred during client initialization: {e}\")\n",
    "        client = None # Ensure client is None if connection failed\n",
    "\n",
    "# --- Verification ---\n",
    "if client:\n",
    "    logging.info(\"Binance client is ready.\")\n",
    "else:\n",
    "    logging.warning(\"Binance client initialization failed. Cannot proceed with API calls.\")\n",
    "    # You might want to raise an error or exit here depending on your script's needs\n",
    "    # raise RuntimeError(\"Client initialization failed.\")\n",
    "\n",
    "# End of Cell 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c00ac3bc-c12e-4111-942d-d8935bbd0e2e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Initializing Binance Client ---\n",
      "✅ Binance client initialized successfully.\n",
      "⚠️ State fetching functions not found in local scope, defining them now...\n",
      "\n",
      "--- Fetching Comprehensive Portfolio State ---\n",
      "\n",
      "--- Portfolio State Summary ---\n",
      "Balances (Free/Locked):\n",
      "             Free      Locked\n",
      "Asset                        \n",
      "BTC    0.00005710  0.00000000\n",
      "ETH    0.00318720  0.00000000\n",
      "XRP    5.97600000  0.00000000\n",
      "USDT   8.96644535  0.00000000\n",
      "ADA    1.99200000  0.00000000\n",
      "BUSD   0.14956400  0.00000000\n",
      "WAVES  0.01000000  0.00000000\n",
      "SOL    0.02988000  0.00000000\n",
      "\n",
      "Open Orders: None found or error fetching.\n",
      "\n",
      "✅ State captured in 'portfolio_state' dictionary.\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Initialize Client & Get Comprehensive Portfolio State\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "from binance.client import Client\n",
    "from dotenv import load_dotenv\n",
    "from decimal import Decimal, ROUND_DOWN # Use Decimal for precision\n",
    "from datetime import datetime, timezone # Import timezone\n",
    "import warnings\n",
    "\n",
    "# Suppress specific Pandas warnings if desired, use cautiously\n",
    "# warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# --- Configuration ---\n",
    "QUOTE_ASSET = 'USDT' # Define your quote asset\n",
    "DISPLAY_PRECISION = 8 # How many decimal places to show in output\n",
    "\n",
    "# --- Initialize Binance Client ---\n",
    "print(\"--- Initializing Binance Client ---\")\n",
    "load_dotenv()\n",
    "api_key = os.environ.get('BINANCE_API_KEY')\n",
    "api_secret = os.environ.get('BINANCE_API_SECRET')\n",
    "client = None\n",
    "if api_key and api_secret:\n",
    "    try:\n",
    "        # Ensure tld='us' for Binance.US\n",
    "        client = Client(api_key, api_secret, tld='us')\n",
    "        client.ping()\n",
    "        print(\"✅ Binance client initialized successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error initializing Binance client: {e}\")\n",
    "        # Stop execution if client fails to initialize\n",
    "        raise RuntimeError(f\"Client initialization failed: {e}\")\n",
    "else:\n",
    "    # Stop execution if keys are missing\n",
    "    raise ValueError(\"❌ API Key or Secret not found in environment variables.\")\n",
    "\n",
    "# --- State Fetching Functions (Define or Verify from Cell 1) ---\n",
    "# These functions should ideally be defined in Cell 1. We check for their existence.\n",
    "# If Cell 1 only contained helpers pasted from history, we might need to define them here.\n",
    "# For now, assume they are defined correctly in Cell 1's execution context.\n",
    "if 'get_current_balances_detailed' not in locals() or 'get_open_orders_detailed' not in locals():\n",
    "    # If the functions weren't defined in Cell 1 for some reason, define them here.\n",
    "    # This provides robustness but defining in Cell 1 is cleaner.\n",
    "    print(\"⚠️ State fetching functions not found in local scope, defining them now...\")\n",
    "\n",
    "    def get_current_balances_detailed(api_client):\n",
    "        \"\"\" Fetches detailed balances using Decimal. \"\"\"\n",
    "        if not api_client: return pd.DataFrame(columns=['Free', 'Locked'], index=pd.Index([], name='Asset'), dtype=object)\n",
    "        try:\n",
    "            account_info = api_client.get_account(); balances_raw = account_info.get('balances', [])\n",
    "            processed = [{'Asset':i['asset'],'Free':Decimal(i['free']),'Locked':Decimal(i['locked'])} for i in balances_raw if Decimal(i['free'])>0 or Decimal(i['locked'])>0]\n",
    "            if not processed: return pd.DataFrame(columns=['Free', 'Locked'], index=pd.Index([], name='Asset'), dtype=object)\n",
    "            df = pd.DataFrame(processed); df.set_index('Asset', inplace=True); return df\n",
    "        except Exception as e: print(f\"❌ Error balances: {e}\"); return pd.DataFrame(columns=['Free', 'Locked'], index=pd.Index([], name='Asset'), dtype=object)\n",
    "\n",
    "    def get_open_orders_detailed(api_client):\n",
    "        \"\"\" Fetches detailed open orders using Decimal. \"\"\"\n",
    "        if not api_client: return pd.DataFrame()\n",
    "        try:\n",
    "            orders = api_client.get_open_orders()\n",
    "            if not orders: return pd.DataFrame()\n",
    "            df = pd.DataFrame(orders)\n",
    "            for col in ['price','origQty','executedQty','cummulativeQuoteQty','stopPrice']:\n",
    "                if col in df.columns: df[col] = df[col].apply(lambda x: Decimal(str(x)) if x is not None else Decimal('0'))\n",
    "            for col in ['time','updateTime']:\n",
    "                if col in df.columns: df[col] = pd.to_datetime(df[col], unit='ms', utc=True, errors='coerce')\n",
    "            return df.sort_values(by=['symbol', 'time'], ascending=[True, False]).reset_index(drop=True)\n",
    "        except Exception as e: print(f\"❌ Error orders: {e}\"); return pd.DataFrame()\n",
    "\n",
    "\n",
    "# --- Main Execution Logic for this Cell ---\n",
    "print(\"\\n--- Fetching Comprehensive Portfolio State ---\")\n",
    "portfolio_state = {\n",
    "    \"balances\": pd.DataFrame(columns=['Free', 'Locked'], index=pd.Index([], name='Asset'), dtype=object),\n",
    "    \"open_orders\": pd.DataFrame()\n",
    "}\n",
    "\n",
    "try:\n",
    "    # Call the functions to get current state\n",
    "    portfolio_state[\"balances\"] = get_current_balances_detailed(client)\n",
    "    portfolio_state[\"open_orders\"] = get_open_orders_detailed(client)\n",
    "\n",
    "    print(\"\\n--- Portfolio State Summary ---\")\n",
    "\n",
    "    # --- Format Balances DataFrame for Display ---\n",
    "    if not portfolio_state[\"balances\"].empty:\n",
    "        print(\"Balances (Free/Locked):\")\n",
    "        balances_display_df = portfolio_state[\"balances\"].copy()\n",
    "        formatter = f'{{:.{DISPLAY_PRECISION}f}}'\n",
    "        balances_display_df['Free'] = balances_display_df['Free'].apply(lambda x: formatter.format(x) if isinstance(x, Decimal) else x)\n",
    "        balances_display_df['Locked'] = balances_display_df['Locked'].apply(lambda x: formatter.format(x) if isinstance(x, Decimal) else x)\n",
    "        print(balances_display_df)\n",
    "    else:\n",
    "        print(\"Balances: None found or error fetching.\")\n",
    "\n",
    "    # --- Format Open Orders DataFrame for Display ---\n",
    "    if not portfolio_state[\"open_orders\"].empty:\n",
    "        print(f\"\\nOpen Orders ({len(portfolio_state['open_orders'])}):\")\n",
    "        orders_display_df = portfolio_state[\"open_orders\"].copy()\n",
    "        cols_to_format = ['price', 'origQty', 'executedQty']\n",
    "        cols_to_display = ['symbol','orderId','side','type','status','price','origQty','executedQty','time']\n",
    "        cols_to_display = [c for c in cols_to_display if c in orders_display_df.columns]\n",
    "        formatter = f'{{:.{DISPLAY_PRECISION}f}}'\n",
    "        for col in cols_to_format:\n",
    "            if col in orders_display_df.columns:\n",
    "                 orders_display_df[col] = orders_display_df[col].apply(lambda x: formatter.format(x) if isinstance(x, Decimal) else x)\n",
    "        # Convert time to a more readable string format for display if needed\n",
    "        if 'time' in orders_display_df.columns:\n",
    "            orders_display_df['time_str'] = orders_display_df['time'].dt.strftime('%Y-%m-%d %H:%M:%S') # Add readable time string\n",
    "            cols_to_display.append('time_str') # Add it to display columns\n",
    "            cols_to_display.remove('time') # Remove original datetime object from display\n",
    "\n",
    "        print(orders_display_df[cols_to_display])\n",
    "    else:\n",
    "        print(\"\\nOpen Orders: None found or error fetching.\")\n",
    "\n",
    "    print(\"\\n✅ State captured in 'portfolio_state' dictionary.\")\n",
    "\n",
    "except Exception as state_fetch_error:\n",
    "     print(f\"\\n❌❌ An error occurred during state fetching: {state_fetch_error}\")\n",
    "     # Ensure portfolio_state is defined but indicates failure\n",
    "     portfolio_state = {\"balances\": pd.DataFrame(), \"open_orders\": pd.DataFrame(), \"error\": str(state_fetch_error)}\n",
    "     print(\"   Subsequent steps may fail.\")\n",
    "\n",
    "\n",
    "# Result: 'portfolio_state' dictionary holds the initial balances and open orders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90d43955-8692-42a8-bce4-d6e5acb13856",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Configuring LLM (Google AI) ---\n",
      "✅ Google AI configured successfully.\n"
     ]
    }
   ],
   "source": [
    "# Cell 3 (NEW): Configure LLM (Google AI)\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "try:\n",
    "    import google.generativeai as genai\n",
    "    google_ai_package_found = True\n",
    "except ImportError:\n",
    "    print(\"WARNING: google.generativeai package not found. Install with: pip install google-generativeai\")\n",
    "    google_ai_package_found = False\n",
    "    genai = None # Ensure genai exists but is None\n",
    "\n",
    "print(\"\\n--- Configuring LLM (Google AI) ---\")\n",
    "genai_configured = False # Default state\n",
    "\n",
    "if google_ai_package_found:\n",
    "    load_dotenv()\n",
    "    google_api_key = os.environ.get('GOOGLE_API_KEY')\n",
    "    if not google_api_key:\n",
    "        print(\"⚠️ GOOGLE_API_KEY not found in environment variables. LLM features will be skipped.\")\n",
    "    else:\n",
    "        try:\n",
    "            genai.configure(api_key=google_api_key)\n",
    "            genai_configured = True # Set flag on success\n",
    "            print(\"✅ Google AI configured successfully.\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error configuring Google AI: {e}\")\n",
    "            print(\"   LLM features will likely fail.\")\n",
    "else:\n",
    "    print(\"Skipping configuration because google-generativeai package is missing.\")\n",
    "\n",
    "# Ensure variable exists for subsequent checks\n",
    "if 'genai_configured' not in locals(): genai_configured = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a9204be-f508-42a5-b074-cb9ea3801fec",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Identifying Top 10 Assets by 24hr USDT Volume ---\n",
      "Processing 188 USDT pairs...\n",
      "Top 10 Assets (by USDT Volume): ['XRP', 'BTC', 'SOL', 'ETH', 'ADA', 'LTC', 'DOGE', 'HBAR', 'SUI', 'XLM']\n",
      "✅ Top 10 symbols identified: ['XRPUSDT', 'BTCUSDT', 'SOLUSDT', 'ETHUSDT', 'ADAUSDT', 'LTCUSDT', 'DOGEUSDT', 'HBARUSDT', 'SUIUSDT', 'XLMUSDT']\n",
      "   Volume ranking data stored in 'volume_ranking_df'.\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Identify Top N Assets by Volume\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "from decimal import Decimal # Use Decimal for price/volume if needed later\n",
    "\n",
    "# --- Configuration ---\n",
    "N = 10 # Number of top crypto assets to target\n",
    "QUOTE_ASSET_FILTER = 'USDT' # Should match QUOTE_ASSET usually\n",
    "STABLECOIN_ASSETS = ['USDT', 'USDC', 'BUSD', 'TUSD', 'USDP', 'FDUSD'] # Define stablecoins to exclude\n",
    "VOLUME_DISPLAY_PRECISION = 2 # Decimals for volume display if printing details\n",
    "\n",
    "# --- Check Prerequisites ---\n",
    "if 'client' not in locals() or client is None:\n",
    "    raise RuntimeError(\"Binance client is not initialized. Please run Cell 2 first.\")\n",
    "\n",
    "# --- Initialize ---\n",
    "top_n_assets = []\n",
    "top_n_symbols = []\n",
    "volume_ranking_df = pd.DataFrame() # Will store detailed volume info\n",
    "\n",
    "# --- Main Logic ---\n",
    "print(f\"\\n--- Identifying Top {N} Assets by 24hr {QUOTE_ASSET_FILTER} Volume ---\")\n",
    "try:\n",
    "    all_tickers = client.get_ticker() # Fetch all symbol tickers\n",
    "    # Filter for pairs ending with the quote asset (e.g., 'USDT')\n",
    "    usdt_tickers = [t for t in all_tickers if t.get('symbol', '').endswith(QUOTE_ASSET_FILTER)]\n",
    "    print(f\"Processing {len(usdt_tickers)} {QUOTE_ASSET_FILTER} pairs...\")\n",
    "\n",
    "    volume_data = []\n",
    "    for ticker in usdt_tickers:\n",
    "        symbol = ticker.get('symbol')\n",
    "        if not symbol: continue # Skip if symbol key is missing\n",
    "\n",
    "        # Derive base asset (e.g., 'BTC' from 'BTCUSDT')\n",
    "        base_asset = symbol[:-len(QUOTE_ASSET_FILTER)] # More robust than replace\n",
    "\n",
    "        # Skip if the base asset is a known stablecoin\n",
    "        if base_asset in STABLECOIN_ASSETS: continue\n",
    "\n",
    "        try:\n",
    "             # Extract quote volume and last price, convert safely to Decimal\n",
    "             volume_str = ticker.get('quoteVolume', '0.0')\n",
    "             price_str = ticker.get('lastPrice', '0.0')\n",
    "             volume = Decimal(volume_str)\n",
    "             last_price = Decimal(price_str)\n",
    "\n",
    "             # Only include assets with positive volume and price\n",
    "             if volume > 0 and last_price > 0:\n",
    "                  volume_data.append({\n",
    "                      'Asset': base_asset,\n",
    "                      'Symbol': symbol,\n",
    "                      f'Volume_{QUOTE_ASSET_FILTER}': volume, # Store as Decimal\n",
    "                      'LastPrice': last_price # Store as Decimal\n",
    "                  })\n",
    "        except Exception as e:\n",
    "             # Log ticker processing errors if needed, otherwise skip problematic tickers\n",
    "             # print(f\"  Warning: Skipping {symbol} due to data error: {e}\")\n",
    "             pass # Continue to the next ticker\n",
    "\n",
    "    if not volume_data:\n",
    "         print(\"⚠️ Warning: No valid volume data found after filtering.\")\n",
    "    else:\n",
    "         # Create DataFrame from collected data\n",
    "         volume_ranking_df = pd.DataFrame(volume_data)\n",
    "         # Sort by volume (descending)\n",
    "         volume_ranking_df.sort_values(by=f'Volume_{QUOTE_ASSET_FILTER}', ascending=False, inplace=True)\n",
    "         # Select the top N rows\n",
    "         top_n_df = volume_ranking_df.head(N)\n",
    "         # Extract asset names and symbols\n",
    "         top_n_assets = top_n_df['Asset'].tolist()\n",
    "         top_n_symbols = top_n_df['Symbol'].tolist()\n",
    "         print(f\"Top {N} Assets (by USDT Volume): {top_n_assets}\") # List print is fine\n",
    "\n",
    "         # --- Optional: Print DataFrame with Corrected Formatting ---\n",
    "         # print(f\"\\n--- Top {N} Volume Details ---\")\n",
    "         # display_format = f'{{:,.{VOLUME_DISPLAY_PRECISION}f}}' # Format with commas, fixed decimals\n",
    "         # cols_to_show = ['Asset', 'Symbol', f'Volume_{QUOTE_ASSET_FILTER}']\n",
    "         # with pd.option_context('display.float_format', display_format.format):\n",
    "         #    top_n_display = top_n_df[cols_to_show].copy()\n",
    "         #    print(top_n_display)\n",
    "         # --- End Optional Print ---\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"❌ An error occurred fetching/processing ticker data: {e}\")\n",
    "    # Reset variables to ensure clean state on error\n",
    "    top_n_assets, top_n_symbols, volume_ranking_df = [], [], pd.DataFrame()\n",
    "\n",
    "# --- Final Check ---\n",
    "if not top_n_symbols:\n",
    "    print(\"⚠️ Top N symbols list is empty. Subsequent steps might fail.\")\n",
    "    # Consider raising an error if this is critical for the strategy\n",
    "    # raise ValueError(\"Failed to identify Top N symbols.\")\n",
    "else:\n",
    "    print(f\"✅ Top {len(top_n_symbols)} symbols identified: {top_n_symbols}\")\n",
    "    print(f\"   Volume ranking data stored in 'volume_ranking_df'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d279e01-f7a1-49d1-9a16-2386ac2a5bfa",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing Kline Data for Top 10 Symbols ---\n",
      "Intervals: ['1d', '1h', '5m', '1m']. Will LOAD local first.\n",
      "✅ Kline data processing complete. Data stored in 'top_n_klines' dictionary.\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Fetch/Load Historical Data for Top N Symbols\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "from binance.client import Client # For interval constants\n",
    "from datetime import datetime, timezone # Import timezone\n",
    "\n",
    "# --- Configuration ---\n",
    "INTERVALS_TO_PROCESS = ['1d', '1h', '5m', '1m'] # Timeframes needed for analysis\n",
    "# Map user-friendly keys to Binance API constants (ensure Client is imported)\n",
    "INTERVAL_API_MAP = {\n",
    "    '1d': Client.KLINE_INTERVAL_1DAY, '1h': Client.KLINE_INTERVAL_1HOUR,\n",
    "    '5m': Client.KLINE_INTERVAL_5MINUTE, '1m': Client.KLINE_INTERVAL_1MINUTE\n",
    "}\n",
    "# Define fetch ranges using relative time strings (used if fetching fresh data)\n",
    "START_DATES_FETCH = {\n",
    "    '1d': \"90 days ago UTC\", '1h': \"7 days ago UTC\",\n",
    "    '5m': \"3 days ago UTC\", '1m': \"1 day ago UTC\"\n",
    "}\n",
    "# Define identifiers used in filenames when saving/loading CSV data\n",
    "START_DATES_SAVE_IDS = {\n",
    "    '1d': \"90_days_ago_UTC\", '1h': \"7_days_ago_UTC\",\n",
    "    '5m': \"3_days_ago_UTC\", '1m': \"1_day_ago_UTC\"\n",
    "}\n",
    "DATA_DIRECTORY = \"data\" # Subdirectory to store/load CSV files\n",
    "FORCE_FETCH_FRESH = False # Set True to always ignore local CSVs and fetch from API\n",
    "\n",
    "# --- Check Prerequisites ---\n",
    "if 'client' not in locals() or client is None:\n",
    "    raise RuntimeError(\"Binance client not initialized. Run Cell 2 first.\")\n",
    "# Ensure fetch helper function exists (should be from Cell 1)\n",
    "if 'fetch_and_process_klines' not in locals():\n",
    "     raise RuntimeError(\"Helper function 'fetch_and_process_klines' not defined. Run Cell 1.\")\n",
    "if 'top_n_symbols' not in locals() or not top_n_symbols:\n",
    "    raise ValueError(\"'top_n_symbols' list not found or empty. Run Cell 3.\")\n",
    "\n",
    "# --- Initialization ---\n",
    "top_n_klines = {} # Dictionary structure: {'SYMBOL': {'interval': DataFrame}}\n",
    "os.makedirs(DATA_DIRECTORY, exist_ok=True) # Ensure data directory exists\n",
    "fetch_errors = 0\n",
    "load_errors = 0\n",
    "save_errors = 0\n",
    "\n",
    "print(f\"\\n--- Processing Kline Data for Top {len(top_n_symbols)} Symbols ---\")\n",
    "print(f\"Intervals: {INTERVALS_TO_PROCESS}. Will {'FETCH FRESH' if FORCE_FETCH_FRESH else 'LOAD local first'}.\")\n",
    "\n",
    "# Loop through each symbol identified in Cell 3\n",
    "for symbol in top_n_symbols:\n",
    "    top_n_klines[symbol] = {} # Initialize nested dictionary for the symbol\n",
    "    symbol_fetch_errors = 0\n",
    "\n",
    "    # Loop through each required interval for the current symbol\n",
    "    for interval_key in INTERVALS_TO_PROCESS:\n",
    "        interval_value = INTERVAL_API_MAP.get(interval_key)\n",
    "        if not interval_value:\n",
    "             print(f\"  ⚠️ Skipping invalid interval key: {interval_key}\")\n",
    "             continue # Skip if interval key isn't mapped\n",
    "\n",
    "        df = None # Reset DataFrame for each interval\n",
    "        loaded_from_csv = False\n",
    "        source_msg = \"\" # To track if loaded or fetched\n",
    "\n",
    "        # --- 1. Attempt to Load from CSV ---\n",
    "        if not FORCE_FETCH_FRESH:\n",
    "            start_id = START_DATES_SAVE_IDS.get(interval_key)\n",
    "            if start_id:\n",
    "                filename = os.path.join(DATA_DIRECTORY, f\"{symbol}_{interval_key}_{start_id}.csv\")\n",
    "                if os.path.exists(filename):\n",
    "                    try:\n",
    "                        # Read CSV, set index, parse dates\n",
    "                        df = pd.read_csv(filename, index_col='Open Time', parse_dates=True)\n",
    "\n",
    "                        # Corrected Timezone Handling\n",
    "                        if df.index.tz is None:\n",
    "                            df.index = df.index.tz_localize('UTC')\n",
    "                        elif df.index.tz != timezone.utc:\n",
    "                             print(f\"  Warning: Timezone for {filename} is {df.index.tz}, converting to UTC.\")\n",
    "                             df.index = df.index.tz_convert('UTC')\n",
    "\n",
    "                        # If df is still valid after timezone check/conversion\n",
    "                        if df is not None:\n",
    "                             loaded_from_csv = True\n",
    "                             source_msg = f\"Loaded {symbol} {interval_key} from CSV.\"\n",
    "\n",
    "                    except Exception as e:\n",
    "                        print(f\"  ⚠️ Error loading {filename}: {e}. Will try fetching.\")\n",
    "                        load_errors += 1\n",
    "                        df = None # Ensure df is None if loading fails\n",
    "\n",
    "        # --- 2. Fetch Fresh if Not Loaded or if Forcing ---\n",
    "        if df is None: # Fetch if df is None (due to not existing, load error, or FORCE_FETCH_FRESH)\n",
    "            start_str = START_DATES_FETCH.get(interval_key, \"7 days ago UTC\")\n",
    "            print(f\"  Fetching {symbol} {interval_key} data starting {start_str}...\")\n",
    "            # Call the helper function defined in Cell 1\n",
    "            df = fetch_and_process_klines(client, symbol, interval_value, start_str)\n",
    "            source_msg = f\"Fetched {symbol} {interval_key} from API.\"\n",
    "\n",
    "            # --- 3. Optionally Save Freshly Fetched Data ---\n",
    "            if df is not None and not df.empty:\n",
    "                 save_id = START_DATES_SAVE_IDS.get(interval_key)\n",
    "                 if save_id:\n",
    "                      save_filename = os.path.join(DATA_DIRECTORY, f\"{symbol}_{interval_key}_{save_id}.csv\")\n",
    "                      try:\n",
    "                           df.to_csv(save_filename)\n",
    "                           source_msg += \" Saved to CSV.\"\n",
    "                      except Exception as e:\n",
    "                           print(f\"  ⚠️ Error SAVING {save_filename}: {e}\")\n",
    "                           save_errors += 1\n",
    "                 else:\n",
    "                      print(f\"  ⚠️ Cannot determine save filename for {interval_key}. Data not saved.\")\n",
    "            elif df is None: # Indicates an error during fetch/process reported by helper\n",
    "                 symbol_fetch_errors += 1\n",
    "                 source_msg += \" Fetch/Process FAILED.\"\n",
    "\n",
    "\n",
    "        # --- 4. Store the final DataFrame ---\n",
    "        if df is not None and not df.empty:\n",
    "             top_n_klines[symbol][interval_key] = df\n",
    "        elif not loaded_from_csv: # Only flag error if fetch failed\n",
    "             print(f\"  ⚠️ No data obtained or processed for {symbol} {interval_key}.\")\n",
    "\n",
    "\n",
    "    # --- End of interval loop ---\n",
    "    if symbol_fetch_errors > 0:\n",
    "        fetch_errors += symbol_fetch_errors\n",
    "\n",
    "# --- End of symbol loop ---\n",
    "\n",
    "# --- Final Summary ---\n",
    "if load_errors > 0: print(f\"⚠️ Encountered {load_errors} error(s) loading existing CSV data.\")\n",
    "if fetch_errors > 0: print(f\"⚠️ Encountered {fetch_errors} error(s) fetching/processing fresh data.\")\n",
    "if save_errors > 0: print(f\"⚠️ Encountered {save_errors} error(s) saving fetched data.\")\n",
    "\n",
    "missing_data_symbols = []\n",
    "for symbol, intervals in top_n_klines.items():\n",
    "     loaded_intervals = list(intervals.keys())\n",
    "     if len(loaded_intervals) < len(INTERVALS_TO_PROCESS):\n",
    "          missing = set(INTERVALS_TO_PROCESS) - set(loaded_intervals)\n",
    "          missing_data_symbols.append(f\"{symbol} (missing: {', '.join(missing)})\")\n",
    "if missing_data_symbols:\n",
    "     print(f\"⚠️ Symbols potentially missing required interval data: {'; '.join(missing_data_symbols)}\")\n",
    "\n",
    "print(f\"✅ Kline data processing complete. Data stored in 'top_n_klines' dictionary.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f270a29-fd54-4145-9d0b-9286a6be8d1e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Calculating Technical Indicators ---\n",
      "✅ Indicator calculation complete for all symbols and intervals.\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Calculate Technical Indicators for Top N Symbols\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np # Needed for manual calculations\n",
    "\n",
    "# --- Configuration ---\n",
    "SMA_PERIODS = [20, 50]      # Periods for Simple Moving Averages\n",
    "RSI_PERIOD = 14             # Period for Relative Strength Index\n",
    "MACD_FAST = 12              # Fast EMA period for MACD\n",
    "MACD_SLOW = 26              # Slow EMA period for MACD\n",
    "MACD_SIGNAL = 9             # Signal Line EMA period for MACD\n",
    "\n",
    "# --- Check Prerequisites ---\n",
    "if 'top_n_klines' not in locals() or not top_n_klines:\n",
    "    raise ValueError(\"'top_n_klines' dictionary not found or empty. Run Cell 4 first.\")\n",
    "\n",
    "print(\"\\n--- Calculating Technical Indicators ---\")\n",
    "calculation_errors = 0\n",
    "\n",
    "# Loop through each symbol in the main dictionary\n",
    "for symbol, interval_dict in top_n_klines.items():\n",
    "    symbol_errors = 0\n",
    "    # Loop through each interval ('1d', '1h', etc.) for the current symbol\n",
    "    for interval, df in interval_dict.items():\n",
    "        # Ensure DataFrame is not empty and has the 'Close' column needed\n",
    "        if df.empty or 'Close' not in df.columns:\n",
    "            # Silently skip empty DFs or those missing essential data\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            # --- Calculate SMAs ---\n",
    "            for period in SMA_PERIODS:\n",
    "                # Ensure enough data points for the rolling window\n",
    "                if len(df) >= period:\n",
    "                    # Use min_periods=period to avoid partial calculations at the start\n",
    "                    df[f'SMA_{period}'] = df['Close'].rolling(window=period, min_periods=period).mean()\n",
    "                else:\n",
    "                    df[f'SMA_{period}'] = np.nan # Assign NaN if not enough data\n",
    "\n",
    "            # --- Calculate RSI ---\n",
    "            if len(df) >= RSI_PERIOD + 1: # Need at least period+1 for diff()\n",
    "                delta = df['Close'].diff()\n",
    "                gain = delta.where(delta > 0, 0.0)\n",
    "                loss = -delta.where(delta < 0, 0.0)\n",
    "                # Use Exponential Moving Average for RSI smoothing\n",
    "                avg_gain = gain.ewm(com=RSI_PERIOD - 1, min_periods=RSI_PERIOD).mean()\n",
    "                avg_loss = loss.ewm(com=RSI_PERIOD - 1, min_periods=RSI_PERIOD).mean()\n",
    "\n",
    "                # Calculate Relative Strength (RS) - handle division by zero\n",
    "                rs = np.where(avg_loss == 0, np.inf, avg_gain / avg_loss) # Avoid division by zero warning\n",
    "\n",
    "                # Calculate RSI\n",
    "                rsi = 100.0 - (100.0 / (1.0 + rs))\n",
    "                rsi[rs == np.inf] = 100.0 # Set RSI to 100 where avg_loss was 0 (infinite RS)\n",
    "\n",
    "                # Fill initial NaNs, potentially assigning a neutral 50.\n",
    "                rsi = pd.Series(rsi, index=df.index).fillna(50.0)\n",
    "\n",
    "                df[f'RSI_{RSI_PERIOD}'] = rsi\n",
    "            else:\n",
    "                df[f'RSI_{RSI_PERIOD}'] = np.nan # Assign NaN if not enough data\n",
    "\n",
    "\n",
    "            # --- Calculate MACD ---\n",
    "            # Need enough data for slow EMA calculation\n",
    "            if len(df) >= MACD_SLOW:\n",
    "                ema_fast = df['Close'].ewm(span=MACD_FAST, adjust=False).mean()\n",
    "                ema_slow = df['Close'].ewm(span=MACD_SLOW, adjust=False).mean()\n",
    "                macd_line = ema_fast - ema_slow\n",
    "                # Need enough data points for signal line calculation on macd_line\n",
    "                if len(macd_line.dropna()) >= MACD_SIGNAL:\n",
    "                     signal_line = macd_line.ewm(span=MACD_SIGNAL, adjust=False).mean()\n",
    "                     histogram = macd_line - signal_line\n",
    "                else:\n",
    "                     signal_line = np.nan\n",
    "                     histogram = np.nan\n",
    "\n",
    "                df[f'MACD_{MACD_FAST}_{MACD_SLOW}_{MACD_SIGNAL}'] = macd_line\n",
    "                df[f'MACDs_{MACD_FAST}_{MACD_SLOW}_{MACD_SIGNAL}'] = signal_line\n",
    "                df[f'MACDh_{MACD_FAST}_{MACD_SLOW}_{MACD_SIGNAL}'] = histogram\n",
    "            else:\n",
    "                 # Assign NaN if not enough data for MACD calculation\n",
    "                 df[f'MACD_{MACD_FAST}_{MACD_SLOW}_{MACD_SIGNAL}'] = np.nan\n",
    "                 df[f'MACDs_{MACD_FAST}_{MACD_SLOW}_{MACD_SIGNAL}'] = np.nan\n",
    "                 df[f'MACDh_{MACD_FAST}_{MACD_SLOW}_{MACD_SIGNAL}'] = np.nan\n",
    "\n",
    "\n",
    "            # DataFrames are modified in-place within the dictionary\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"  ❌ Error calculating indicators for {symbol} {interval}: {e}\")\n",
    "            symbol_errors += 1\n",
    "            # Attempt cleanup of potentially partially added columns\n",
    "            potential_new_cols = [f'SMA_{p}' for p in SMA_PERIODS] + \\\n",
    "                                 [f'RSI_{RSI_PERIOD}', f'MACD_{MACD_FAST}_{MACD_SLOW}_{MACD_SIGNAL}', \\\n",
    "                                  f'MACDs_{MACD_FAST}_{MACD_SLOW}_{MACD_SIGNAL}', f'MACDh_{MACD_FAST}_{MACD_SLOW}_{MACD_SIGNAL}']\n",
    "            for col in potential_new_cols:\n",
    "                 if col in df.columns:\n",
    "                      try: df.drop(columns=[col], inplace=True)\n",
    "                      except Exception: pass # Ignore cleanup errors\n",
    "\n",
    "    if symbol_errors > 0:\n",
    "        calculation_errors += symbol_errors\n",
    "\n",
    "if calculation_errors > 0:\n",
    "     print(f\"⚠️ Indicator calculation completed with {calculation_errors} total errors.\")\n",
    "\n",
    "# --- Optional: Display sample data to verify ---\n",
    "# symbol_to_show = top_n_symbols[0] if top_n_symbols else None\n",
    "# interval_to_show = '1h'\n",
    "# if symbol_to_show and interval_to_show in top_n_klines.get(symbol_to_show, {}):\n",
    "#     print(f\"\\n--- Sample {symbol_to_show} {interval_to_show} Data with Indicators (Last 5 Rows) ---\")\n",
    "#     df_sample = top_n_klines[symbol_to_show][interval_to_show]\n",
    "#     cols = ['Close', f'SMA_{SMA_PERIODS[0]}', f'SMA_{SMA_PERIODS[1]}', f'RSI_{RSI_PERIOD}', f'MACD_{MACD_FAST}_{MACD_SLOW}_{MACD_SIGNAL}']\n",
    "#     cols = [c for c in cols if c in df_sample.columns]\n",
    "#     with pd.option_context('display.float_format', '{:.4f}'.format): print(df_sample[cols].tail())\n",
    "\n",
    "print(\"✅ Indicator calculation complete for all symbols and intervals.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd7a1c36-5b72-457f-9883-572db7d2e2ec",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Calculating Dynamic Target Allocations ---\n",
      "Total 24hr Volume for Top 10 crypto assets: 7,141,983.37 USDT\n",
      "Target Allocations Sum: 100.00%\n",
      "✅ Dynamic target allocations calculated ('dynamic_target_allocations_pct').\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Calculate Dynamic Target Allocations\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from decimal import Decimal # Use Decimal for precise percentage calculations\n",
    "\n",
    "# --- Configuration ---\n",
    "# Ensure N matches the number of assets selected in Cell 3\n",
    "TOP_N_ASSETS_COUNT = 10\n",
    "STABLECOIN_RESERVE_PCT = Decimal('20.0') # Target reserve percentage as Decimal\n",
    "STABLECOIN_ASSETS = ['USDT', 'USDC', 'BUSD', 'TUSD', 'USDP', 'FDUSD']\n",
    "# Primary quote/stablecoin, should match filter used in Cell 3\n",
    "QUOTE_ASSET = 'USDT'\n",
    "\n",
    "# --- Check Prerequisites ---\n",
    "if 'volume_ranking_df' not in locals() or volume_ranking_df.empty:\n",
    "    # Attempt to regenerate volume_ranking_df if it's missing (e.g., error in Cell 3)\n",
    "    print(\"⚠️ 'volume_ranking_df' missing, attempting regeneration from tickers...\")\n",
    "    try:\n",
    "        # Minimal regeneration logic (assumes client exists from Cell 1/2)\n",
    "        if 'client' not in locals() or client is None: raise RuntimeError(\"Client missing for regen\")\n",
    "        all_tickers = client.get_ticker()\n",
    "        usdt_tickers = [t for t in all_tickers if t.get('symbol', '').endswith(QUOTE_ASSET)]\n",
    "        volume_data = []\n",
    "        for ticker in usdt_tickers:\n",
    "            symbol=ticker.get('symbol'); base=symbol[:-len(QUOTE_ASSET)]; vol_str=ticker.get('quoteVolume','0'); price_str=ticker.get('lastPrice','0')\n",
    "            if base not in STABLECOIN_ASSETS:\n",
    "                try: # Convert safely\n",
    "                    vol=Decimal(vol_str); price=Decimal(price_str)\n",
    "                    if vol > 0 and price > 0: volume_data.append({'Asset':base,'Symbol':symbol,f'Volume_{QUOTE_ASSET}':vol})\n",
    "                except Exception: pass # Skip invalid tickers\n",
    "        if volume_data:\n",
    "            volume_ranking_df = pd.DataFrame(volume_data)\n",
    "            # Ensure Volume column is Decimal if regenerated\n",
    "            volume_ranking_df[f'Volume_{QUOTE_ASSET}'] = volume_ranking_df[f'Volume_{QUOTE_ASSET}'].apply(Decimal)\n",
    "            volume_ranking_df.sort_values(f'Volume_{QUOTE_ASSET}',ascending=False,inplace=True)\n",
    "        else:\n",
    "            volume_ranking_df = pd.DataFrame() # Ensure empty if still no data\n",
    "\n",
    "        if volume_ranking_df.empty: raise ValueError(\"Could not regenerate volume data.\")\n",
    "        print(\"✅ Volume ranking regenerated.\")\n",
    "    except Exception as e:\n",
    "        # If regeneration fails, targets cannot be calculated dynamically\n",
    "        raise ValueError(f\"Volume data unavailable and regeneration failed: {e}. Cannot calculate targets. Check Cell 3.\")\n",
    "\n",
    "# Check if the required volume column exists and is of Decimal type\n",
    "volume_col = f'Volume_{QUOTE_ASSET}'\n",
    "if volume_col not in volume_ranking_df.columns:\n",
    "     raise KeyError(f\"Required volume column '{volume_col}' not found in volume_ranking_df. Check Cell 3.\")\n",
    "# Ensure the volume column has Decimal type for accurate calculation\n",
    "if not pd.api.types.is_object_dtype(volume_ranking_df[volume_col]) or \\\n",
    "   not all(isinstance(v, Decimal) for v in volume_ranking_df[volume_col]):\n",
    "    print(f\"⚠️ Converting volume column '{volume_col}' to Decimal for calculation.\")\n",
    "    try:\n",
    "        volume_ranking_df[volume_col] = volume_ranking_df[volume_col].apply(lambda x: Decimal(str(x)))\n",
    "    except Exception as conv_err:\n",
    "        raise TypeError(f\"Failed to convert volume column to Decimal: {conv_err}\")\n",
    "\n",
    "\n",
    "# --- Initialize ---\n",
    "# Stores target allocation percentages as Decimals\n",
    "dynamic_target_allocations_pct = {}\n",
    "\n",
    "print(\"\\n--- Calculating Dynamic Target Allocations ---\")\n",
    "try:\n",
    "    # Filter out stablecoins again just in case, and get top N\n",
    "    crypto_volume_df = volume_ranking_df[~volume_ranking_df['Asset'].isin(STABLECOIN_ASSETS)].copy()\n",
    "    top_n_crypto_df = crypto_volume_df.head(TOP_N_ASSETS_COUNT)\n",
    "\n",
    "    # Calculate total volume of the Top N crypto assets (ensure Decimal)\n",
    "    total_top_n_volume = top_n_crypto_df[volume_col].sum()\n",
    "\n",
    "    if total_top_n_volume <= 0:\n",
    "        print(\"⚠️ Warning: Total volume for Top N crypto assets is zero or negative. Assigning 0% target weights to crypto.\")\n",
    "        total_top_n_volume = Decimal('0') # Prevent division by zero\n",
    "    else:\n",
    "         # Display volume with formatting\n",
    "         print(f\"Total 24hr Volume for Top {TOP_N_ASSETS_COUNT} crypto assets: {total_top_n_volume:,.2f} {QUOTE_ASSET}\")\n",
    "\n",
    "    # --- Calculate Dynamic Crypto Allocations ---\n",
    "    # Percentage available for non-stablecoins\n",
    "    crypto_allocation_pct = Decimal('100.0') - STABLECOIN_RESERVE_PCT\n",
    "\n",
    "    if total_top_n_volume > 0:\n",
    "        # Calculate weight based on volume contribution to the Top N total\n",
    "        for index, row in top_n_crypto_df.iterrows():\n",
    "            asset = row['Asset']\n",
    "            volume = row[volume_col] # Should be Decimal\n",
    "\n",
    "            # Calculate target percentage for this asset\n",
    "            target_pct = (volume / total_top_n_volume) * crypto_allocation_pct\n",
    "            dynamic_target_allocations_pct[asset] = target_pct\n",
    "    else:\n",
    "         # If total volume is zero, assign 0% target to all Top N crypto assets\n",
    "         for asset in top_n_crypto_df['Asset'].tolist():\n",
    "              dynamic_target_allocations_pct[asset] = Decimal('0.0')\n",
    "\n",
    "\n",
    "    # --- Add Stablecoin Allocation ---\n",
    "    # Assign the reserve percentage to the primary quote asset\n",
    "    if QUOTE_ASSET in dynamic_target_allocations_pct:\n",
    "         dynamic_target_allocations_pct[QUOTE_ASSET] += STABLECOIN_RESERVE_PCT\n",
    "    else:\n",
    "         dynamic_target_allocations_pct[QUOTE_ASSET] = STABLECOIN_RESERVE_PCT\n",
    "\n",
    "    # --- Ensure all target assets (Top N + Stablecoins) are in the dict ---\n",
    "    # Create a set of all assets that *should* have a target (even if 0%)\n",
    "    all_intended_target_assets = set(top_n_crypto_df['Asset'].tolist() + STABLECOIN_ASSETS)\n",
    "    for asset in all_intended_target_assets:\n",
    "         if asset not in dynamic_target_allocations_pct:\n",
    "              dynamic_target_allocations_pct[asset] = Decimal('0.0') # Assign 0% if missing\n",
    "\n",
    "    # --- Verify Sum ---\n",
    "    total_dynamic_pct = sum(dynamic_target_allocations_pct.values())\n",
    "    # Display sum with formatting\n",
    "    print(f\"Target Allocations Sum: {total_dynamic_pct:.2f}%\")\n",
    "    # Use Decimal for comparison threshold\n",
    "    if abs(total_dynamic_pct - Decimal('100.0')) > Decimal('0.01'):\n",
    "        print(\"⚠️ WARNING: Target Sum is not 100%!\")\n",
    "\n",
    "    # --- Optional: Print sorted targets for review ---\n",
    "    # print(\"\\nCalculated Target Allocations (%):\")\n",
    "    # sorted_targets = dict(sorted(dynamic_target_allocations_pct.items(), key=lambda item: item[1], reverse=True))\n",
    "    # for asset, pct in sorted_targets.items():\n",
    "    #     if pct > 0: print(f\"  {asset}: {pct:.2f}%\") # Show non-zero targets with 2 decimals\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"❌ An error occurred during dynamic target calculation: {e}\")\n",
    "    dynamic_target_allocations_pct = {} # Reset on error\n",
    "\n",
    "if not dynamic_target_allocations_pct:\n",
    "    print(\"⚠️ Dynamic target allocation dictionary is empty.\")\n",
    "else:\n",
    "    print(\"✅ Dynamic target allocations calculated ('dynamic_target_allocations_pct').\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "adde86e3-e5f8-4c5c-a66d-155dda453759",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Defining Helper Function: find_simple_sr ---\n",
      "✅ Helper function 'find_simple_sr' defined.\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: Define Support/Resistance Helper Function\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from decimal import Decimal # Import Decimal\n",
    "\n",
    "print(\"\\n--- Defining Helper Function: find_simple_sr ---\")\n",
    "\n",
    "def find_simple_sr(df, lookback=20):\n",
    "    \"\"\"\n",
    "    Identifies simple recent swing lows (support) and highs (resistance).\n",
    "    Looks for the min Low and max High over a rolling lookback period.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Kline DataFrame with 'Low' and 'High' columns.\n",
    "                           Assumes these columns contain numeric types (float or Decimal).\n",
    "        lookback (int): How many recent periods (rows) to consider.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (recent_support, recent_resistance) as the original numeric type (float/Decimal)\n",
    "               Returns (None, None) if not enough data or columns missing.\n",
    "    \"\"\"\n",
    "    required_cols = ['Low', 'High']\n",
    "    # Check if DataFrame is valid and has enough rows for the lookback\n",
    "    if df is None or df.empty or len(df) < lookback or not all(c in df.columns for c in required_cols):\n",
    "        return None, None # Not enough data or required columns missing\n",
    "\n",
    "    try:\n",
    "        # Get the relevant 'Low' and 'High' data for the lookback period\n",
    "        # Use .iloc[-lookback:] for potentially better performance than .tail() on large dfs\n",
    "        recent_data = df.iloc[-lookback:]\n",
    "        recent_lows = recent_data['Low']\n",
    "        recent_highs = recent_data['High']\n",
    "\n",
    "        # Check if the slices contain valid (non-NaN) data before finding min/max\n",
    "        if recent_lows.isnull().all() or recent_highs.isnull().all():\n",
    "            # print(f\"  Debug SR: All Lows or Highs are NaN in lookback period.\") # Optional debug\n",
    "            return None, None\n",
    "\n",
    "        # Find the minimum low (support) and maximum high (resistance), skipping NaNs\n",
    "        support = recent_lows.min(skipna=True)\n",
    "        resistance = recent_highs.max(skipna=True)\n",
    "\n",
    "        # Ensure we return None if min/max resulted in NaN (e.g., if all values were NaN despite previous check)\n",
    "        if pd.isna(support) or pd.isna(resistance):\n",
    "            return None, None\n",
    "\n",
    "        # Return the values (will be float or Decimal depending on df input type)\n",
    "        return support, resistance\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"  ❌ Error finding S/R: {e}\")\n",
    "        return None, None\n",
    "\n",
    "print(\"✅ Helper function 'find_simple_sr' defined.\")\n",
    "# --- Example Test (Optional - Uncomment to run) ---\n",
    "# if 'top_n_klines' in locals() and top_n_klines and 'top_n_symbols' in locals() and top_n_symbols:\n",
    "#     test_symbol = top_n_symbols[0]\n",
    "#     test_interval = '1d'\n",
    "#     if test_symbol in top_n_klines and test_interval in top_n_klines[test_symbol]:\n",
    "#         test_df = top_n_klines[test_symbol][test_interval]\n",
    "#         print(f\"\\nRunning S/R example for {test_symbol} {test_interval}...\")\n",
    "#         # Ensure Low/High are numeric if needed (should be from processing)\n",
    "#         # test_df['Low'] = pd.to_numeric(test_df['Low'], errors='coerce')\n",
    "#         # test_df['High'] = pd.to_numeric(test_df['High'], errors='coerce')\n",
    "#         sup, res = find_simple_sr(test_df, lookback=30) # Example lookback\n",
    "#         print(f\"Example {test_symbol} Daily S/R (lookback 30):\")\n",
    "#         if sup is not None and res is not None:\n",
    "#             # Format output appropriately, checking if Decimal or float\n",
    "#             sup_str = f\"{sup:.8f}\" if isinstance(sup, Decimal) else f\"{sup:.4f}\"\n",
    "#             res_str = f\"{res:.8f}\" if isinstance(res, Decimal) else f\"{res:.4f}\"\n",
    "#             print(f\"  Support: {sup_str}, Resistance: {res_str}\")\n",
    "#             if 'Close' in test_df.columns:\n",
    "#                 last_close = test_df['Close'].iloc[-1]\n",
    "#                 close_str = f\"{last_close:.8f}\" if isinstance(last_close, Decimal) else f\"{last_close:.4f}\"\n",
    "#                 print(f\"  Last Close: {close_str}\")\n",
    "#                 # Perform subtraction carefully if types might differ\n",
    "#                 try:\n",
    "#                     dist_sup = Decimal(str(last_close)) - Decimal(str(sup))\n",
    "#                     dist_res = Decimal(str(res)) - Decimal(str(last_close))\n",
    "#                     print(f\"  Dist to Support: {dist_sup:.8f}\")\n",
    "#                     print(f\"  Dist to Resistance: {dist_res:.8f}\")\n",
    "#                 except Exception as calc_err:\n",
    "#                     print(f\"  Could not calculate distances: {calc_err}\")\n",
    "#         else:\n",
    "#             print(\"  Could not calculate S/R (check data).\")\n",
    "#     else:\n",
    "#         print(f\"\\nCannot run example S/R test: {test_symbol} {test_interval} data missing or invalid.\")\n",
    "# else:\n",
    "#     print(\"\\nCannot run example S/R test: Prerequisite data missing.\")\n",
    "# --- End Example Test ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b54aa0ea-ffdc-41e7-b155-47d7074f708d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Selecting Assets (Top Volume + Whitelist) ---\n",
      "Whitelist: ['BTC', 'ETH']\n",
      "Fetching tickers & ranking top 15 by volume...\n",
      "\n",
      "✅ Final Target Assets (10): ['BTC', 'ETH', 'XRP', 'LTC', 'ADA', 'XLM', 'DOGE', 'SOL', 'HBAR', 'SUI']\n",
      "✅ Final Target Symbols: ['BTCUSDT', 'ETHUSDT', 'XRPUSDT', 'LTCUSDT', 'ADAUSDT', 'XLMUSDT', 'DOGEUSDT', 'SOLUSDT', 'HBARUSDT', 'SUIUSDT']\n"
     ]
    }
   ],
   "source": [
    "# Cell 9 (Restore): Asset Selection (Volume + Whitelist)\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "from decimal import Decimal\n",
    "\n",
    "# --- Configuration ---\n",
    "N_VOLUME_CANDIDATES = 15 # How many top volume assets to consider initially\n",
    "N_FINAL_TARGET = 10 # Aim for roughly this many assets in the final list\n",
    "QUOTE_ASSET = 'USDT'\n",
    "STABLECOIN_ASSETS = ['USDT', 'USDC', 'BUSD', 'TUSD', 'USDP', 'FDUSD']\n",
    "MANUAL_WHITELIST_ASSETS = ['BTC', 'ETH'] # Always include these if available\n",
    "\n",
    "# --- Check Prerequisites ---\n",
    "if 'client' not in locals() or client is None: raise RuntimeError(\"Client not initialized.\")\n",
    "\n",
    "# --- Initialize ---\n",
    "strategy_target_assets = [] # Use this name for final list\n",
    "strategy_target_symbols = []\n",
    "volume_ranking_df = pd.DataFrame() # Can be used later if needed\n",
    "\n",
    "print(\"\\n--- Selecting Assets (Top Volume + Whitelist) ---\")\n",
    "print(f\"Whitelist: {MANUAL_WHITELIST_ASSETS}\")\n",
    "\n",
    "try:\n",
    "    # 1. Fetch Tickers & Rank by Volume\n",
    "    print(f\"Fetching tickers & ranking top {N_VOLUME_CANDIDATES} by volume...\")\n",
    "    all_tickers = client.get_ticker()\n",
    "    quote_pairs = [t for t in all_tickers if t.get('symbol','').endswith(QUOTE_ASSET)]\n",
    "    volume_data = []; all_available_symbols = set()\n",
    "    for ticker in quote_pairs:\n",
    "        symbol = ticker.get('symbol');\n",
    "        if not symbol: continue\n",
    "        all_available_symbols.add(symbol)\n",
    "        base_asset = symbol[:-len(QUOTE_ASSET)]\n",
    "        if base_asset in STABLECOIN_ASSETS: continue\n",
    "        try:\n",
    "             volume = Decimal(ticker.get('quoteVolume','0.0')); price = Decimal(ticker.get('lastPrice','0.0'))\n",
    "             if volume > 0 and price > 0: volume_data.append({'Asset': base_asset, 'Symbol': symbol, f'Volume_{QUOTE_ASSET}': volume})\n",
    "        except Exception: pass\n",
    "    if not volume_data: raise ValueError(\"No valid volume data found.\")\n",
    "    volume_ranking_df = pd.DataFrame(volume_data)\n",
    "    volume_ranking_df[f'Volume_{QUOTE_ASSET}'] = volume_ranking_df[f'Volume_{QUOTE_ASSET}'].apply(Decimal)\n",
    "    volume_ranking_df.sort_values(by=f'Volume_{QUOTE_ASSET}', ascending=False, inplace=True)\n",
    "\n",
    "    # 2. Create Candidate Pool (Top N Vol + Whitelist)\n",
    "    top_n_assets_set = set(volume_ranking_df.head(N_VOLUME_CANDIDATES)['Asset'].tolist())\n",
    "    whitelisted_candidates = set()\n",
    "    for asset in MANUAL_WHITELIST_ASSETS:\n",
    "        symbol = f\"{asset}{QUOTE_ASSET}\"\n",
    "        if symbol in all_available_symbols: whitelisted_candidates.add(asset)\n",
    "        else: print(f\"  Warn: Whitelisted {asset} not found.\")\n",
    "    candidate_assets_set = top_n_assets_set.union(whitelisted_candidates)\n",
    "\n",
    "    # 3. Final Selection (Filter original DF, limit size, ensure whitelist)\n",
    "    final_candidates_df = volume_ranking_df[volume_ranking_df['Asset'].isin(candidate_assets_set)].copy()\n",
    "    if len(final_candidates_df) > N_FINAL_TARGET:\n",
    "        final_candidates_df = final_candidates_df.head(N_FINAL_TARGET)\n",
    "    strategy_target_assets = final_candidates_df['Asset'].tolist()\n",
    "    for asset in MANUAL_WHITELIST_ASSETS: # Ensure whitelist included\n",
    "         symbol = f\"{asset}{QUOTE_ASSET}\"\n",
    "         if symbol in all_available_symbols and asset not in strategy_target_assets:\n",
    "             print(f\"  Re-adding required whitelisted asset: {asset}\")\n",
    "             asset_data = volume_ranking_df[volume_ranking_df['Asset'] == asset]\n",
    "             if not asset_data.empty: strategy_target_assets.append(asset) ; # Only need asset name now\n",
    "    # Deduplicate just in case\n",
    "    strategy_target_assets = sorted(list(set(strategy_target_assets)), key = lambda x: volume_ranking_df[volume_ranking_df['Asset']==x].index[0] if x in volume_ranking_df['Asset'].values else float('inf')) # Sort approx by volume rank\n",
    "    strategy_target_symbols = [f\"{asset}{QUOTE_ASSET}\" for asset in strategy_target_assets]\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error during asset selection: {e}\"); strategy_target_assets, strategy_target_symbols = [], []\n",
    "\n",
    "# --- Final Output ---\n",
    "if not strategy_target_symbols: print(\"\\n⚠️ Failed to determine target symbols.\")\n",
    "else:\n",
    "    print(f\"\\n✅ Final Target Assets ({len(strategy_target_assets)}): {strategy_target_assets}\")\n",
    "    print(f\"✅ Final Target Symbols: {strategy_target_symbols}\")\n",
    "\n",
    "if 'strategy_target_assets' not in locals(): strategy_target_assets=[]\n",
    "if 'strategy_target_symbols' not in locals(): strategy_target_symbols=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "694f7033-8d26-4eda-8eff-efed08f3fa01",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Calculating Target Allocations (Equal Weight) ---\n",
      "Targeting 10 crypto assets: ['BTC', 'ETH', 'XRP', 'LTC', 'ADA', 'XLM', 'DOGE', 'SOL', 'HBAR', 'SUI']\n",
      "Stablecoin Reserve Target: 20.0% (USDT)\n",
      "Assigning ~8.00% target to each crypto asset.\n",
      "\n",
      "Target Allocations Sum (Pre-Adjustment): 100.0000%\n",
      "\n",
      "--- Final Target Allocations (%) ---\n",
      "  USDT: 20.00%\n",
      "  BTC: 8.00%\n",
      "  ETH: 8.00%\n",
      "  XRP: 8.00%\n",
      "  LTC: 8.00%\n",
      "  ADA: 8.00%\n",
      "  XLM: 8.00%\n",
      "  DOGE: 8.00%\n",
      "  SOL: 8.00%\n",
      "  HBAR: 8.00%\n",
      "  SUI: 8.00%\n",
      "\n",
      "✅ Equal weight target allocations calculated.\n",
      "   Stored results in 'target_allocations_pct'.\n"
     ]
    }
   ],
   "source": [
    "# Cell 10: Calculate Target Allocations (Equal Weight)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from decimal import Decimal\n",
    "\n",
    "# --- Configuration ---\n",
    "# Use the asset list generated in the previous cell (Cell 9)\n",
    "ASSET_LIST_VARIABLE = 'strategy_target_assets'\n",
    "# Define reserve and stablecoins\n",
    "STABLECOIN_RESERVE_PCT = Decimal('20.0') # Fixed reserve for this strategy version\n",
    "STABLECOIN_ASSETS = ['USDT', 'USDC', 'BUSD', 'TUSD', 'USDP', 'FDUSD']\n",
    "QUOTE_ASSET = 'USDT' # Primary stablecoin\n",
    "\n",
    "# --- Check Prerequisites ---\n",
    "if ASSET_LIST_VARIABLE not in locals() or not locals()[ASSET_LIST_VARIABLE]:\n",
    "     raise ValueError(f\"List of target assets ('{ASSET_LIST_VARIABLE}') not found or empty. Run Cell 9 first.\")\n",
    "\n",
    "# --- Initialize ---\n",
    "target_allocations_pct = {} # Stores final targets as Decimals\n",
    "crypto_assets_to_allocate = locals()[ASSET_LIST_VARIABLE] # Get the list from Cell 9\n",
    "num_crypto_assets = len(crypto_assets_to_allocate)\n",
    "\n",
    "print(\"\\n--- Calculating Target Allocations (Equal Weight) ---\")\n",
    "print(f\"Targeting {num_crypto_assets} crypto assets: {crypto_assets_to_allocate}\")\n",
    "print(f\"Stablecoin Reserve Target: {STABLECOIN_RESERVE_PCT}% ({QUOTE_ASSET})\")\n",
    "\n",
    "if num_crypto_assets <= 0:\n",
    "    print(\"⚠️ No crypto assets selected. Assigning 100% to stablecoin.\")\n",
    "    target_allocations_pct[QUOTE_ASSET] = Decimal('100.0')\n",
    "else:\n",
    "    # Calculate Equal Weight for Crypto Assets\n",
    "    crypto_total_pct = Decimal('100.0') - STABLECOIN_RESERVE_PCT\n",
    "    # Use quantize for potentially cleaner division result if needed, though direct division is usually fine\n",
    "    pct_per_crypto = (crypto_total_pct / Decimal(num_crypto_assets)).quantize(Decimal('0.0001')) # 4 decimal places for percentage\n",
    "    print(f\"Assigning ~{pct_per_crypto:.2f}% target to each crypto asset.\")\n",
    "\n",
    "    for asset in crypto_assets_to_allocate:\n",
    "        target_allocations_pct[asset] = pct_per_crypto\n",
    "\n",
    "    # Assign Stablecoin Reserve\n",
    "    target_allocations_pct[QUOTE_ASSET] = STABLECOIN_RESERVE_PCT\n",
    "\n",
    "# Ensure all stablecoins have a 0% target (unless primary)\n",
    "for stable in STABLECOIN_ASSETS:\n",
    "    if stable not in target_allocations_pct:\n",
    "        target_allocations_pct[stable] = Decimal('0.0')\n",
    "\n",
    "# Verify Sum & Adjust if necessary due to quantization/rounding\n",
    "total_calculated_pct = sum(target_allocations_pct.values())\n",
    "print(f\"\\nTarget Allocations Sum (Pre-Adjustment): {total_calculated_pct:.4f}%\")\n",
    "# Adjust the largest crypto allocation slightly if sum is off\n",
    "if abs(total_calculated_pct - Decimal('100.0')) > Decimal('0.0001'):\n",
    "    difference = Decimal('100.0') - total_calculated_pct\n",
    "    # Find asset with largest allocation (excluding USDT) to adjust\n",
    "    asset_to_adjust = max((asset for asset in crypto_assets_to_allocate),\n",
    "                           key=lambda a: target_allocations_pct.get(a, Decimal(0)))\n",
    "    if asset_to_adjust:\n",
    "         target_allocations_pct[asset_to_adjust] += difference\n",
    "         print(f\"Adjusting {asset_to_adjust} target by {difference:.4f}% to reach 100% sum.\")\n",
    "         total_calculated_pct = sum(target_allocations_pct.values()) # Recalculate sum\n",
    "         print(f\"Target Allocations Sum (Post-Adjustment): {total_calculated_pct:.2f}%\")\n",
    "    else:\n",
    "         print(f\"⚠️ WARNING: Target Sum != 100% ({total_calculated_pct:.4f}%) and couldn't find asset to adjust.\")\n",
    "\n",
    "# Display Allocations\n",
    "print(\"\\n--- Final Target Allocations (%) ---\")\n",
    "sorted_targets = dict(sorted(target_allocations_pct.items(), key=lambda item: item[1], reverse=True))\n",
    "for asset, pct in sorted_targets.items():\n",
    "    if pct > 0: print(f\"  {asset}: {pct:.2f}%\") # Show non-zero targets\n",
    "\n",
    "print(\"\\n✅ Equal weight target allocations calculated.\")\n",
    "print(\"   Stored results in 'target_allocations_pct'.\")\n",
    "\n",
    "if 'target_allocations_pct' not in locals(): target_allocations_pct = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "00d5334c-8abb-43eb-84c1-de868cdcdca9",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Defining RSS Feed Fetching Function ---\n",
      "✅ Function 'fetch_recent_rss_entries' defined.\n",
      "\n",
      "--- Fetching Current News Items ---\n",
      "Fetching RSS feeds (Max 5/feed, <12 hrs old)...\n",
      "  Fetching: https://cointelegraph.com/rss/tag/bitcoin...\n",
      "    -> Found 5 recent items.\n",
      "  Fetching: https://cointelegraph.com/rss/tag/ethereum...\n",
      "    -> Found 2 recent items.\n",
      "  Fetching: https://www.coindesk.com/arc/outboundfeeds/rss/...\n",
      "    -> Found 5 recent items.\n",
      "  Fetching: https://www.newsbtc.com/feed/...\n",
      "    -> Found 5 recent items.\n",
      "  Fetching: https://cryptoslate.com/feed/...\n",
      "    -> Found 5 recent items.\n",
      "--- Finished fetching. Total recent: 22 ---\n",
      "\n",
      "--- 22 Recent News Items (Sample) ---\n",
      "      published_str                                              title\n",
      "0  2025-04-09 12:50  Bitcoin’s safe-haven appeal grows during trade...\n",
      "1  2025-04-09 12:37  Binance's Second Reward-Bearing Asset LDUSDT t...\n",
      "2  2025-04-09 12:17  Bitcoin emerges as major winner as China eyes ...\n",
      "3  2025-04-09 12:00  XRP To Flip Ethereum: Standard Chartered Predi...\n",
      "4  2025-04-09 11:52  UK Bond Yields Hit 5.6%, Stirring ‘Memories of...\n",
      "5  2025-04-09 11:28  Cboe files for first US Sui spot ETF for altco...\n",
      "6  2025-04-09 11:27  China Strikes Back With 84% Tariff on U.S. Goo...\n",
      "7  2025-04-09 11:15  Crypto Daybook Americas: Bitcoin Downside Risk...\n",
      "8  2025-04-09 11:10  Kraken taps Mastercard to launch crypto debit ...\n",
      "9  2025-04-09 11:00  Uncertainty Rocks Market As ETH/BTC Drops To 6...\n",
      "\n",
      "✅ News fetching complete. Stored in 'recent_news_items'.\n"
     ]
    }
   ],
   "source": [
    "# Cell 11 (Corrected Syntax v2): Fetch RSS News Feeds\n",
    "\n",
    "# --- Necessary Imports ---\n",
    "try: import feedparser\n",
    "except ImportError: raise ImportError(\"feedparser not found. pip install feedparser\")\n",
    "try: import requests\n",
    "except ImportError: raise ImportError(\"requests not found. pip install requests\")\n",
    "import pandas as pd\n",
    "from datetime import datetime, timezone, timedelta\n",
    "import time\n",
    "import socket\n",
    "import re\n",
    "\n",
    "# --- Configuration ---\n",
    "RSS_FEED_URLS = [ # Use relevant, working feeds\n",
    "    \"https://cointelegraph.com/rss/tag/bitcoin\", \"https://cointelegraph.com/rss/tag/ethereum\",\n",
    "    \"https://www.coindesk.com/arc/outboundfeeds/rss/\", \"https://www.newsbtc.com/feed/\",\n",
    "    \"https://cryptoslate.com/feed/\", ]\n",
    "MAX_ITEMS_PER_FEED = 5\n",
    "MAX_ITEM_AGE_HOURS = 12\n",
    "REQUEST_TIMEOUT = 10; SOCKET_TIMEOUT = 10\n",
    "\n",
    "# --- Function Definition ---\n",
    "print(\"\\n--- Defining RSS Feed Fetching Function ---\")\n",
    "def fetch_recent_rss_entries(feed_urls, max_items=5, max_age_hours=24, req_timeout=10, sock_timeout=10):\n",
    "    all_recent_entries = []; processed_links = set(); now_utc = datetime.now(timezone.utc)\n",
    "    cutoff_time = now_utc - timedelta(hours=max_age_hours)\n",
    "    print(f\"Fetching RSS feeds (Max {max_items}/feed, <{max_age_hours} hrs old)...\")\n",
    "    original_timeout = socket.getdefaulttimeout(); socket.setdefaulttimeout(sock_timeout)\n",
    "    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}\n",
    "    for url in feed_urls:\n",
    "        print(f\"  Fetching: {url[:70]}...\")\n",
    "        entries_from_feed = []\n",
    "        try:\n",
    "            response = requests.get(url, headers=headers, timeout=req_timeout); response.raise_for_status()\n",
    "            feed_data = feedparser.parse(response.text); count = 0\n",
    "            if feed_data.bozo: print(f\"    ⚠️ Feedparser issue: {getattr(feed_data, 'bozo_exception', 'Unknown')}\")\n",
    "            for entry in feed_data.entries:\n",
    "                if count >= max_items: break\n",
    "                link = getattr(entry, 'link', None)\n",
    "                if not link or link in processed_links: continue\n",
    "                published_time = None\n",
    "                pub_parsed = getattr(entry, 'published_parsed', None) or getattr(entry, 'updated_parsed', None)\n",
    "                # --- CORRECTED SYNTAX (Indentation) ---\n",
    "                if pub_parsed:\n",
    "                    try:\n",
    "                        published_time = datetime.fromtimestamp(time.mktime(pub_parsed), timezone.utc)\n",
    "                    except Exception:\n",
    "                        pass # Ignore time parsing errors silently\n",
    "                # --- END CORRECTION ---\n",
    "                if published_time and published_time >= cutoff_time:\n",
    "                    title = getattr(entry, 'title', 'N/A').strip()\n",
    "                    summary = ' '.join(re.sub('<[^<]+?>', '', getattr(entry, 'summary', 'N/A')).split()).strip()\n",
    "                    entries_from_feed.append({'title': title, 'link': link, 'summary': summary[:350] + ('...' if len(summary) > 350 else ''), 'published': published_time, 'source_feed': url})\n",
    "                    processed_links.add(link); count += 1\n",
    "            print(f\"    -> Found {len(entries_from_feed)} recent items.\")\n",
    "            all_recent_entries.extend(entries_from_feed)\n",
    "        except requests.exceptions.Timeout: print(f\"    ❌ TIMEOUT: {url}\")\n",
    "        except requests.exceptions.RequestException as req_err: print(f\"    ❌ REQ ERROR: {req_err}\")\n",
    "        except Exception as e: print(f\"    ❌ UNEX ERROR: {e}\")\n",
    "        time.sleep(0.2)\n",
    "    socket.setdefaulttimeout(original_timeout)\n",
    "    all_recent_entries.sort(key=lambda x: x.get('published', datetime.min.replace(tzinfo=timezone.utc)), reverse=True)\n",
    "    print(f\"--- Finished fetching. Total recent: {len(all_recent_entries)} ---\")\n",
    "    return all_recent_entries\n",
    "print(\"✅ Function 'fetch_recent_rss_entries' defined.\")\n",
    "\n",
    "# --- Execute the Function ---\n",
    "print(\"\\n--- Fetching Current News Items ---\")\n",
    "recent_news_items = fetch_recent_rss_entries(\n",
    "    feed_urls=RSS_FEED_URLS, max_items=MAX_ITEMS_PER_FEED, max_age_hours=MAX_ITEM_AGE_HOURS,\n",
    "    req_timeout=REQUEST_TIMEOUT, sock_timeout=SOCKET_TIMEOUT )\n",
    "\n",
    "# --- Display ---\n",
    "if not recent_news_items: print(\"\\nNo recent relevant news items found.\")\n",
    "else: print(f\"\\n--- {len(recent_news_items)} Recent News Items (Sample) ---\"); news_df = pd.DataFrame(recent_news_items); news_df['published_str'] = news_df['published'].dt.strftime('%Y-%m-%d %H:%M'); print(news_df[['published_str', 'title']].head(10))\n",
    "print(\"\\n✅ News fetching complete. Stored in 'recent_news_items'.\")\n",
    "if 'recent_news_items' not in locals(): recent_news_items = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f550faf-26b2-4fc3-88de-3bd0c974fc72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Summarizing Recent News Context (gemini-1.5-flash-latest) ---\n",
      "Preparing summary prompt using up to 5 news items...\n",
      "Prepared 5 news items for prompt.\n",
      "Sending simplified request to LLM for news summary...\n",
      "\n",
      "--- LLM Raw Summary Output ---\n",
      "Increased global trade tensions are boosting Bitcoin's status as a safe-haven asset.  Binance is launching a second reward-bearing asset, LDUSDT.  Meanwhile, predictions for XRP's market dominance and concerns over rising UK bond yields add to the complex cryptocurrency market landscape.\n",
      "--- End Raw Summary ---\n",
      "\n",
      "✅ News context summarized successfully (simplified request).\n",
      "\n",
      "--- Current News Summary ---\n",
      "News Sentiment: Unknown (Not Requested)\n",
      "News Themes: Unknown (Not Requested)\n",
      "News Summary: Increased global trade tensions are boosting Bitcoin's status as a safe-haven asset.  Binance is launching a second reward-bearing asset, LDUSDT.  Meanwhile, predictions for XRP's market dominance and concerns over rising UK bond yields add to the complex cryptocurrency market landscape.\n",
      "(Generated: 2025-04-09T12:58:42.295801+00:00)\n",
      "\n",
      "News summary stored in 'news_summary' dictionary.\n"
     ]
    }
   ],
   "source": [
    "# Cell 12: Summarize News Context\n",
    "\n",
    "import google.generativeai as genai\n",
    "import pandas as pd\n",
    "import json\n",
    "from datetime import datetime, timezone\n",
    "import time\n",
    "import re\n",
    "import os # Need os to check for env var existence robustly\n",
    "from dotenv import load_dotenv # Ensure dotenv is loaded if needed\n",
    "\n",
    "# --- Configuration ---\\\n",
    "LLM_MODEL_NAME_SUMMARIZER = \"gemini-1.5-flash-latest\"\n",
    "MAX_NEWS_ITEMS_FOR_SUMMARY = 5 # Number of news items to feed into the summary prompt\n",
    "MAX_CHARS_PER_ITEM_FOR_SUMMARY = 300 # Limit characters per news item in prompt\n",
    "\n",
    "# --- Check Prerequisites ---\\\n",
    "news_summary = {\n",
    "    \"timestamp\": datetime.now(timezone.utc).isoformat(),\n",
    "    \"summary\": \"Prerequisites not met or LLM skipped.\",\n",
    "    \"sentiment\": \"Unknown\",\n",
    "    \"themes\": \"N/A\"\n",
    "}\n",
    "proceed_with_summary = False\n",
    "\n",
    "# Ensure genai_configured flag exists from Cell 3\n",
    "if 'genai_configured' not in locals():\n",
    "    # Attempt to re-check configuration if flag is missing (e.g., cell run out of order)\n",
    "    print(\"⚠️ 'genai_configured' flag not found, re-checking LLM configuration...\")\n",
    "    genai_configured = False # Default\n",
    "    try:\n",
    "        if 'genai' in locals() and genai is not None: # Check if genai object exists\n",
    "             load_dotenv()\n",
    "             google_api_key = os.environ.get('GOOGLE_API_KEY')\n",
    "             if google_api_key:\n",
    "                 genai.configure(api_key=google_api_key)\n",
    "                 genai_configured = True # Set flag on success\n",
    "                 print(\"✅ LLM re-configured.\")\n",
    "             else:\n",
    "                 print(\"⚠️ GOOGLE_API_KEY not found on re-check.\")\n",
    "        else:\n",
    "             print(\"⚠️ google.generativeai object not found on re-check.\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error re-configuring Google AI: {e}\")\n",
    "\n",
    "\n",
    "# Now perform the checks using the potentially updated genai_configured flag\n",
    "if not genai_configured:\n",
    "    print(\"⚠️ LLM not configured. Skipping news summarization.\")\n",
    "elif 'recent_news_items' not in locals():\n",
    "    print(\"⚠️ 'recent_news_items' list not found (Run Cell 11?).\")\n",
    "    news_summary['summary'] = \"News fetch failed or variable missing.\"\n",
    "elif not recent_news_items:\n",
    "    print(\"ℹ️ No news items found in 'recent_news_items' (Cell 11 result was empty).\")\n",
    "    news_summary['summary'] = \"No recent news available to summarize.\"\n",
    "else:\n",
    "    proceed_with_summary = True\n",
    "\n",
    "# --- Main Summarization Logic ---\\\n",
    "if proceed_with_summary:\n",
    "    print(f\"\\n--- Summarizing Recent News Context ({LLM_MODEL_NAME_SUMMARIZER}) ---\")\n",
    "    # Prepare News Text for Prompt\n",
    "    news_text_for_prompt = \"\"\n",
    "    item_count = 0\n",
    "    char_count = 0\n",
    "    print(f\"Preparing summary prompt using up to {MAX_NEWS_ITEMS_FOR_SUMMARY} news items...\")\n",
    "\n",
    "    # Iterate through the fetched news items (newest first, assuming sorted)\n",
    "    for item in recent_news_items:\n",
    "        if item_count >= MAX_NEWS_ITEMS_FOR_SUMMARY:\n",
    "            break\n",
    "\n",
    "        title = item.get('title', 'N/A')\n",
    "        summary = item.get('summary', 'N/A')\n",
    "        published_dt = item.get('published')\n",
    "        published_str = published_dt.strftime('%Y-%m-%d %H:%M') if published_dt else \"Unknown Time\"\n",
    "\n",
    "        # Create text for this item, truncate if necessary\n",
    "        item_text_full = f\"[{published_str}] {title}: {summary}\"\n",
    "        item_text_truncated = item_text_full[:MAX_CHARS_PER_ITEM_FOR_SUMMARY]\n",
    "        if len(item_text_full) > MAX_CHARS_PER_ITEM_FOR_SUMMARY:\n",
    "            item_text_truncated += \"...\"\n",
    "\n",
    "        # Basic check to avoid overly large prompts (adjust limit as needed)\n",
    "        if char_count + len(item_text_truncated) > 8000: # Safety break\n",
    "             print(\"  Warning: Approaching character limit for prompt, stopping news inclusion.\")\n",
    "             break\n",
    "\n",
    "        news_text_for_prompt += f\"- {item_text_truncated}\\n\"\n",
    "        char_count += len(item_text_truncated) + 3 # +3 for \"- \" and newline\n",
    "        item_count += 1\n",
    "\n",
    "    print(f\"Prepared {item_count} news items for prompt.\")\n",
    "\n",
    "    # Simplified Prompt focusing ONLY on summarization\n",
    "    summarization_prompt = f\"\"\"\n",
    "    Please provide a concise summary (2-3 sentences) of the following recent cryptocurrency news items. Focus on the main events or sentiments expressed.\n",
    "\n",
    "    NEWS ITEMS:\n",
    "    {news_text_for_prompt}\n",
    "\n",
    "    OUTPUT: Just the summary text. No greetings, no extra commentary.\n",
    "    \"\"\"\n",
    "\n",
    "    # Call LLM\n",
    "    try:\n",
    "        model = genai.GenerativeModel(LLM_MODEL_NAME_SUMMARIZER)\n",
    "        # These safety settings are needed to ALLOW summarization, which Google\n",
    "        # might sometimes flag as \"dangerous\" if news mentions finance/risk.\n",
    "        # Use with caution and understand the model might still refuse.\n",
    "        safety_settings=[\n",
    "            {\"category\": \"HARM_CATEGORY_HARASSMENT\", \"threshold\": \"BLOCK_NONE\"},\n",
    "            {\"category\": \"HARM_CATEGORY_HATE_SPEECH\", \"threshold\": \"BLOCK_NONE\"},\n",
    "            {\"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\", \"threshold\": \"BLOCK_NONE\"},\n",
    "            {\"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\", \"threshold\": \"BLOCK_NONE\"},\n",
    "        ]\n",
    "\n",
    "        print(\"Sending simplified request to LLM for news summary...\")\n",
    "        # Adding generation_config for potentially better control if needed later\n",
    "        # generation_config = genai.types.GenerationConfig(\n",
    "        #     # candidate_count=1, # Default is 1\n",
    "        #     # stop_sequences=['\\n\\n'], # Example if needed\n",
    "        #     # max_output_tokens=150, # Example limit\n",
    "        #     temperature=0.7 # Adjust creativity vs consistency\n",
    "        # )\n",
    "        response = model.generate_content(\n",
    "            summarization_prompt,\n",
    "            safety_settings=safety_settings,\n",
    "            # generation_config=generation_config # Uncomment to use config\n",
    "            )\n",
    "\n",
    "        # Check for blocks or empty response\n",
    "        if not response.candidates or (response.prompt_feedback and response.prompt_feedback.block_reason):\n",
    "            reason = response.prompt_feedback.block_reason if response.prompt_feedback else \"Unknown reason (no candidates)\"\n",
    "            print(f\"❌ LLM Response BLOCKED or Empty. Reason: {reason}\")\n",
    "            news_summary['summary'] = f\"LLM Response Blocked/Empty: {reason}\"\n",
    "            news_summary['sentiment'] = \"Blocked/Error\"\n",
    "            news_summary['themes'] = \"Blocked/Error\"\n",
    "        else:\n",
    "            # Successfully received response\n",
    "            raw_summary_text = response.text.strip()\n",
    "            print(f\"\\n--- LLM Raw Summary Output ---\\n{raw_summary_text}\\n--- End Raw Summary ---\")\n",
    "\n",
    "            # Store the summary, mark others as not requested for this simplified call\n",
    "            news_summary['summary'] = raw_summary_text\n",
    "            news_summary['sentiment'] = \"Unknown (Not Requested)\"\n",
    "            news_summary['themes'] = \"Unknown (Not Requested)\"\n",
    "            news_summary['timestamp'] = datetime.now(timezone.utc).isoformat() # Update timestamp\n",
    "            print(\"\\n✅ News context summarized successfully (simplified request).\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error during LLM news summarization: {e}\")\n",
    "        news_summary['summary'] = f\"LLM API Error: {str(e)}\"\n",
    "        news_summary['sentiment'] = \"Error\"\n",
    "        news_summary['themes'] = \"Error\"\n",
    "else:\n",
    "    # This handles cases where prerequisites weren't met\n",
    "    print(\"\\nSkipped news summarization due to missing prerequisites or empty news list.\")\n",
    "\n",
    "# --- Final Output ---\\\n",
    "print(\"\\n--- Current News Summary ---\")\n",
    "print(f\"News Sentiment: {news_summary.get('sentiment', 'Unknown')}\")\n",
    "print(f\"News Themes: {news_summary.get('themes', 'N/A')}\")\n",
    "print(f\"News Summary: {news_summary.get('summary', 'N/A')}\")\n",
    "print(f\"(Generated: {news_summary.get('timestamp')})\")\n",
    "\n",
    "print(\"\\nNews summary stored in 'news_summary' dictionary.\")\n",
    "\n",
    "# Ensure news_summary variable exists in the global scope even if skipped\n",
    "if 'news_summary' not in locals():\n",
    "    news_summary = {\"summary\": \"Variable not created.\", \"sentiment\": \"Unknown\"}\n",
    "\n",
    "# Reminder about MACRO_CONTEXT_SUMMARY if it exists from previous runs/manual definitions\n",
    "# (This variable is no longer actively used in the core summarization prompt)\n",
    "if 'MACRO_CONTEXT_SUMMARY' in locals():\n",
    "     print(\"\\nWarning: 'MACRO_CONTEXT_SUMMARY' variable still exists in the environment. It's not used by this cell but might be present from older versions.\")\n",
    "     # Consider removing it if definitively unused:\n",
    "     # del MACRO_CONTEXT_SUMMARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c1cc5941-78dc-4b4f-a76a-b11fd14e4ac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing Kline Data for 10 Selected Symbols ---\n",
      "Symbols: ['BTCUSDT', 'ETHUSDT', 'XRPUSDT', 'LTCUSDT', 'ADAUSDT', 'XLMUSDT', 'DOGEUSDT', 'SOLUSDT', 'HBARUSDT', 'SUIUSDT']\n",
      "Intervals: ['1d', '1h', '5m', '1m']\n",
      "Will LOAD local first.\n",
      "\n",
      "Finished processing data.\n",
      "\n",
      "✅ Kline data stored in 'selected_asset_klines'.\n"
     ]
    }
   ],
   "source": [
    "# Cell 13: Fetch/Load Historical Data for Selected Assets\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "from binance.client import Client # For interval constants\n",
    "from datetime import datetime, timezone # For timezone handling\n",
    "import time # Potentially useful for slight delays if needed\n",
    "\n",
    "# --- Configuration ---\\\n",
    "# Define intervals needed for TA and potentially other logic\n",
    "INTERVALS_TO_PROCESS = ['1d', '1h', '5m', '1m']\n",
    "# Map user-friendly keys to Binance API constants\n",
    "INTERVAL_API_MAP = {\n",
    "    '1d': Client.KLINE_INTERVAL_1DAY,\n",
    "    '1h': Client.KLINE_INTERVAL_1HOUR,\n",
    "    '5m': Client.KLINE_INTERVAL_5MINUTE,\n",
    "    '1m': Client.KLINE_INTERVAL_1MINUTE\n",
    "}\n",
    "# Define fetch ranges (used if fetching fresh data)\n",
    "START_DATES_FETCH = {\n",
    "    '1d': \"90 days ago UTC\",\n",
    "    '1h': \"7 days ago UTC\",\n",
    "    '5m': \"3 days ago UTC\",\n",
    "    '1m': \"1 day ago UTC\"\n",
    "}\n",
    "# Define identifiers used in filenames when saving/loading CSV data\n",
    "START_DATES_SAVE_IDS = {\n",
    "    '1d': \"90_days_ago_UTC\",\n",
    "    '1h': \"7_days_ago_UTC\",\n",
    "    '5m': \"3_days_ago_UTC\",\n",
    "    '1m': \"1_day_ago_UTC\"\n",
    "}\n",
    "DATA_DIRECTORY = \"data\" # Subdirectory to store/load CSV files\n",
    "FORCE_FETCH_FRESH = False # Set True to always ignore local CSVs and fetch from API\n",
    "\n",
    "# --- Check Prerequisites ---\\\n",
    "if 'client' not in locals() or client is None:\n",
    "    raise RuntimeError(\"Binance client is not initialized. Run Cell 2 first.\")\n",
    "# Use the asset list generated in Cell 9\n",
    "if 'strategy_target_symbols' not in locals() or not strategy_target_symbols:\n",
    "    raise ValueError(\"'strategy_target_symbols' list not found or empty. Run Cell 9 first.\")\n",
    "# Ensure fetch helper function exists (should be from Cell 1)\n",
    "if 'fetch_and_process_klines' not in locals():\n",
    "     raise RuntimeError(\"Helper function 'fetch_and_process_klines' not defined. Run Cell 1.\")\n",
    "\n",
    "# --- Initialization ---\\\n",
    "selected_asset_klines = {} # Dictionary structure: {'SYMBOL': {'interval': DataFrame}}\n",
    "os.makedirs(DATA_DIRECTORY, exist_ok=True) # Ensure data directory exists\n",
    "errors = {'load': 0, 'fetch': 0, 'save': 0} # Track errors by type\n",
    "missing_symbols_data = [] # Track symbols missing some intervals\n",
    "\n",
    "print(f\"\\n--- Processing Kline Data for {len(strategy_target_symbols)} Selected Symbols ---\")\n",
    "print(f\"Symbols: {strategy_target_symbols}\")\n",
    "print(f\"Intervals: {INTERVALS_TO_PROCESS}\")\n",
    "print(f\"Will {'FETCH FRESH' if FORCE_FETCH_FRESH else 'LOAD local first'}.\")\n",
    "\n",
    "# Loop through each symbol selected in Cell 9\n",
    "for symbol in strategy_target_symbols:\n",
    "    selected_asset_klines[symbol] = {} # Initialize nested dictionary for the symbol\n",
    "    symbol_fetch_errors = 0\n",
    "    symbol_intervals_loaded = 0\n",
    "\n",
    "    # Loop through each required interval for the current symbol\n",
    "    for interval_key in INTERVALS_TO_PROCESS:\n",
    "        interval_value = INTERVAL_API_MAP.get(interval_key)\n",
    "        if not interval_value:\n",
    "             print(f\"  ⚠️ Skipping invalid interval key: {interval_key} for {symbol}\")\n",
    "             continue # Skip if interval key isn't mapped\n",
    "\n",
    "        df = None # Reset DataFrame for each interval\n",
    "        loaded_from_csv = False\n",
    "        source_msg = \"\" # To track if loaded or fetched\n",
    "\n",
    "        # --- 1. Attempt to Load from CSV ---\\\n",
    "        if not FORCE_FETCH_FRESH:\n",
    "            start_id = START_DATES_SAVE_IDS.get(interval_key)\n",
    "            if start_id:\n",
    "                filename = os.path.join(DATA_DIRECTORY, f\"{symbol}_{interval_key}_{start_id}.csv\")\n",
    "                if os.path.exists(filename):\n",
    "                    try:\n",
    "                        # Read CSV, set index, parse dates\n",
    "                        df = pd.read_csv(filename, index_col='Open Time', parse_dates=True)\n",
    "\n",
    "                        # Consistent Timezone Handling (Crucial!)\n",
    "                        if df.index.tz is None:\n",
    "                            # If no timezone info, assume it should be UTC and localize\n",
    "                            df.index = df.index.tz_localize('UTC')\n",
    "                            # print(f\"  Localized {filename} index to UTC.\") # Optional debug\n",
    "                        elif df.index.tz != timezone.utc:\n",
    "                            # If it has a timezone but it's not UTC, convert it\n",
    "                             print(f\"  Warning: Timezone for {filename} is {df.index.tz}, converting to UTC.\")\n",
    "                             df.index = df.index.tz_convert('UTC')\n",
    "\n",
    "                        # Validate DF after loading and timezone adjustment\n",
    "                        if df is not None and not df.empty:\n",
    "                             loaded_from_csv = True\n",
    "                             source_msg = f\"Loaded {symbol} {interval_key} from CSV.\"\n",
    "                             # print(f\"  {source_msg}\") # Optional: Confirm load success\n",
    "                        else:\n",
    "                             df = None # Ensure df is None if loading resulted in empty df\n",
    "\n",
    "                    except Exception as e:\n",
    "                        print(f\"  ⚠️ Error loading {filename}: {e}. Will try fetching.\")\n",
    "                        errors['load'] += 1\n",
    "                        df = None # Ensure df is None if loading fails\n",
    "\n",
    "        # --- 2. Fetch Fresh if Not Loaded or if Forcing ---\\\n",
    "        if df is None: # Fetch if df is None (due to not existing, load error, or FORCE_FETCH_FRESH)\n",
    "            start_str = START_DATES_FETCH.get(interval_key, \"7 days ago UTC\") # Default fallback\n",
    "            # Fetch message handled within the helper function now\n",
    "            # print(f\"  Fetching {symbol} {interval_key} data starting {start_str}...\")\n",
    "            # Call the helper function defined in Cell 1\n",
    "            df = fetch_and_process_klines(client, symbol, interval_value, start_str)\n",
    "            source_msg = f\"Fetched {symbol} {interval_key} from API.\"\n",
    "\n",
    "            # --- 3. Optionally Save Freshly Fetched Data ---\\\n",
    "            if df is not None and not df.empty:\n",
    "                 save_id = START_DATES_SAVE_IDS.get(interval_key)\n",
    "                 if save_id:\n",
    "                      save_filename = os.path.join(DATA_DIRECTORY, f\"{symbol}_{interval_key}_{save_id}.csv\")\n",
    "                      try:\n",
    "                           df.to_csv(save_filename)\n",
    "                           # print(f\"  Saved {save_filename}\") # Optional: Confirm save success\n",
    "                      except Exception as e:\n",
    "                           print(f\"  ⚠️ Error SAVING {save_filename}: {e}\")\n",
    "                           errors['save'] += 1\n",
    "                 else:\n",
    "                      print(f\"  ⚠️ Cannot determine save filename for {interval_key}. Data not saved.\")\n",
    "            elif df is None: # Indicates an error during fetch/process reported by helper\n",
    "                 symbol_fetch_errors += 1\n",
    "                 # Error message printed by helper function\n",
    "\n",
    "        # --- 4. Store the final DataFrame ---\\\n",
    "        if df is not None and not df.empty:\n",
    "             selected_asset_klines[symbol][interval_key] = df\n",
    "             symbol_intervals_loaded += 1\n",
    "        elif not loaded_from_csv: # Only flag error if fetch failed (load failure already logged)\n",
    "             print(f\"  ⚠️ No data obtained or processed for {symbol} {interval_key}.\")\n",
    "\n",
    "    # --- End of interval loop ---\n",
    "    if symbol_intervals_loaded < len(INTERVALS_TO_PROCESS):\n",
    "         missing_intervals = set(INTERVALS_TO_PROCESS) - set(selected_asset_klines.get(symbol, {}).keys())\n",
    "         print(f\"  -> Note: {symbol} processed, but missing interval(s): {', '.join(missing_intervals)}\")\n",
    "         if symbol not in missing_symbols_data:\n",
    "             missing_symbols_data.append(symbol)\n",
    "\n",
    "    if symbol_fetch_errors > 0:\n",
    "        errors['fetch'] += symbol_fetch_errors\n",
    "        # Detailed fetch errors already printed by helper\n",
    "\n",
    "# --- End of symbol loop ---\\\n",
    "\n",
    "# --- Final Summary ---\\\n",
    "print(f\"\\nFinished processing data.\")\n",
    "for error_type, count in errors.items():\n",
    "    if count > 0:\n",
    "        print(f\"⚠️ Encountered {count} {error_type.capitalize()} error(s) during processing.\")\n",
    "\n",
    "if missing_symbols_data:\n",
    "     print(f\"⚠️ Symbols potentially missing required interval data: {list(set(missing_symbols_data))}\")\n",
    "\n",
    "KLINE_DICT_NAME = 'selected_asset_klines' # Define the output variable name explicitly\n",
    "print(f\"\\n✅ Kline data stored in '{KLINE_DICT_NAME}'.\")\n",
    "\n",
    "# Final check to ensure the dictionary exists and report if empty\n",
    "if KLINE_DICT_NAME not in locals():\n",
    "     locals()[KLINE_DICT_NAME] = {} # Create empty dict if it somehow doesn't exist\n",
    "     print(f\"⚠️ '{KLINE_DICT_NAME}' was not created during processing!\")\n",
    "elif not locals()[KLINE_DICT_NAME]:\n",
    "     print(f\"⚠️ '{KLINE_DICT_NAME}' is empty! No data was loaded or fetched successfully.\")\n",
    "elif len(locals()[KLINE_DICT_NAME]) != len(strategy_target_symbols):\n",
    "     print(f\"⚠️ Warning: Processed {len(locals()[KLINE_DICT_NAME])} symbols, expected {len(strategy_target_symbols)}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a81a7c80-4cca-4213-8cb2-b0f0da495deb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Calculating Technical Indicators for Selected Assets ---\n",
      "\n",
      "--- Sample BTCUSDT 1h Data with Indicators (Last 5 Rows) ---\n",
      "                               Close     SMA_20     SMA_50  RSI_14  \\\n",
      "Open Time                                                            \n",
      "2025-04-07 14:00:00+00:00 79000.0900 77598.5935 80705.8584 52.6313   \n",
      "2025-04-07 15:00:00+00:00 78790.5400 77557.4935 80628.3876 51.2791   \n",
      "2025-04-07 16:00:00+00:00 77362.1600 77486.2510 80515.9292 43.1424   \n",
      "2025-04-07 17:00:00+00:00 79051.6000 77491.2750 80445.6094 52.7019   \n",
      "2025-04-07 18:00:00+00:00 78835.3000 77536.5630 80369.3856 51.5079   \n",
      "\n",
      "                           MACD_12_26_9  \n",
      "Open Time                                \n",
      "2025-04-07 14:00:00+00:00     -936.0072  \n",
      "2025-04-07 15:00:00+00:00     -769.5557  \n",
      "2025-04-07 16:00:00+00:00     -744.3199  \n",
      "2025-04-07 17:00:00+00:00     -581.2959  \n",
      "2025-04-07 18:00:00+00:00     -464.2007  \n",
      "\n",
      "✅ Indicator calculation complete for data in 'selected_asset_klines'.\n"
     ]
    }
   ],
   "source": [
    "# Cell 14: Calculate Indicators for Selected Assets\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np # Needed for manual calculations and NaN handling\n",
    "\n",
    "# --- Configuration ---\\\n",
    "# Match periods used in indicator calculations (should align with Cell 6 if consistency is desired)\n",
    "SMA_PERIODS = [20, 50]      # Periods for Simple Moving Averages\n",
    "RSI_PERIOD = 14             # Period for Relative Strength Index\n",
    "MACD_FAST = 12              # Fast EMA period for MACD\n",
    "MACD_SLOW = 26              # Slow EMA period for MACD\n",
    "MACD_SIGNAL = 9             # Signal Line EMA period for MACD\n",
    "\n",
    "# --- Check Prerequisites ---\\\n",
    "KLINE_DATA_DICT = 'selected_asset_klines' # Input variable name from Cell 13\n",
    "if KLINE_DATA_DICT not in locals() or not locals()[KLINE_DATA_DICT]:\n",
    "    raise ValueError(f\"Kline data dictionary ('{KLINE_DATA_DICT}') not found or empty. Run Cell 13 first.\")\n",
    "\n",
    "print(\"\\n--- Calculating Technical Indicators for Selected Assets ---\")\n",
    "calculation_errors = 0\n",
    "# Get the dictionary from the local scope\n",
    "kline_data = locals()[KLINE_DATA_DICT]\n",
    "\n",
    "# Loop through each symbol in the main dictionary\n",
    "for symbol, interval_dict in kline_data.items():\n",
    "    # Check if the symbol has any interval data loaded\n",
    "    if not interval_dict:\n",
    "        # print(f\"  Skipping {symbol}: No interval data found.\") # Optional debug\n",
    "        continue\n",
    "\n",
    "    symbol_errors = 0\n",
    "    # Loop through each interval ('1d', '1h', etc.) for the current symbol\n",
    "    for interval, df in interval_dict.items():\n",
    "        # Ensure DataFrame is not empty and has the 'Close' column needed\n",
    "        if df.empty or 'Close' not in df.columns:\n",
    "            # print(f\"  Skipping {symbol} {interval}: DataFrame empty or missing 'Close' column.\") # Optional debug\n",
    "            continue\n",
    "\n",
    "        # --- Perform Calculations within a try-except block per DataFrame ---\n",
    "        try:\n",
    "            # --- Calculate SMAs ---\n",
    "            for period in SMA_PERIODS:\n",
    "                sma_col_name = f'SMA_{period}'\n",
    "                # Ensure enough data points for the rolling window\n",
    "                if len(df) >= period:\n",
    "                    # Use min_periods=period to avoid partial calculations at the start\n",
    "                    df[sma_col_name] = df['Close'].rolling(window=period, min_periods=period).mean()\n",
    "                else:\n",
    "                    df[sma_col_name] = np.nan # Assign NaN if not enough data\n",
    "\n",
    "            # --- Calculate RSI ---\n",
    "            rsi_col_name = f'RSI_{RSI_PERIOD}'\n",
    "            # Need at least period+1 rows for diff() to work properly\n",
    "            if len(df) >= RSI_PERIOD + 1:\n",
    "                delta = df['Close'].diff()\n",
    "                gain = delta.where(delta > 0, 0.0) # Get gains, default to 0\n",
    "                loss = -delta.where(delta < 0, 0.0) # Get losses (as positive values), default to 0\n",
    "\n",
    "                # Calculate Average Gain/Loss using Exponential Moving Average (common for RSI)\n",
    "                avg_gain = gain.ewm(com=RSI_PERIOD - 1, min_periods=RSI_PERIOD).mean()\n",
    "                avg_loss = loss.ewm(com=RSI_PERIOD - 1, min_periods=RSI_PERIOD).mean()\n",
    "\n",
    "                # Calculate Relative Strength (RS) - handle division by zero\n",
    "                # Where avg_loss is 0, RS is theoretically infinite (set RSI to 100 later)\n",
    "                rs = np.where(avg_loss == 0, np.inf, avg_gain / avg_loss)\n",
    "\n",
    "                # Calculate RSI\n",
    "                rsi = 100.0 - (100.0 / (1.0 + rs))\n",
    "                # Handle the infinite RS case explicitly\n",
    "                rsi[rs == np.inf] = 100.0\n",
    "\n",
    "                # Ensure it's a Series with the correct index before filling NaNs\n",
    "                rsi_series = pd.Series(rsi, index=df.index)\n",
    "\n",
    "                # --- CORRECTED fillna ---\n",
    "                # Backfill initial NaNs from EWM calculation (up to RSI period length)\n",
    "                rsi_series.bfill(limit=RSI_PERIOD, inplace=True) # Use bfill() directly\n",
    "                # Fill any remaining NaNs (usually only at the very start if bfill didn't reach) with 50\n",
    "                rsi_series.fillna(50.0, inplace=True)\n",
    "                # --- END CORRECTION ---\n",
    "\n",
    "                df[rsi_col_name] = rsi_series\n",
    "            else:\n",
    "                df[rsi_col_name] = np.nan # Assign NaN if not enough data\n",
    "\n",
    "            # --- Calculate MACD ---\n",
    "            macd_col = f'MACD_{MACD_FAST}_{MACD_SLOW}_{MACD_SIGNAL}'\n",
    "            macds_col = f'MACDs_{MACD_FAST}_{MACD_SLOW}_{MACD_SIGNAL}' # Signal line\n",
    "            macdh_col = f'MACDh_{MACD_FAST}_{MACD_SLOW}_{MACD_SIGNAL}' # Histogram\n",
    "\n",
    "            # Need enough data for the slow EMA calculation\n",
    "            if len(df) >= MACD_SLOW:\n",
    "                ema_fast = df['Close'].ewm(span=MACD_FAST, adjust=False).mean()\n",
    "                ema_slow = df['Close'].ewm(span=MACD_SLOW, adjust=False).mean()\n",
    "                macd_line = ema_fast - ema_slow\n",
    "\n",
    "                # Need enough *valid* MACD line points for the signal line EMA\n",
    "                # Check non-NaN count of macd_line before calculating signal\n",
    "                if macd_line.dropna().shape[0] >= MACD_SIGNAL:\n",
    "                     signal_line = macd_line.ewm(span=MACD_SIGNAL, adjust=False).mean()\n",
    "                     histogram = macd_line - signal_line\n",
    "                else:\n",
    "                     # Not enough data to calculate signal line reliably\n",
    "                     signal_line = np.nan\n",
    "                     histogram = np.nan\n",
    "\n",
    "                df[macd_col] = macd_line\n",
    "                df[macds_col] = signal_line\n",
    "                df[macdh_col] = histogram\n",
    "            else:\n",
    "                 # Assign NaN if not enough data for initial MACD calculation\n",
    "                 df[macd_col] = np.nan\n",
    "                 df[macds_col] = np.nan\n",
    "                 df[macdh_col] = np.nan\n",
    "\n",
    "            # Note: DataFrames are modified in-place within the kline_data dictionary\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"  ❌ Error calculating indicators for {symbol} {interval}: {e}\")\n",
    "            symbol_errors += 1\n",
    "            # Attempt cleanup of potentially partially added columns on error\n",
    "            potential_new_cols = [f'SMA_{p}' for p in SMA_PERIODS] + \\\n",
    "                                 [f'RSI_{RSI_PERIOD}', macd_col, macds_col, macdh_col]\n",
    "            for col in potential_new_cols:\n",
    "                 if col in df.columns:\n",
    "                      try:\n",
    "                          df.drop(columns=[col], inplace=True)\n",
    "                      except Exception:\n",
    "                          pass # Ignore cleanup errors\n",
    "\n",
    "    # Accumulate errors from this symbol\n",
    "    if symbol_errors > 0:\n",
    "        calculation_errors += symbol_errors\n",
    "\n",
    "# --- Final Summary ---\n",
    "if calculation_errors > 0:\n",
    "     print(f\"\\n⚠️ Indicator calculation completed with {calculation_errors} total errors across all symbols/intervals.\")\n",
    "\n",
    "# --- Optional: Display sample data to verify one symbol/interval ---\n",
    "try:\n",
    "     # Check if strategy_target_symbols exists and is not empty\n",
    "     if 'strategy_target_symbols' in locals() and strategy_target_symbols:\n",
    "         symbol_to_show = strategy_target_symbols[0] # Show first selected symbol\n",
    "         interval_to_show = '1h' # Choose an interval to display\n",
    "         if symbol_to_show in kline_data and interval_to_show in kline_data[symbol_to_show]:\n",
    "             print(f\"\\n--- Sample {symbol_to_show} {interval_to_show} Data with Indicators (Last 5 Rows) ---\")\n",
    "             df_sample = kline_data[symbol_to_show][interval_to_show]\n",
    "             # Define columns to show (ensure they exist after calculation)\n",
    "             cols_to_display = ['Close', f'SMA_{SMA_PERIODS[0]}', f'SMA_{SMA_PERIODS[1]}',\n",
    "                                f'RSI_{RSI_PERIOD}', f'MACD_{MACD_FAST}_{MACD_SLOW}_{MACD_SIGNAL}']\n",
    "             # Filter list to only include columns that actually exist in the DataFrame\n",
    "             cols_to_display = [c for c in cols_to_display if c in df_sample.columns]\n",
    "             if cols_to_display:\n",
    "                 with pd.option_context('display.float_format', '{:.4f}'.format, 'display.max_rows', 5):\n",
    "                     print(df_sample[cols_to_display].tail())\n",
    "             else:\n",
    "                 print(\"  Could not find expected indicator columns in sample DataFrame.\")\n",
    "         else:\n",
    "             print(f\"\\nSample display skipped: Data for {symbol_to_show} {interval_to_show} not found.\")\n",
    "     else:\n",
    "         print(\"\\nSample display skipped: 'strategy_target_symbols' list is empty or missing.\")\n",
    "except Exception as display_err:\n",
    "     print(f\"\\nError during sample display: {display_err}\")\n",
    "# --- End Optional Display ---\n",
    "\n",
    "print(f\"\\n✅ Indicator calculation complete for data in '{KLINE_DATA_DICT}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f2c5c2c3-5790-433b-86da-605c45b0b020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "'trades_df' (ideal trades) is empty/missing. No trades to filter.\n"
     ]
    }
   ],
   "source": [
    "# Cell 15: Filter Ideal Trades by Updated Feasibility\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from decimal import Decimal\n",
    "\n",
    "# --- Configuration ---\n",
    "QUOTE_ASSET = 'USDT'\n",
    "\n",
    "# --- Check Prerequisites ---\n",
    "# Use ideal trades from Cell 11\n",
    "if 'trades_df' not in locals() or trades_df.empty:\n",
    "     print(\"\\n'trades_df' (ideal trades) is empty/missing. No trades to filter.\")\n",
    "     final_trades_to_format_df = pd.DataFrame()\n",
    "# Use UPDATED balances from Cell 14\n",
    "elif 'updated_balances_df' not in locals():\n",
    "     print(\"⚠️ Updated balances ('updated_balances_df') not found. Cannot check final feasibility.\")\n",
    "     final_trades_to_format_df = pd.DataFrame() # Cannot proceed\n",
    "else:\n",
    "    print(\"\\n--- Filtering Ideal Trades by Updated Feasibility ---\")\n",
    "\n",
    "    # Copy ideal trades to start filtering\n",
    "    final_trades_to_format_df = trades_df.copy()\n",
    "    final_trades_to_format_df['Feasible_Updated'] = True # Add new feasibility column\n",
    "    final_trades_to_format_df['Feasibility_Reason'] = ''\n",
    "\n",
    "    balances = updated_balances_df # Use the LATEST balances\n",
    "\n",
    "    # Get LATEST free USDT\n",
    "    free_usdt = balances.loc[QUOTE_ASSET, 'Free'] if QUOTE_ASSET in balances.index else Decimal('0.0')\n",
    "    print(f\"Available Free {QUOTE_ASSET} (Updated): {free_usdt:.8f}\")\n",
    "\n",
    "    cumulative_buy_cost = Decimal('0.0') # Track cost for updated check\n",
    "\n",
    "    # Iterate through the IDEAL trades\n",
    "    for index, trade in final_trades_to_format_df.iterrows():\n",
    "        asset = trade['Asset']; action = trade['Action']\n",
    "        ideal_qty = Decimal(str(trade['IdealQuantity']))\n",
    "        ideal_value = Decimal(str(trade['IdealValueUSDT']))\n",
    "\n",
    "        # Check SELL Feasibility vs UPDATED Free balance\n",
    "        if action == 'SELL':\n",
    "            free_balance = balances.loc[asset,'Free'] if asset in balances.index else Decimal('0.0')\n",
    "            if ideal_qty > free_balance:\n",
    "                final_trades_to_format_df.loc[index, 'Feasible_Updated'] = False\n",
    "                final_trades_to_format_df.loc[index, 'Feasibility_Reason'] = f'Insufficient Free {asset} ({free_balance:.8f})'\n",
    "\n",
    "        # Check BUY Feasibility vs UPDATED Free USDT (Cumulative)\n",
    "        elif action == 'BUY':\n",
    "            required_usdt = ideal_value\n",
    "            if cumulative_buy_cost + required_usdt > free_usdt:\n",
    "                final_trades_to_format_df.loc[index, 'Feasible_Updated'] = False\n",
    "                final_trades_to_format_df.loc[index, 'Feasibility_Reason'] = f'Insufficient Free {QUOTE_ASSET} (Need {required_usdt:.2f}, Avail {(free_usdt - cumulative_buy_cost):.2f})'\n",
    "            else:\n",
    "                # Only increment cumulative cost if feasible based on UPDATED balance\n",
    "                cumulative_buy_cost += required_usdt\n",
    "\n",
    "    # Filter DataFrame based on the new Feasible_Updated column\n",
    "    final_trades_to_format_df = final_trades_to_format_df[final_trades_to_format_df['Feasible_Updated']].copy()\n",
    "\n",
    "    # --- Report Summary ---\n",
    "    proceed_count = len(final_trades_to_format_df)\n",
    "    original_count = len(trades_df) # Count from Cell 11's output DF\n",
    "    skipped_count = original_count - proceed_count\n",
    "\n",
    "    print(f\"\\nFinal Feasibility Check Summary (using updated balances):\")\n",
    "    print(f\"  {proceed_count} / {original_count} ideal trades are feasible.\")\n",
    "    if skipped_count > 0:\n",
    "        print(f\"  {skipped_count} ideal trades skipped due to updated balance constraints.\")\n",
    "        # Optional: Display skipped trades and reasons if needed\n",
    "\n",
    "    if not final_trades_to_format_df.empty:\n",
    "        print(\"\\n--- Trades Ready for Formatting ---\")\n",
    "        display_cols = ['Action', 'Asset', 'IdealQuantity', 'IdealValueUSDT']\n",
    "        def fmt(x,p=8): return f\"{x:.{p}f}\" if isinstance(x,Decimal) else (f\"{x:.{p}f}\" if isinstance(x,(int,float)) else str(x))\n",
    "        formatters = {'IdealQuantity':lambda x:fmt(x,8), 'IdealValueUSDT':lambda x:fmt(x,2)}\n",
    "        print(final_trades_to_format_df[display_cols].to_string(formatters=formatters, index=False))\n",
    "        print(\"\\n✅ Filtering complete. Feasible trades stored in 'final_trades_to_format_df'.\")\n",
    "    else:\n",
    "        print(\"\\n✅ Filtering complete. No ideal trades were feasible with updated balances.\")\n",
    "\n",
    "\n",
    "# Ensure df exists\n",
    "if 'final_trades_to_format_df' not in locals(): final_trades_to_format_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0f3023ff-a672-4ae5-8b38-799824c9ee5e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Determining Ideal Rebalancing Trades (Based on Total Value Deviation) ---\n",
      "Calculating current portfolio value...\n",
      "  USDT Balance: 8.97\n",
      "  BTC Balance: 0.00005710 @ 78835.3000 = 4.50 USDT\n",
      "  ETH Balance: 0.00318720 @ 1485.0000 = 4.73 USDT\n",
      "  XRP Balance: 5.97600000 @ 1.8595 = 11.11 USDT\n",
      "  ADA Balance: 1.99200000 @ 0.5725 = 1.14 USDT\n",
      "  Info: Kline data for BUSDUSDT (5m) unavailable. Will try ticker fallback.\n",
      "  Attempting ticker fetch for BUSDUSDT...\n",
      "    -> Fetched ticker price: 0.99930000\n",
      "  BUSD Balance: 0.14956400 @ 0.9993 = 0.15 USDT\n",
      "  Info: Kline data for WAVESUSDT (5m) unavailable. Will try ticker fallback.\n",
      "  Attempting ticker fetch for WAVESUSDT...\n",
      "    -> Fetched ticker price: 3.32900000\n",
      "  WAVES Balance: 0.01000000 @ 3.3290 = 0.03 USDT\n",
      "  SOL Balance: 0.02988000 @ 103.7400 = 3.10 USDT\n",
      "\n",
      "Total Portfolio Value: 33.74 USDT\n",
      "\n",
      "Determining ideal trades based on deviation...\n",
      "  Skipping SELL XRP: Deviation value 8.41 < Min Trade Value 10.00 or within tolerance.\n",
      "No significant deviations found requiring trades.\n",
      "\n",
      "✅ Ideal trades calculation finished (Success=True). No trades met the minimum threshold.\n",
      "   'trades_df' is empty.\n"
     ]
    }
   ],
   "source": [
    "# Cell 16: Calculate Ideal Rebalancing Trades (Deviation-Based)\n",
    "# NOTE: Cell number in comment may differ from execution order if cells were inserted/deleted.\n",
    "# This cell calculates trades based on portfolio deviation from target allocations.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from decimal import Decimal, InvalidOperation\n",
    "\n",
    "# --- Configuration ---\\\n",
    "QUOTE_ASSET = 'USDT'\n",
    "MIN_TRADE_VALUE_USDT = Decimal('10.0') # Minimum value for a trade to be considered significant\n",
    "DISPLAY_PRECISION_QTY = 8\n",
    "DISPLAY_PRECISION_VAL = 2\n",
    "# Use a recent, frequently updated interval for price calculation\n",
    "# '5m' or '1m' are often preferred for current valuation if data is reliable.\n",
    "# '1h' is a safer fallback if shorter intervals are patchy.\n",
    "PRICE_SOURCE_INTERVAL = '5m'\n",
    "\n",
    "# --- Check Prerequisites ---\\\n",
    "if 'portfolio_state' not in locals() or not isinstance(portfolio_state, dict) or 'balances' not in portfolio_state:\n",
    "    raise ValueError(\"Initial 'portfolio_state' (with 'balances' DataFrame) not found. Run Cell 2.\")\n",
    "if 'target_allocations_pct' not in locals() or not isinstance(target_allocations_pct, dict) or not target_allocations_pct:\n",
    "    raise ValueError(\"Target allocations ('target_allocations_pct') not found or empty. Run Cell 10.\")\n",
    "# Use the kline data with indicators from Cell 14 for latest prices\n",
    "if 'selected_asset_klines' not in locals() or not isinstance(selected_asset_klines, dict) or not selected_asset_klines:\n",
    "     raise ValueError(\"Kline data ('selected_asset_klines') not found or empty. Run Cell 13 & 14.\")\n",
    "# Check if client exists for potential ticker fallback\n",
    "if 'client' not in locals() or client is None:\n",
    "     print(\"⚠️ Binance client not found. Ticker price fallback will not be available.\")\n",
    "     # Allow to continue, but price fetching might fail if klines are missing\n",
    "\n",
    "# --- Initialize ---\\\n",
    "trades_df = pd.DataFrame(columns=[\n",
    "    'Asset', 'Action', 'IdealQuantity', 'IdealValueUSDT', 'CurrentValueUSDT',\n",
    "    'TargetValueUSDT', 'DeviationValueUSDT', 'DeviationPercent', 'CurrentPct',\n",
    "    'TargetPct', 'CalcPrice' # Add CalcPrice column\n",
    "])\n",
    "calculation_success = False # Flag to track success\n",
    "\n",
    "print(\"\\n--- Determining Ideal Rebalancing Trades (Based on Total Value Deviation) ---\")\n",
    "\n",
    "try:\n",
    "    # --- 1. Calculate Current Portfolio Value ---\n",
    "    print(\"Calculating current portfolio value...\")\n",
    "    current_portfolio_value = Decimal('0.0')\n",
    "    current_allocations_value = {} # Store value of each asset\n",
    "    latest_prices = {} # Store prices used for calculation\n",
    "\n",
    "    balances_df = portfolio_state['balances'] # Use initial balances from Cell 2\n",
    "\n",
    "    # Get USDT balance first\n",
    "    if QUOTE_ASSET in balances_df.index:\n",
    "        usdt_total = balances_df.loc[QUOTE_ASSET, 'Free'] + balances_df.loc[QUOTE_ASSET, 'Locked']\n",
    "        current_portfolio_value += usdt_total\n",
    "        current_allocations_value[QUOTE_ASSET] = usdt_total\n",
    "        latest_prices[QUOTE_ASSET] = Decimal('1.0') # Price of USDT is 1\n",
    "        print(f\"  {QUOTE_ASSET} Balance: {usdt_total:.{DISPLAY_PRECISION_VAL}f}\")\n",
    "    else:\n",
    "         # Ensure USDT is included even if balance is zero, for target comparison\n",
    "         current_allocations_value[QUOTE_ASSET] = Decimal('0.0')\n",
    "         latest_prices[QUOTE_ASSET] = Decimal('1.0')\n",
    "\n",
    "\n",
    "    # Iterate through assets in our balance sheet\n",
    "    for asset in balances_df.index:\n",
    "        if asset == QUOTE_ASSET:\n",
    "            continue # Already handled\n",
    "\n",
    "        symbol = f\"{asset}{QUOTE_ASSET}\"\n",
    "        total_balance = balances_df.loc[asset, 'Free'] + balances_df.loc[asset, 'Locked']\n",
    "\n",
    "        if total_balance <= Decimal('0.0'): # Skip if no balance, ensure it's in dict with 0 value\n",
    "            current_allocations_value[asset] = Decimal('0.0')\n",
    "            latest_prices[asset] = None # Mark price as unknown initially\n",
    "            continue\n",
    "\n",
    "        # Find latest price from kline data (use specified interval)\n",
    "        price = None\n",
    "        if symbol in selected_asset_klines and PRICE_SOURCE_INTERVAL in selected_asset_klines[symbol]:\n",
    "            kline_df = selected_asset_klines[symbol][PRICE_SOURCE_INTERVAL]\n",
    "            # Check if DF is not empty and has the 'Close' column\n",
    "            if not kline_df.empty and 'Close' in kline_df.columns:\n",
    "                try:\n",
    "                    # Get the last non-NaN close price from the specified interval\n",
    "                    last_valid_price = kline_df['Close'].dropna().iloc[-1]\n",
    "                    price = Decimal(str(last_valid_price))\n",
    "                    latest_prices[asset] = price # Store the price used\n",
    "                except (IndexError, InvalidOperation, ValueError) as e:\n",
    "                    print(f\"  ⚠️ Could not get valid last close price for {symbol} from {PRICE_SOURCE_INTERVAL} klines ({e}). Will try ticker fallback.\")\n",
    "                    price = None # Ensure price is None if error occurs\n",
    "            else:\n",
    "                 print(f\"  Info: Kline data for {symbol} ({PRICE_SOURCE_INTERVAL}) empty or missing 'Close'. Will try ticker fallback.\")\n",
    "                 price = None\n",
    "        else:\n",
    "             print(f\"  Info: Kline data for {symbol} ({PRICE_SOURCE_INTERVAL}) unavailable. Will try ticker fallback.\")\n",
    "             price = None # Will trigger fallback below\n",
    "\n",
    "        # Fallback: Try fetching ticker price if kline data failed or unavailable\n",
    "        if price is None:\n",
    "            print(f\"  Attempting ticker fetch for {symbol}...\")\n",
    "            if 'client' in locals() and client is not None:\n",
    "                try:\n",
    "                    ticker = client.get_symbol_ticker(symbol=symbol)\n",
    "                    price = Decimal(ticker['price'])\n",
    "                    latest_prices[asset] = price\n",
    "                    print(f\"    -> Fetched ticker price: {price}\")\n",
    "                except Exception as e:\n",
    "                     print(f\"  ⚠️ Error fetching ticker for {symbol}: {e}. Skipping value.\")\n",
    "                     price = None\n",
    "            else:\n",
    "                 print(f\"  ⚠️ Client not available to fetch ticker for {symbol}. Skipping value.\")\n",
    "                 price = None\n",
    "\n",
    "        # Calculate value if price is valid\n",
    "        if price is not None and price > Decimal('0.0'):\n",
    "            value = total_balance * price\n",
    "            current_portfolio_value += value\n",
    "            current_allocations_value[asset] = value\n",
    "            print(f\"  {asset} Balance: {total_balance:.{DISPLAY_PRECISION_QTY}f} @ {price:.4f} = {value:.{DISPLAY_PRECISION_VAL}f} {QUOTE_ASSET}\")\n",
    "        else:\n",
    "            # If we have balance but couldn't get price, add asset with 0 value\n",
    "             current_allocations_value[asset] = Decimal('0.0')\n",
    "             latest_prices[asset] = None # Ensure price is marked as unknown\n",
    "             print(f\"  {asset} Balance: {total_balance:.{DISPLAY_PRECISION_QTY}f} (Price Unknown - Value treated as 0)\")\n",
    "\n",
    "    print(f\"\\nTotal Portfolio Value: {current_portfolio_value:.{DISPLAY_PRECISION_VAL}f} {QUOTE_ASSET}\")\n",
    "\n",
    "    # Handle case of zero portfolio value\n",
    "    if current_portfolio_value <= Decimal('0.0'):\n",
    "        print(\"⚠️ Total portfolio value is zero or negative. Cannot calculate deviations.\")\n",
    "    else:\n",
    "        # --- 2. Calculate Deviations and Ideal Trades ---\n",
    "        print(\"\\nDetermining ideal trades based on deviation...\")\n",
    "        trades_to_consider = []\n",
    "\n",
    "        # Combine all assets: those in balance AND those in target list\n",
    "        all_assets = set(current_allocations_value.keys()) | set(target_allocations_pct.keys())\n",
    "\n",
    "        for asset in all_assets:\n",
    "            current_value = current_allocations_value.get(asset, Decimal('0.0'))\n",
    "            target_pct = target_allocations_pct.get(asset, Decimal('0.0')) # Get target %, default 0\n",
    "\n",
    "            # Ensure target_pct is a valid Decimal\n",
    "            if not isinstance(target_pct, Decimal):\n",
    "                try:\n",
    "                    target_pct = Decimal(str(target_pct))\n",
    "                    print(f\"  Warning: Converted target_pct for {asset} to Decimal.\")\n",
    "                except (InvalidOperation, ValueError):\n",
    "                    print(f\"  ERROR: Invalid target percentage type for {asset} ('{target_allocations_pct.get(asset)}'). Skipping.\")\n",
    "                    continue\n",
    "\n",
    "            target_value = current_portfolio_value * (target_pct / Decimal('100.0'))\n",
    "            deviation_value = current_value - target_value\n",
    "            current_pct = (current_value / current_portfolio_value) * Decimal('100.0') if current_portfolio_value > Decimal('0.0') else Decimal('0.0')\n",
    "            deviation_pct = current_pct - target_pct\n",
    "\n",
    "            # Determine action (BUY if underweight, SELL if overweight)\n",
    "            action = None\n",
    "            # Use a small tolerance based on MIN_TRADE_VALUE to avoid tiny trades near zero deviation\n",
    "            tolerance = MIN_TRADE_VALUE_USDT / Decimal('2.0')\n",
    "            if deviation_value < -tolerance: # Significantly underweight -> BUY\n",
    "                action = 'BUY'\n",
    "            elif deviation_value > tolerance: # Significantly overweight -> SELL\n",
    "                action = 'SELL'\n",
    "\n",
    "            # Calculate ideal quantity only if action is needed\n",
    "            ideal_quantity = Decimal('0.0')\n",
    "            price_used = latest_prices.get(asset) # Get price stored earlier\n",
    "\n",
    "            # Ensure we have a valid price for quantity calculation\n",
    "            if action and (price_used is None or price_used <= Decimal('0.0')):\n",
    "                 # If price was unknown earlier, try fetching ticker price again now\n",
    "                 symbol = f\"{asset}{QUOTE_ASSET}\" if asset != QUOTE_ASSET else None\n",
    "                 print(f\"  Attempting price re-fetch for {asset} (needed for quantity)...\")\n",
    "                 if symbol and 'client' in locals() and client is not None:\n",
    "                      try:\n",
    "                          ticker = client.get_symbol_ticker(symbol=symbol)\n",
    "                          price_used = Decimal(ticker['price'])\n",
    "                          latest_prices[asset] = price_used # Store the newly fetched price\n",
    "                          print(f\"    -> Fetched ticker price: {price_used}\")\n",
    "                      except Exception as e:\n",
    "                           print(f\"    ⚠️ Error fetching ticker for {symbol}: {e}. Cannot calculate quantity.\")\n",
    "                           price_used = None\n",
    "                 elif asset == QUOTE_ASSET:\n",
    "                      price_used = Decimal('1.0') # Price for USDT is 1\n",
    "                 else:\n",
    "                      price_used = None # Could not fetch\n",
    "\n",
    "            # Calculate quantity if price is valid\n",
    "            if action and price_used is not None and price_used > Decimal('0.0'):\n",
    "                # Ideal quantity is the absolute value of the deviation, divided by price\n",
    "                ideal_quantity = abs(deviation_value) / price_used\n",
    "            elif action:\n",
    "                # Cannot determine quantity if price is invalid\n",
    "                print(f\"  ⚠️ Cannot calculate ideal quantity for {action} {asset} due to invalid/missing price.\")\n",
    "                action = None # Nullify action if quantity cannot be calculated\n",
    "\n",
    "            # Add to list if trade action is defined and meets minimum value threshold\n",
    "            # Use absolute deviation value for the threshold check\n",
    "            if action and abs(deviation_value) >= MIN_TRADE_VALUE_USDT:\n",
    "                trades_to_consider.append({\n",
    "                    'Asset': asset,\n",
    "                    'Action': action,\n",
    "                    'IdealQuantity': ideal_quantity, # Store as Decimal\n",
    "                    'IdealValueUSDT': abs(deviation_value), # Absolute value of deviation\n",
    "                    'CurrentValueUSDT': current_value,\n",
    "                    'TargetValueUSDT': target_value,\n",
    "                    'DeviationValueUSDT': deviation_value,\n",
    "                    'DeviationPercent': deviation_pct,\n",
    "                    'CurrentPct': current_pct,\n",
    "                    'TargetPct': target_pct,\n",
    "                    'CalcPrice': price_used # Store the price used for calculation\n",
    "                })\n",
    "            elif action:\n",
    "                 # Trade doesn't meet min value or tolerance, log for info\n",
    "                 print(f\"  Skipping {action} {asset}: Deviation value {abs(deviation_value):.2f} < Min Trade Value {MIN_TRADE_VALUE_USDT:.2f} or within tolerance.\")\n",
    "\n",
    "\n",
    "        # --- 3. Create and Sort DataFrame ---\n",
    "        if trades_to_consider:\n",
    "            trades_df = pd.DataFrame(trades_to_consider)\n",
    "            # Sort: SELLs first, then BUYs (prioritize larger deviations within each group)\n",
    "            trades_df.sort_values(by=['Action', 'IdealValueUSDT'], ascending=[False, False], inplace=True)\n",
    "            trades_df.reset_index(drop=True, inplace=True)\n",
    "            calculation_success = True\n",
    "        else:\n",
    "            print(\"No significant deviations found requiring trades.\")\n",
    "            calculation_success = True # Still successful, just no trades needed\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"❌ An error occurred during ideal trade calculation: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc() # Print detailed traceback for debugging\n",
    "    # Ensure trades_df is empty on error\n",
    "    trades_df = pd.DataFrame(columns=trades_df.columns)\n",
    "    calculation_success = False\n",
    "\n",
    "# --- Final Output ---\n",
    "if calculation_success and not trades_df.empty:\n",
    "    print(\"\\n--- Ideal Rebalancing Trades Proposed ---\")\n",
    "    # Format for display\n",
    "    display_df = trades_df[['Action', 'Asset', 'IdealQuantity', 'IdealValueUSDT', 'CalcPrice']].copy()\n",
    "    # Define formatters using Decimal/float check and specified precision\n",
    "    def fmt_qty(x): return f\"{x:.{DISPLAY_PRECISION_QTY}f}\" if isinstance(x, (Decimal, float)) else str(x)\n",
    "    def fmt_val(x): return f\"{x:.{DISPLAY_PRECISION_VAL}f}\" if isinstance(x, (Decimal, float)) else str(x)\n",
    "    # Show price with more precision in output table if desired\n",
    "    def fmt_price(x): return f\"{x:.6f}\" if isinstance(x, (Decimal, float)) else str(x)\n",
    "\n",
    "    formatters = {\n",
    "        'IdealQuantity': fmt_qty,\n",
    "        'IdealValueUSDT': fmt_val,\n",
    "        'CalcPrice': fmt_price\n",
    "    }\n",
    "    print(display_df.to_string(index=False, formatters=formatters))\n",
    "    print(f\"\\n✅ Ideal trades calculation finished (Success={calculation_success}). Found {len(trades_df)} trades.\")\n",
    "    print(\"   Stored results in 'trades_df'.\")\n",
    "elif calculation_success:\n",
    "    print(\"\\n✅ Ideal trades calculation finished (Success=True). No trades met the minimum threshold.\")\n",
    "    print(\"   'trades_df' is empty.\")\n",
    "else:\n",
    "    print(\"\\n❌ Ideal trades calculation FAILED.\")\n",
    "    print(\"   'trades_df' is empty.\")\n",
    "\n",
    "# Ensure df exists even if calculation failed or yielded no trades\n",
    "if 'trades_df' not in locals():\n",
    "    trades_df = pd.DataFrame(columns=[\n",
    "    'Asset', 'Action', 'IdealQuantity', 'IdealValueUSDT', 'CurrentValueUSDT',\n",
    "    'TargetValueUSDT', 'DeviationValueUSDT', 'DeviationPercent', 'CurrentPct',\n",
    "    'TargetPct', 'CalcPrice'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1abf8238-d527-4d28-8e14-0845e2e3eff4",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "'trades_df' is empty/missing. Skipping feasibility check.\n"
     ]
    }
   ],
   "source": [
    "# Cell 17 (Corrected BUY Feasibility Logic): Check Trade Feasibility\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from decimal import Decimal\n",
    "\n",
    "# --- Configuration ---\\\n",
    "QUOTE_ASSET = 'USDT'\n",
    "\n",
    "# --- Check Prerequisites ---\\\n",
    "if 'trades_df' not in locals() or trades_df.empty:\n",
    "     print(\"\\n'trades_df' is empty/missing. Skipping feasibility check.\")\n",
    "     feasible_trades_df = pd.DataFrame()\n",
    "elif 'portfolio_state' not in locals() or 'balances' not in portfolio_state or 'open_orders' not in portfolio_state:\n",
    "     raise ValueError(\"Portfolio state missing. Run Cell 2 first.\")\n",
    "else:\n",
    "    print(\"\\n--- Checking Trade Feasibility Against Free Balances & Open Orders ---\")\n",
    "\n",
    "    feasible_trades_df = trades_df.copy()\n",
    "    feasible_trades_df['Feasible'] = True\n",
    "    feasible_trades_df['ConflictType'] = ''\n",
    "    feasible_trades_df['BlockingOrderIDs'] = [[] for _ in range(len(feasible_trades_df))]\n",
    "\n",
    "    balances = portfolio_state['balances']\n",
    "    open_orders = portfolio_state['open_orders']\n",
    "\n",
    "    free_usdt = balances.loc[QUOTE_ASSET, 'Free'] if QUOTE_ASSET in balances.index else Decimal('0.0')\n",
    "    print(f\"Available Free {QUOTE_ASSET} (from Cell 2): {free_usdt:.8f}\")\n",
    "\n",
    "    # --- Track cumulative USDT needed for BUYS ---\n",
    "    cumulative_buy_cost = Decimal('0.0')\n",
    "\n",
    "    # Iterate through proposed trades (ensure consistent order, e.g., SELLs first)\n",
    "    # Assuming trades_df is already sorted SELLs then BUYs from Cell 16\n",
    "    for index, trade in feasible_trades_df.iterrows():\n",
    "        asset = trade['Asset']; action = trade['Action']\n",
    "        ideal_qty = Decimal(str(trade['IdealQuantity']))\n",
    "        ideal_value = Decimal(str(trade['IdealValueUSDT'])) # Value of this specific trade\n",
    "\n",
    "        # --- Check SELL Feasibility vs FREE balance ---\n",
    "        if action == 'SELL':\n",
    "            free_balance = balances.loc[asset,'Free'] if asset in balances.index else Decimal('0.0')\n",
    "            if ideal_qty > free_balance:\n",
    "                feasible_trades_df.loc[index, 'Feasible'] = False\n",
    "                feasible_trades_df.loc[index, 'ConflictType'] = 'Insufficient Free Balance'\n",
    "                symbol_str = f\"{asset}{QUOTE_ASSET}\" if asset != QUOTE_ASSET else None\n",
    "                blocking_orders = []\n",
    "                if symbol_str and not open_orders.empty and 'symbol' in open_orders:\n",
    "                    blocking_orders = open_orders[ (open_orders['symbol']==symbol_str) & (open_orders['side']=='SELL') & (open_orders['status'].isin(['NEW','PARTIALLY_FILLED'])) ]['orderId'].tolist()\n",
    "                feasible_trades_df.at[index, 'BlockingOrderIDs'] = blocking_orders\n",
    "\n",
    "        # --- Check BUY Feasibility vs FREE USDT (Cumulative) ---\n",
    "        elif action == 'BUY':\n",
    "            # --- CORRECTED LOGIC ---\n",
    "            required_usdt_for_this_buy = ideal_value\n",
    "            # Check if *this* order PLUS previous BUYs exceed available free USDT\n",
    "            if cumulative_buy_cost + required_usdt_for_this_buy > free_usdt:\n",
    "                feasible_trades_df.loc[index, 'Feasible'] = False\n",
    "                feasible_trades_df.loc[index, 'ConflictType'] = f'Insufficient Free {QUOTE_ASSET} (Cumulative)'\n",
    "                # List open BUY orders potentially locking USDT\n",
    "                blocking_orders = []\n",
    "                if not open_orders.empty and 'side' in open_orders:\n",
    "                     blocking_orders = open_orders[ (open_orders['side'] == 'BUY') & (open_orders['status'].isin(['NEW', 'PARTIALLY_FILLED'])) ]['orderId'].tolist()\n",
    "                feasible_trades_df.at[index, 'BlockingOrderIDs'] = blocking_orders\n",
    "            else:\n",
    "                # If this BUY is feasible, add its cost to the cumulative total\n",
    "                cumulative_buy_cost += required_usdt_for_this_buy\n",
    "            # --- END CORRECTED LOGIC ---\\\n",
    "\n",
    "    # --- Report Summary ---\\\n",
    "    feasible_count = feasible_trades_df['Feasible'].sum()\n",
    "    conflicting_count = len(feasible_trades_df) - feasible_count\n",
    "    print(f\"\\nFeasibility Check Summary:\"); print(f\"  Feasible: {feasible_count}, Conflicting: {conflicting_count}\")\n",
    "    if conflicting_count > 0:\n",
    "        print(\"\\n--- Conflicting Trades Details ---\")\n",
    "        cols = ['Action','Asset','IdealQuantity','IdealValueUSDT','ConflictType','BlockingOrderIDs']\n",
    "        cols = [c for c in cols if c in feasible_trades_df.columns]\n",
    "        def fmt(x,p=8): return f\"{x:.{p}f}\" if isinstance(x,Decimal) else (f\"{x:.{p}f}\" if isinstance(x,(int,float)) else str(x))\n",
    "        formatters = {'IdealQuantity':lambda x:fmt(x,8), 'IdealValueUSDT':lambda x:fmt(x,2)}\n",
    "        print(feasible_trades_df.loc[~feasible_trades_df['Feasible'], cols].to_string(formatters=formatters, index=False))\n",
    "\n",
    "    print(f\"\\n✅ Feasibility check complete. Stored in 'feasible_trades_df'.\")\n",
    "\n",
    "if 'feasible_trades_df' not in locals(): feasible_trades_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d70cdb19-1153-4b1b-a82e-ab040cf50b5d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ℹ️ 'feasible_trades_df' is empty. No orders to cancel.\n",
      "\n",
      "Cancellation details stored in 'cancellation_summary'.\n"
     ]
    }
   ],
   "source": [
    "# Cell 18: Cancel Conflicting Orders\n",
    "# This cell cancels existing open orders that conflict with proposed trades.\n",
    "\n",
    "import pandas as pd\n",
    "from binance.client import Client\n",
    "from decimal import Decimal\n",
    "\n",
    "# --- Check Prerequisites ---\n",
    "if 'client' not in locals() or client is None:\n",
    "    raise RuntimeError(\"Binance client not initialized. Run Cell 2 first.\")\n",
    "if 'feasible_trades_df' not in locals():\n",
    "    print(\"⚠️ 'feasible_trades_df' not found. No orders to cancel.\")\n",
    "    cancellation_summary = {\"attempted\": 0, \"successful\": 0, \"errors\": 0}\n",
    "elif feasible_trades_df.empty:\n",
    "    print(\"ℹ️ 'feasible_trades_df' is empty. No orders to cancel.\")\n",
    "    cancellation_summary = {\"attempted\": 0, \"successful\": 0, \"errors\": 0}\n",
    "elif 'portfolio_state' not in locals() or 'open_orders' not in portfolio_state:\n",
    "    raise ValueError(\"Portfolio state missing 'open_orders'. Run Cell 2 first.\")\n",
    "else:\n",
    "    print(\"\\n--- Cancelling Conflicting Open Orders ---\")\n",
    "    open_orders = portfolio_state['open_orders']\n",
    "    cancellation_summary = {\"attempted\": 0, \"successful\": 0, \"errors\": 0}\n",
    "\n",
    "    # 1. Extract Symbols from Trades\n",
    "    symbols_to_check = set()\n",
    "    for index, trade in feasible_trades_df.iterrows():\n",
    "        asset = trade['Asset']\n",
    "        symbol = f\"{asset}{QUOTE_ASSET}\" if asset != QUOTE_ASSET else QUOTE_ASSET # Include quote asset symbol for cancels\n",
    "        symbols_to_check.add(symbol)\n",
    "\n",
    "    # Convert to a list for easier iteration and to avoid modifying the set during iteration.\n",
    "    symbols_to_check_list = list(symbols_to_check)\n",
    "\n",
    "    # 2. Iterate through Open Orders and Cancel Conflicting Ones\n",
    "    if not open_orders.empty and 'symbol' in open_orders.columns and not feasible_trades_df.empty:\n",
    "        print(f\"  Found {len(open_orders)} open order(s).\")\n",
    "        for index, order in open_orders.iterrows():\n",
    "            symbol = order['symbol']\n",
    "            order_id = order['orderId']\n",
    "\n",
    "            # Cancel only orders for symbols relevant to our trade strategy\n",
    "            if symbol in symbols_to_check_list:\n",
    "                cancellation_summary[\"attempted\"] += 1\n",
    "                try:\n",
    "                    print(f\"    Attempting to cancel order {order_id} for {symbol}...\")\n",
    "                    result = client.cancel_order(symbol=symbol, orderId=order_id)\n",
    "                    print(f\"      ✅ Order {order_id} cancellation successful: {result}\")\n",
    "                    cancellation_summary[\"successful\"] += 1\n",
    "                except Exception as e:\n",
    "                    print(f\"      ❌ Error cancelling order {order_id} for {symbol}: {e}\")\n",
    "                    cancellation_summary[\"errors\"] += 1\n",
    "    else:\n",
    "        print(\"  No open orders found, or no symbols to check against.\")\n",
    "\n",
    "    print(f\"\\nCancellation Summary: Attempted={cancellation_summary['attempted']}, Successful={cancellation_summary['successful']}, Errors={cancellation_summary['errors']}\")\n",
    "\n",
    "# Store the cancellation summary even if no cancels were attempted.\n",
    "if 'cancellation_summary' not in locals():\n",
    "    cancellation_summary = {\"attempted\": 0, \"successful\": 0, \"errors\": 0}\n",
    "print(\"\\nCancellation details stored in 'cancellation_summary'.\")\n",
    "\n",
    "# Ensure summary exists even if no cancellations occurred\n",
    "if 'cancellation_summary' not in locals():\n",
    "    cancellation_summary = {\"attempted\": 0, \"successful\": 0, \"errors\": 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "257b7554-f4f2-44b9-b128-7a059d94dd5b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ℹ️ 'feasible_trades_df' is empty. No trades to filter.\n"
     ]
    }
   ],
   "source": [
    "# Cell 19: Filter for Feasible Trades ONLY\n",
    "\n",
    "import pandas as pd\n",
    "from decimal import Decimal\n",
    "\n",
    "# --- Check Prerequisites ---\n",
    "if 'feasible_trades_df' not in locals():\n",
    "    print(\"⚠️ 'feasible_trades_df' not found. Skipping filtering.\")\n",
    "    final_trades_to_format_df = pd.DataFrame()\n",
    "elif feasible_trades_df.empty:\n",
    "    print(\"ℹ️ 'feasible_trades_df' is empty. No trades to filter.\")\n",
    "    final_trades_to_format_df = pd.DataFrame()\n",
    "else:\n",
    "    print(\"\\n--- Filtering for Feasible Trades (Based on Cell 17 check) ---\")\n",
    "\n",
    "    # Ensure necessary columns exist\n",
    "    required_cols = ['Feasible', 'Action', 'Asset', 'IdealQuantity', 'IdealValueUSDT']\n",
    "    if not all(col in feasible_trades_df.columns for col in required_cols):\n",
    "         missing = [c for c in required_cols if c not in feasible_trades_df.columns]\n",
    "         raise ValueError(f\"Input 'feasible_trades_df' missing columns: {missing}\")\n",
    "\n",
    "    # Filter condition: ONLY Feasible == True\n",
    "    feasible_condition = (feasible_trades_df['Feasible'] == True)\n",
    "\n",
    "    final_trades_to_format_df = feasible_trades_df[feasible_condition].copy()\n",
    "\n",
    "    # --- Report Summary ---\n",
    "    original_count = len(feasible_trades_df)\n",
    "    proceed_count = len(final_trades_to_format_df)\n",
    "    conflicting_count = original_count - proceed_count\n",
    "\n",
    "    print(f\"Out of {original_count} ideal trades considered:\")\n",
    "    print(f\"  - {proceed_count} trade(s) are feasible based on current free balances.\")\n",
    "    if conflicting_count > 0:\n",
    "        print(f\"  - {conflicting_count} trade(s) were filtered out as infeasible.\")\n",
    "\n",
    "    if not final_trades_to_format_df.empty:\n",
    "        print(\"\\n--- Trades Ready for Formatting ---\")\n",
    "        display_cols = ['Action', 'Asset', 'IdealQuantity', 'IdealValueUSDT']\n",
    "        display_cols = [c for c in display_cols if c in final_trades_to_format_df.columns]\n",
    "        def fmt(x,p=8): return f\"{x:.{p}f}\" if isinstance(x,Decimal) else (f\"{x:.{p}f}\" if isinstance(x,(int,float)) else str(x))\n",
    "        formatters = {'IdealQuantity':lambda x:fmt(x,8), 'IdealValueUSDT':lambda x:fmt(x,2)}\n",
    "        print(final_trades_to_format_df[display_cols].to_string(formatters=formatters, index=False))\n",
    "        print(\"\\n✅ Filtering complete. Feasible trades stored in 'final_trades_to_format_df'.\")\n",
    "    else:\n",
    "        print(\"\\n✅ Filtering complete. No feasible trades found to format.\")\n",
    "\n",
    "\n",
    "# Ensure the final DataFrame exists, even if empty\n",
    "if 'final_trades_to_format_df' not in locals():\n",
    "     final_trades_to_format_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e02a8f52-61dd-4eb6-aeb7-8170b6d7d671",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Waiting 1.0 seconds before final balance check...\n",
      "\n",
      "--- Fetching Updated Balances Post-Potential-Cancellation ---\n",
      "✅ Updated balances fetched successfully.\n",
      "\n",
      "--- Latest Balances (Free/Locked) ---\n",
      "             Free      Locked\n",
      "Asset                        \n",
      "BTC    0.00005710  0.00000000\n",
      "ETH    0.00318720  0.00000000\n",
      "XRP    5.97600000  0.00000000\n",
      "USDT   8.96644535  0.00000000\n",
      "ADA    1.99200000  0.00000000\n",
      "BUSD   0.14956400  0.00000000\n",
      "WAVES  0.01000000  0.00000000\n",
      "SOL    0.02988000  0.00000000\n",
      "\n",
      "✅ Updated balances stored in 'updated_balances_df'. Ready for final formatting.\n"
     ]
    }
   ],
   "source": [
    "# Cell 20: Get Updated Balances Post-Cancellation\n",
    "\n",
    "import pandas as pd\n",
    "from decimal import Decimal, ROUND_DOWN\n",
    "import time\n",
    "\n",
    "# --- Configuration ---\n",
    "QUOTE_ASSET = 'USDT'\n",
    "DISPLAY_PRECISION = 8\n",
    "# Delay even if no cancellations attempted, ensures consistency in timing\n",
    "POST_CANCEL_DELAY_SECONDS = 1.0 # Shorter delay might be fine if no cancels usually happen\n",
    "\n",
    "# --- Check Prerequisites ---\n",
    "if 'client' not in locals() or client is None:\n",
    "    raise RuntimeError(\"Binance client not initialized. Run Cell 2 first.\")\n",
    "if 'get_current_balances_detailed' not in locals():\n",
    "     raise RuntimeError(\"Function 'get_current_balances_detailed' not defined.\")\n",
    "\n",
    "# --- Add Delay ---\n",
    "print(f\"\\nWaiting {POST_CANCEL_DELAY_SECONDS} seconds before final balance check...\")\n",
    "time.sleep(POST_CANCEL_DELAY_SECONDS)\n",
    "\n",
    "print(\"\\n--- Fetching Updated Balances Post-Potential-Cancellation ---\")\n",
    "\n",
    "updated_balances_df = pd.DataFrame() # Initialize empty\n",
    "try:\n",
    "    # Call the detailed balance function again\n",
    "    updated_balances_df = get_current_balances_detailed(client) # Assumes function defined in Cell 1/2\n",
    "\n",
    "    if not updated_balances_df.empty:\n",
    "        print(\"✅ Updated balances fetched successfully.\")\n",
    "        print(\"\\n--- Latest Balances (Free/Locked) ---\")\n",
    "        # Display with formatting\n",
    "        balances_display_df = updated_balances_df.copy()\n",
    "        formatter = f'{{:.{DISPLAY_PRECISION}f}}'\n",
    "        for col in ['Free', 'Locked']:\n",
    "             if col in balances_display_df.columns:\n",
    "                  balances_display_df[col] = balances_display_df[col].apply(lambda x: formatter.format(x) if isinstance(x, Decimal) else x)\n",
    "        print(balances_display_df)\n",
    "    else:\n",
    "        print(\"⚠️ Updated balances fetch returned empty or failed.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error fetching updated balances: {e}\")\n",
    "    updated_balances_df = pd.DataFrame() # Ensure empty on error\n",
    "\n",
    "# Result stored in 'updated_balances_df'\n",
    "if 'updated_balances_df' not in locals() or updated_balances_df.empty:\n",
    "     print(\"\\n⚠️ Could not get updated balances. Final order formatting may fail.\")\n",
    "else:\n",
    "     print(\"\\n✅ Updated balances stored in 'updated_balances_df'. Ready for final formatting.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "faf56b08-9bbf-4b92-b95a-6bd22e0a6683",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Defined buy orders ('buy_orders_to_place_df') not found.\n",
      "\n",
      "--- Final Executable LIMIT Orders ---\n",
      "No buy orders were feasible or met formatting requirements.\n"
     ]
    }
   ],
   "source": [
    "# Cell 21: Format & Finalize Executable Buy Orders\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "# Need Client for exchange info, client should be initialized\n",
    "from binance.client import Client\n",
    "from decimal import Decimal, ROUND_DOWN\n",
    "\n",
    "# --- Configuration ---\n",
    "QUOTE_ASSET = 'USDT'\n",
    "# Maker strategy (used if price needs re-formatting, though less likely for deep limits)\n",
    "PLACE_BUY_AT = 'BID'\n",
    "PLACE_SELL_AT = 'ASK' # Not used this cycle\n",
    "\n",
    "# --- Check Prerequisites ---\n",
    "if 'client' not in locals() or client is None: raise RuntimeError(\"Binance client not initialized.\")\n",
    "if 'format_price_correctly' not in locals() or 'adjust_quantity_to_step' not in locals(): raise RuntimeError(\"Formatting helpers not defined.\")\n",
    "# Use the buy orders defined in Cell 17\n",
    "if 'buy_orders_to_place_df' not in locals(): print(\"⚠️ Defined buy orders ('buy_orders_to_place_df') not found.\"); final_executable_orders = []\n",
    "elif buy_orders_to_place_df.empty: print(\"ℹ️ Defined buy orders list ('buy_orders_to_place_df') is empty.\"); final_executable_orders = []\n",
    "# Use the LATEST balances from Cell 19\n",
    "elif 'updated_balances_df' not in locals(): print(\"⚠️ Updated balances ('updated_balances_df') not found.\"); final_executable_orders = []\n",
    "# Allow proceeding if balances df is technically present but empty\n",
    "# elif updated_balances_df.empty: print(\"⚠️ Updated balances DataFrame is empty.\"); final_executable_orders = []\n",
    "else:\n",
    "    print(\"\\n--- Formatting Final Executable BUY Orders ---\")\n",
    "    print(f\"Checking against updated balances. Strategy: Place BUY orders at LLM suggested levels.\")\n",
    "\n",
    "    # --- Get Exchange Info ---\n",
    "    print(\"Fetching exchange information for formatting rules...\")\n",
    "    symbols_info = None\n",
    "    try:\n",
    "        exchange_info = client.get_exchange_info(); symbols_info = {item['symbol']: item for item in exchange_info['symbols']}\n",
    "        print(\"✅ Exchange information received.\")\n",
    "    except Exception as e: print(f\"❌ Error fetching exchange info: {e}. Formatting may be inaccurate.\")\n",
    "\n",
    "    final_executable_orders = [] # List for final parameters\n",
    "\n",
    "    # Get updated free USDT balance from Cell 19 DataFrame\n",
    "    free_usdt = updated_balances_df.loc[QUOTE_ASSET, 'Free'] if QUOTE_ASSET in updated_balances_df.index else Decimal('0.0')\n",
    "    print(f\"Updated Free {QUOTE_ASSET} for final check: {free_usdt:.8f}\")\n",
    "\n",
    "    usdt_to_be_spent = Decimal('0.0') # Track cumulative cost\n",
    "\n",
    "    # Iterate through the BUY orders defined in Cell 17\n",
    "    for index, order_def in buy_orders_to_place_df.iterrows():\n",
    "        symbol = order_def['symbol']\n",
    "        asset = symbol.replace(QUOTE_ASSET, '')\n",
    "        side = order_def['side'] # Should be 'BUY'\n",
    "        # Price/Qty from the definition step (Cell 17)\n",
    "        target_price_dec = order_def['target_price'] # Decimal\n",
    "        ideal_quantity_dec = order_def['ideal_quantity'] # Decimal\n",
    "        intended_usdt_value = order_def['usdt_value'] # Decimal ($ per order config)\n",
    "\n",
    "        print(f\"\\nProcessing Defined Order {index+1}: {side} {asset} @ {target_price_dec:.8f} (Qty: ~{ideal_quantity_dec:.8f})\")\n",
    "\n",
    "        # --- Final Feasibility Check vs Updated Balances ---\n",
    "        # Check if we have enough USDT for THIS order, considering already allocated USDT\n",
    "        if usdt_to_be_spent + intended_usdt_value > free_usdt:\n",
    "            print(f\"  INFEASIBLE: Need ~${intended_usdt_value:.2f} {QUOTE_ASSET}, Available after prior allocations: ${(free_usdt - usdt_to_be_spent):.2f}. Skipping.\")\n",
    "            continue # Skip this order and potentially subsequent ones if using priority\n",
    "        else:\n",
    "             print(f\"  FEASIBLE: Sufficient USDT available for this order.\")\n",
    "             # Tentatively commit the USDT for this order for subsequent checks\n",
    "             usdt_to_be_spent += intended_usdt_value\n",
    "\n",
    "        # --- Formatting ---\n",
    "        if symbols_info is None or symbol not in symbols_info: print(f\"  ⚠️ Rules not found for {symbol}. Skipping formatting.\"); continue\n",
    "        symbol_info = symbols_info[symbol]; filters = {f['filterType']: f for f in symbol_info['filters']}\n",
    "        price_filter=filters.get('PRICE_FILTER',{}); lot_size_filter=filters.get('LOT_SIZE',{})\n",
    "        notional_filter=filters.get('NOTIONAL',{}); min_notional_str = notional_filter.get('minNotional')\n",
    "        if min_notional_str is None: min_notional_str = filters.get('MIN_NOTIONAL',{}).get('minNotional','0.0')\n",
    "        tick_size=price_filter.get('tickSize'); step_size=lot_size_filter.get('stepSize')\n",
    "\n",
    "        if not tick_size or not step_size or min_notional_str is None: print(f\"  ⚠️ Missing filter info. Skipping.\"); continue\n",
    "        try: min_notional = Decimal(min_notional_str)\n",
    "        except Exception: print(f\"  ⚠️ Invalid minNotional. Skipping.\"); continue\n",
    "\n",
    "        try:\n",
    "            # Format the TARGET price provided by LLM/Cell 17\n",
    "            adjusted_price_str = format_price_correctly(target_price_dec, tick_size)\n",
    "            # Adjust the IDEAL quantity calculated in Cell 17 based on step size\n",
    "            adjusted_quantity_str = adjust_quantity_to_step(ideal_quantity_dec, step_size)\n",
    "            # Convert back for final check\n",
    "            adjusted_price_dec_final = Decimal(adjusted_price_str)\n",
    "            adjusted_quantity_dec_final = Decimal(adjusted_quantity_str)\n",
    "            print(f\"  Formatted Price Str: {adjusted_price_str}\")\n",
    "            print(f\"  Adjusted Quantity Str: {adjusted_quantity_str}\")\n",
    "        except Exception as fmt_err: print(f\"  ❌ Formatting error: {fmt_err}. Skipping.\"); continue\n",
    "\n",
    "        # Final Check: Adjusted Quantity > 0 and Meets MIN_NOTIONAL\n",
    "        if adjusted_quantity_dec_final <= 0: print(f\"  ⚠️ Adjusted quantity zero or less. Skipping.\"); continue\n",
    "        order_value_final = adjusted_quantity_dec_final * adjusted_price_dec_final\n",
    "        if min_notional > 0 and order_value_final < min_notional:\n",
    "             print(f\"  ⚠️ Final order value ({order_value_final:.8f}) < min notional ({min_notional:.8f}). Skipping.\");\n",
    "             # Since skipped, roll back the USDT commitment for this order\n",
    "             usdt_to_be_spent -= intended_usdt_value\n",
    "             continue\n",
    "\n",
    "        print(f\"  ✅ Final order meets min notional ({order_value_final:.8f} >= {min_notional:.8f}).\")\n",
    "\n",
    "        # Add Validated Order Parameters\n",
    "        final_executable_orders.append({\n",
    "            'symbol': symbol, 'side': side.upper(), 'type': 'LIMIT', 'timeInForce': 'GTC',\n",
    "            'quantity': adjusted_quantity_str, # FORMATTED STRING\n",
    "            'price': adjusted_price_str   # FORMATTED STRING\n",
    "        })\n",
    "        print(f\"  ✅ Added valid LIMIT order parameters for {symbol} to final execution list.\")\n",
    "\n",
    "# --- Final Display ---\n",
    "print(\"\\n--- Final Executable LIMIT Orders ---\")\n",
    "if 'final_executable_orders' not in locals() or not final_executable_orders:\n",
    "    print(\"No buy orders were feasible or met formatting requirements.\")\n",
    "    final_executable_orders = [] # Ensure list exists and is empty\n",
    "else:\n",
    "    executable_orders_df = pd.DataFrame(final_executable_orders)\n",
    "    print(executable_orders_df[['symbol', 'side', 'type', 'quantity', 'price']])\n",
    "    print(f\"\\nStored {len(final_executable_orders)} order(s) in 'final_executable_orders'.\")\n",
    "\n",
    "# Ensure list exists\n",
    "if 'final_executable_orders' not in locals(): final_executable_orders = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "786c4f8d-e8d6-4d2c-aced-23ae95efca8b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ℹ️ 'final_executable_orders' is empty. Nothing to execute.\n",
      "\n",
      "✅ Final check & confirmation complete. Ready to execute? False\n"
     ]
    }
   ],
   "source": [
    "# Cell 22 (Corrected String Literal): Final LLM Check & User Confirmation\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "import time\n",
    "from decimal import Decimal\n",
    "# Ensure google.generativeai is imported if needed and configured\n",
    "try: import google.generativeai as genai\n",
    "except ImportError: print(\"Warning: google.generativeai not found.\"); genai = None\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# --- Configuration ---\n",
    "EXECUTE_REAL_ORDERS_FLAG = True # Controls whether Cell 22 runs, but confirmation happens here\n",
    "REQUIRE_CONFIRMATION = True\n",
    "PERFORM_LLM_FINAL_CHECK = True\n",
    "# --- CORRECTED LINE ---\n",
    "LLM_MODEL_NAME_FINAL_CHECK = \"gemini-1.5-flash-latest\" # Or \"gemini-pro\"\n",
    "# --- END CORRECTION ---\n",
    "QUOTE_ASSET = 'USDT'\n",
    "RSI_PERIOD = 14\n",
    "\n",
    "# --- Initialize flag ---\n",
    "proceed_user_confirmation = False # Default to not proceeding\n",
    "\n",
    "# --- Check Prerequisites ---\n",
    "# Check the final list from Cell 20\n",
    "if 'final_executable_orders' not in locals():\n",
    "     print(\"⚠️ 'final_executable_orders' list not found. Cannot proceed.\")\n",
    "elif not final_executable_orders:\n",
    "     print(\"ℹ️ 'final_executable_orders' is empty. Nothing to execute.\")\n",
    "# Check LLM requirements only if check is enabled\n",
    "elif PERFORM_LLM_FINAL_CHECK and (genai is None or 'genai_configured' not in locals() or not genai_configured):\n",
    "     print(\"⚠️ LLM not configured/imported. Disabling final LLM check.\")\n",
    "     PERFORM_LLM_FINAL_CHECK = False\n",
    "elif PERFORM_LLM_FINAL_CHECK and 'full_market_state' not in locals():\n",
    "     print(\"⚠️ Market state not found. Disabling final LLM check.\"); PERFORM_LLM_FINAL_CHECK = False\n",
    "elif PERFORM_LLM_FINAL_CHECK and 'news_summary' not in locals():\n",
    "     print(\"⚠️ News summary not found. Disabling final LLM check.\"); PERFORM_LLM_FINAL_CHECK = False\n",
    "# If all checks pass or LLM check disabled:\n",
    "else:\n",
    "    # --- Display Orders First ---\n",
    "    print(\"\\n\" + \"=\"*60); print(\" !!! FINAL CONFIRMATION BEFORE LIVE EXECUTION !!!\"); print(\"=\"*60)\n",
    "    print(\"The following order(s) will be placed if confirmed:\")\n",
    "    try:\n",
    "        orders_to_exec_df = pd.DataFrame(final_executable_orders); print(orders_to_exec_df[['symbol', 'side', 'type', 'quantity', 'price']])\n",
    "        print(f\"\\nTotal order(s) to execute: {len(orders_to_exec_df)}\")\n",
    "    except Exception as e: print(f\"Error previewing orders: {e}\\nRaw list:\", final_executable_orders)\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    # --- Perform Final LLM Sanity Check (if enabled) ---\n",
    "    llm_final_recommendation = \"APPROVE\"; llm_final_rationale = \"LLM check skipped or default.\"\n",
    "    if PERFORM_LLM_FINAL_CHECK:\n",
    "        print(\"\\n--- Performing Final LLM Sanity Check ---\")\n",
    "        try:\n",
    "            # Prepare Context\n",
    "            orders_str_list=[]; symbols_involved = set()\n",
    "            for order in final_executable_orders: orders_str_list.append(f\"- {order['side']} {order['quantity']} {order['symbol']} @ {order['price']}\"); symbols_involved.add(order['symbol'])\n",
    "            orders_for_prompt = \"\\n\".join(orders_str_list); ta_summary_parts = []\n",
    "            macro_context = locals().get('MACRO_CONTEXT_SUMMARY', \"Not specified.\") # Get if defined, else default\n",
    "            for sym in symbols_involved:\n",
    "                state = full_market_state.get(sym)\n",
    "                if state and not state.get('error'):\n",
    "                    trend = 'UP' if state.get('daily_trend_up') else ('DOWN' if state.get('daily_trend_up') is False else 'Unk'); rsi_val = state.get('last_5m_rsi'); rsi_str = f\"{rsi_val:.1f}\" if rsi_val is not None else \"N/A\"\n",
    "                    ta_summary_parts.append(f\"{sym}: Trend {trend}, RSI {rsi_str}\")\n",
    "                else: ta_summary_parts.append(f\"{sym}: TA N/A\")\n",
    "            ta_summary_for_prompt = \"; \".join(ta_summary_parts)\n",
    "            news_context_summary = news_summary.get('summary', 'N/A'); news_context_sentiment = news_summary.get('sentiment', 'Unknown')\n",
    "\n",
    "            # Construct Final Check Prompt\n",
    "            final_check_prompt = f\"\"\"\n",
    "            Perform a final review for a batch of cryptocurrency trades generated by a long-term accumulation/rebalancing strategy.\n",
    "\n",
    "            CONTEXT:\n",
    "            * Strategy Goal: Long-term growth, buy dips in core assets, rebalance toward volume-based targets.\n",
    "            * Recent News Sentiment: {news_context_sentiment}\n",
    "            * Recent News Summary: {news_context_summary}\n",
    "            * Relevant Asset TA Summary: {ta_summary_for_prompt}\n",
    "            * Macro Environment Context: {macro_context}\n",
    "\n",
    "            PROPOSED ORDERS (Calculated, Feasible, Formatted):\n",
    "            {orders_for_prompt}\n",
    "\n",
    "            FINAL REVIEW TASK:\n",
    "            Considering the strategy, context, orders, and your general market knowledge (history, tokenomics):\n",
    "            1. Briefly summarize your assessment of executing this batch *now* (1-2 sentences). Is it generally aligned with the strategy and current context, or are there significant contradictions/red flags?\n",
    "            2. State your final recommendation clearly on a new line: **APPROVE EXECUTION** or **REJECT EXECUTION**.\n",
    "\n",
    "            Example Output:\n",
    "            Assessment: The proposed BUY order for BTC aligns with the accumulation strategy, targeting a potential support level identified. News context is mixed, TA is neutral. No major red flags.\n",
    "            Recommendation: APPROVE EXECUTION\n",
    "            \"\"\"\n",
    "\n",
    "            # Call LLM\n",
    "            model = genai.GenerativeModel(LLM_MODEL_NAME_FINAL_CHECK)\n",
    "            safety_settings=[{\"category\": c, \"threshold\": \"BLOCK_NONE\"} for c in [\"HARM_CATEGORY_HARASSMENT\", \"HARM_CATEGORY_HATE_SPEECH\", \"HARM_CATEGORY_SEXUALLY_EXPLICIT\", \"HARM_CATEGORY_DANGEROUS_CONTENT\"]]\n",
    "            response = model.generate_content(final_check_prompt, safety_settings=safety_settings)\n",
    "\n",
    "            if not response.candidates or (response.prompt_feedback and response.prompt_feedback.block_reason):\n",
    "                 reason = response.prompt_feedback.block_reason if response.prompt_feedback else \"Unknown\"; print(f\"LLM Final Check BLOCKED: {reason}\")\n",
    "                 llm_final_recommendation = \"REJECT\"; llm_final_rationale = f\"LLM Response Blocked: {reason}\"\n",
    "            else:\n",
    "                 raw_text = response.text.strip(); print(f\"LLM Final Check Response:\\n---\\n{raw_text}\\n---\")\n",
    "                 llm_final_rationale = raw_text\n",
    "                 last_line_upper = raw_text.split('\\n')[-1].upper()\n",
    "                 if \"REJECT EXECUTION\" in last_line_upper: llm_final_recommendation = \"REJECT\"; print(\"LLM signaled REJECT.\")\n",
    "                 elif \"APPROVE EXECUTION\" in last_line_upper: llm_final_recommendation = \"APPROVE\"; print(\"LLM signaled APPROVE.\")\n",
    "                 else: llm_final_recommendation = \"REJECT\"; llm_final_rationale = \"Recommendation keyword unclear\"; print(\"⚠️ LLM recommendation keyword unclear, defaulting to REJECT.\")\n",
    "\n",
    "        except Exception as llm_err:\n",
    "            print(f\"❌ Error during LLM final check: {llm_err}\"); llm_final_recommendation = \"REJECT\"; llm_final_rationale = f\"LLM API Error: {llm_err}\"\n",
    "\n",
    "        print(\"-\" * 30); print(f\"LLM FINAL RECOMMENDATION: {llm_final_recommendation}\"); print(\"-\" * 30)\n",
    "    else: print(\"\\n--- Skipping Final LLM Sanity Check (Setting: OFF or Prereqs Missing) ---\")\n",
    "\n",
    "    # --- Get User Confirmation ---\n",
    "    if REQUIRE_CONFIRMATION:\n",
    "        print(\"\\nDecision Point: Review the prepared order(s) and LLM recommendation above.\")\n",
    "        try:\n",
    "            prompt_msg = f\">>> Type 'yes' exactly to EXECUTE the prepared order(s) (LLM: {llm_final_recommendation}): \"\n",
    "            confirm = input(prompt_msg)\n",
    "            if confirm == 'yes': proceed_user_confirmation = True; print(\"\\nUser confirmed execution...\")\n",
    "            else: print(\"\\nUser confirmation not given. EXECUTION CANCELLED.\")\n",
    "        except EOFError: print(\"\\nCould not get user confirmation (EOFError). EXECUTION CANCELLED.\")\n",
    "    else: # Confirmation not required\n",
    "        print(\"Skipping user confirmation step (REQUIRE_CONFIRMATION = False).\")\n",
    "        if PERFORM_LLM_FINAL_CHECK and llm_final_recommendation == \"REJECT\":\n",
    "             print(\"EXECUTION HALTED: LLM recommended REJECT (and user confirmation was skipped).\"); proceed_user_confirmation = False\n",
    "        else: proceed_user_confirmation = True\n",
    "\n",
    "# Store decision state for next cell\n",
    "print(f\"\\n✅ Final check & confirmation complete. Ready to execute? {proceed_user_confirmation}\")\n",
    "\n",
    "# Ensure flag exists even if initial checks failed\n",
    "if 'proceed_user_confirmation' not in locals(): proceed_user_confirmation = False\n",
    "# Ensure LLM recommendation state exists\n",
    "if 'llm_final_recommendation' not in locals(): llm_final_recommendation = \"SKIP\" # Or APPROVE if default desired when skipped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b5fc2ef3-a275-4e87-a8e7-9bdfbee03170",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ℹ️ 'final_executable_orders' is empty.\n",
      "\n",
      "Skipping confirmation and execution steps as no orders are ready.\n",
      "\n",
      "✅ Final check & confirmation complete. Ready to execute? False\n"
     ]
    }
   ],
   "source": [
    "# Cell 23: Final LLM Check & User Confirmation\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "import time\n",
    "from decimal import Decimal\n",
    "try: import google.generativeai as genai\n",
    "except ImportError: print(\"Warning: google.generativeai not found.\"); genai = None\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# --- Configuration ---\n",
    "EXECUTE_REAL_ORDERS_FLAG = True # User decision stored here now\n",
    "REQUIRE_CONFIRMATION = True\n",
    "PERFORM_LLM_FINAL_CHECK = True\n",
    "LLM_MODEL_NAME_FINAL_CHECK = \"gemini-1.5-flash-latest\"\n",
    "QUOTE_ASSET = 'USDT'\n",
    "RSI_PERIOD = 14\n",
    "DEFAULT_LLM_REC = \"APPROVE\" # Default if check skipped/fails\n",
    "\n",
    "# --- Initialize flags ---\n",
    "proceed_user_confirmation = False # Final user decision\n",
    "llm_final_recommendation = DEFAULT_LLM_REC\n",
    "llm_final_rationale = \"LLM check skipped or default.\"\n",
    "\n",
    "# --- Check Prerequisites --- # <<< MODIFIED BLOCK\n",
    "execution_possible = False # Can we even execute anything?\n",
    "llm_check_possible = PERFORM_LLM_FINAL_CHECK # Should we try the LLM check?\n",
    "\n",
    "if 'client' not in locals() or client is None: print(\"❌ Client not initialized.\")\n",
    "elif 'format_price_correctly' not in locals(): print(\"❌ Formatting helpers missing.\")\n",
    "elif 'final_executable_orders' not in locals(): print(\"⚠️ 'final_executable_orders' list not found.\")\n",
    "elif not final_executable_orders: print(\"ℹ️ 'final_executable_orders' is empty.\")\n",
    "else: execution_possible = True # Basic execution prerequisites met\n",
    "\n",
    "# Check LLM prereqs only if enabled AND execution is possible\n",
    "if not execution_possible:\n",
    "    llm_check_possible = False # No point checking if we can't execute\n",
    "elif PERFORM_LLM_FINAL_CHECK and (genai is None or 'genai_configured' not in locals() or not genai_configured):\n",
    "     print(\"⚠️ LLM not configured/imported. Disabling final LLM check.\")\n",
    "     llm_check_possible = False\n",
    "elif PERFORM_LLM_FINAL_CHECK and 'full_market_state' not in locals():\n",
    "     print(\"⚠️ Market state not found. Disabling final LLM check.\"); llm_check_possible = False\n",
    "elif PERFORM_LLM_FINAL_CHECK and 'news_summary' not in locals():\n",
    "     print(\"⚠️ News summary not found. Disabling final LLM check.\"); llm_check_possible = False\n",
    "# --- END Check Prerequisites --- #\n",
    "\n",
    "if not execution_possible:\n",
    "     print(\"\\nSkipping confirmation and execution steps as no orders are ready.\")\n",
    "else:\n",
    "    # --- Display Orders First ---\n",
    "    # (Display logic remains the same...)\n",
    "    print(\"\\n\" + \"=\"*60); print(\" !!! FINAL CONFIRMATION BEFORE LIVE EXECUTION !!!\"); print(\"=\"*60);\n",
    "    try: orders_to_exec_df = pd.DataFrame(final_executable_orders); print(orders_to_exec_df[['symbol', 'side', 'type', 'quantity', 'price']]); print(f\"\\nTotal order(s) to execute: {len(orders_to_exec_df)}\")\n",
    "    except Exception as e: print(f\"Error previewing: {e}\\n{final_executable_orders}\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    # --- Perform Final LLM Sanity Check (if possible) ---\n",
    "    if llm_check_possible:\n",
    "        print(\"\\n--- Performing Final LLM Sanity Check ---\")\n",
    "        try:\n",
    "            # (Prepare context logic remains the same...)\n",
    "            orders_str_list=[]; symbols_involved=set();[orders_str_list.append(f\"- {o['side']} {o['quantity']} {o['symbol']} @ {o['price']}\") or symbols_involved.add(o['symbol']) for o in final_executable_orders]\n",
    "            orders_for_prompt = \"\\n\".join(orders_str_list); ta_summary_parts = []\n",
    "            macro_context = locals().get('MACRO_CONTEXT_SUMMARY', \"Not specified.\")\n",
    "            for sym in symbols_involved:\n",
    "                state = full_market_state.get(sym)\n",
    "                if state and not state.get('error'): trend='UP' if state.get('daily_trend_up') else ('DOWN' if state.get('daily_trend_up') is False else 'Unk'); rsi_val=state.get('last_5m_rsi'); rsi_str=f\"{rsi_val:.1f}\" if rsi_val is not None else \"N/A\"; ta_summary_parts.append(f\"{sym}: Trend {trend}, RSI {rsi_str}\")\n",
    "                else: ta_summary_parts.append(f\"{sym}: TA N/A\")\n",
    "            ta_summary_for_prompt = \"; \".join(ta_summary_parts)\n",
    "            news_context_summary = news_summary.get('summary', 'N/A'); news_context_sentiment = news_summary.get('sentiment', 'Unknown')\n",
    "            # (Construct prompt logic remains the same...)\n",
    "            final_check_prompt = f\"\"\"Final Sanity Check...CONTEXT: Strategy Goal: Long-term growth... | Macro: {macro_context} | News Sentiment: {news_context_sentiment} | News Summary: {news_context_summary} | TA Summary: {ta_summary_for_prompt}\\nPROPOSED ORDER(S):\\n{orders_for_prompt}\\nFINAL QUESTION: Any major red flags to abort this batch now?\\nRespond: **APPROVE EXECUTION** or **REJECT EXECUTION**, optionally followed by brief reason.\"\"\"\n",
    "            # (Call LLM logic remains the same...)\n",
    "            model = genai.GenerativeModel(LLM_MODEL_NAME_FINAL_CHECK)\n",
    "            safety_settings=[{\"category\": c, \"threshold\": \"BLOCK_NONE\"} for c in [\"HARM_CATEGORY_HARASSMENT\", \"HARM_CATEGORY_HATE_SPEECH\", \"HARM_CATEGORY_SEXUALLY_EXPLICIT\", \"HARM_CATEGORY_DANGEROUS_CONTENT\"]]\n",
    "            response = model.generate_content(final_check_prompt, safety_settings=safety_settings)\n",
    "            if not response.candidates or (response.prompt_feedback and response.prompt_feedback.block_reason): reason = response.prompt_feedback.block_reason if response.prompt_feedback else \"Unknown\"; print(f\"LLM Blocked: {reason}\"); llm_final_recommendation = \"REJECT\"; llm_final_rationale = f\"LLM Blocked: {reason}\"\n",
    "            else:\n",
    "                 raw_text = response.text.strip(); print(f\"LLM Final Check Response:\\n---\\n{raw_text}\\n---\"); llm_final_rationale = raw_text\n",
    "                 last_line_upper = raw_text.split('\\n')[-1].upper()\n",
    "                 if \"REJECT EXECUTION\" in last_line_upper: llm_final_recommendation = \"REJECT\"; print(\"LLM signaled REJECT.\")\n",
    "                 elif \"APPROVE EXECUTION\" in last_line_upper: llm_final_recommendation = \"APPROVE\"; print(\"LLM signaled APPROVE.\")\n",
    "                 else: llm_final_recommendation = \"REJECT\"; llm_final_rationale = \"Keyword unclear\"; print(\"⚠️ LLM keyword unclear, defaulting to REJECT.\")\n",
    "        except Exception as llm_err: print(f\"❌ Error during LLM final check: {llm_err}\"); llm_final_recommendation = \"REJECT\"; llm_final_rationale = f\"LLM API Error: {llm_err}\"\n",
    "        print(\"-\" * 30); print(f\"LLM FINAL RECOMMENDATION: {llm_final_recommendation}\"); print(\"-\" * 30)\n",
    "    # Handle cases where check was disabled or skipped\n",
    "    elif PERFORM_LLM_FINAL_CHECK: print(\"\\n--- Skipping Final LLM Sanity Check (Prerequisites Missing) ---\")\n",
    "    else: print(\"\\n--- Skipping Final LLM Sanity Check (Setting: OFF) ---\")\n",
    "\n",
    "    # --- Get User Confirmation ---\n",
    "    if REQUIRE_CONFIRMATION:\n",
    "        print(\"\\nDecision Point: Review the prepared order(s) and LLM recommendation above.\")\n",
    "        try:\n",
    "            prompt_msg = f\">>> Type 'yes' exactly to EXECUTE the prepared order(s) (LLM: {llm_final_recommendation}): \"\n",
    "            confirm = input(prompt_msg)\n",
    "            if confirm == 'yes': proceed_user_confirmation = True; print(\"\\nUser confirmed execution...\")\n",
    "            else: print(\"\\nUser confirmation not given. EXECUTION CANCELLED.\")\n",
    "        except EOFError: print(\"\\nCould not get user confirmation (EOFError). EXECUTION CANCELLED.\")\n",
    "    else: # Confirmation not required\n",
    "        print(\"Skipping user confirmation step (REQUIRE_CONFIRMATION = False).\")\n",
    "        if PERFORM_LLM_FINAL_CHECK and llm_final_recommendation == \"REJECT\": print(\"EXECUTION HALTED: LLM recommended REJECT.\"); proceed_user_confirmation = False\n",
    "        else: proceed_user_confirmation = True # Auto-proceed if confirmation off and LLM didn't reject\n",
    "\n",
    "\n",
    "# Final decision stored in 'proceed_user_confirmation' flag\n",
    "print(f\"\\n✅ Final check & confirmation complete. Ready to execute? {proceed_user_confirmation}\")\n",
    "if 'proceed_user_confirmation' not in locals(): proceed_user_confirmation = False\n",
    "if 'llm_final_recommendation' not in locals(): llm_final_recommendation = \"SKIP\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ee5e7545-e1e0-45a0-9fe4-c7ed1b4edea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ℹ️ Ideal trades list ('trades_df') is empty. No trades to filter.\n"
     ]
    }
   ],
   "source": [
    "# Cell 21: Final Feasibility Filter (Using Updated Balances)\n",
    "# Re-evaluates the ideal trades from Cell 16 against the balances from Cell 20.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from decimal import Decimal\n",
    "\n",
    "# --- Configuration ---\\\n",
    "QUOTE_ASSET = 'USDT'\n",
    "DISPLAY_PRECISION_QTY = 8\n",
    "DISPLAY_PRECISION_VAL = 2\n",
    "\n",
    "# --- Check Prerequisites ---\\\n",
    "# Use ideal trades from Cell 16\n",
    "if 'trades_df' not in locals():\n",
    "     print(\"⚠️ Ideal trades ('trades_df' from Cell 16) not found. Cannot filter.\")\n",
    "     final_trades_to_format_df = pd.DataFrame() # Cannot proceed\n",
    "elif trades_df.empty:\n",
    "     print(\"ℹ️ Ideal trades list ('trades_df') is empty. No trades to filter.\")\n",
    "     final_trades_to_format_df = pd.DataFrame() # Nothing to filter\n",
    "# Use UPDATED balances from Cell 20\n",
    "elif 'updated_balances_df' not in locals():\n",
    "     print(\"⚠️ Updated balances ('updated_balances_df' from Cell 20) not found. Cannot check final feasibility.\")\n",
    "     # If updated balances failed, we cannot proceed safely.\n",
    "     final_trades_to_format_df = pd.DataFrame()\n",
    "elif updated_balances_df.empty:\n",
    "      print(\"⚠️ Updated balances DataFrame ('updated_balances_df') is empty. Cannot check final feasibility.\")\n",
    "      # If updated balances are empty (e.g., API error), we cannot proceed safely.\n",
    "      final_trades_to_format_df = pd.DataFrame()\n",
    "else:\n",
    "    print(\"\\n--- Filtering Ideal Trades by Updated Feasibility (Cell 20 Balances) ---\")\n",
    "\n",
    "    # Copy ideal trades to start filtering\n",
    "    filtered_df = trades_df.copy() # Work on a copy of the original ideal trades\n",
    "    filtered_df['Feasible_Updated'] = True # Add new feasibility column\n",
    "    filtered_df['Feasibility_Reason'] = ''\n",
    "\n",
    "    balances = updated_balances_df # Use the LATEST balances from Cell 20\n",
    "\n",
    "    # Get LATEST free USDT\n",
    "    free_usdt = balances.loc[QUOTE_ASSET, 'Free'] if QUOTE_ASSET in balances.index else Decimal('0.0')\n",
    "    print(f\"Available Free {QUOTE_ASSET} (Updated): {free_usdt:.{DISPLAY_PRECISION_QTY}f}\")\n",
    "\n",
    "    cumulative_buy_cost = Decimal('0.0') # Track cost for updated check\n",
    "\n",
    "    # Iterate through the IDEAL trades (sorted SELLs then BUYs from Cell 16)\n",
    "    for index, trade in filtered_df.iterrows():\n",
    "        asset = trade['Asset']; action = trade['Action']\n",
    "        # Ensure data types are Decimal for calculation\n",
    "        try:\n",
    "            ideal_qty = Decimal(str(trade['IdealQuantity']))\n",
    "            ideal_value = Decimal(str(trade['IdealValueUSDT']))\n",
    "            if ideal_qty <= 0 or ideal_value <=0:\n",
    "                 raise ValueError(\"Ideal quantity or value is zero/negative\")\n",
    "        except (ValueError, TypeError, InvalidOperation) as dec_err:\n",
    "             print(f\"  Error converting trade data for {asset} to Decimal: {dec_err}. Marking infeasible.\")\n",
    "             filtered_df.loc[index, 'Feasible_Updated'] = False\n",
    "             filtered_df.loc[index, 'Feasibility_Reason'] = 'Invalid trade data'\n",
    "             continue # Skip to next trade\n",
    "\n",
    "        # Check SELL Feasibility vs UPDATED Free balance\n",
    "        if action == 'SELL':\n",
    "            free_balance = balances.loc[asset,'Free'] if asset in balances.index else Decimal('0.0')\n",
    "            if ideal_qty > free_balance:\n",
    "                filtered_df.loc[index, 'Feasible_Updated'] = False\n",
    "                reason = f'Insufficient Free {asset} ({free_balance:.{DISPLAY_PRECISION_QTY}f} < {ideal_qty:.{DISPLAY_PRECISION_QTY}f})'\n",
    "                filtered_df.loc[index, 'Feasibility_Reason'] = reason\n",
    "                print(f\"  Marking SELL {asset} infeasible: {reason}\")\n",
    "\n",
    "\n",
    "        # Check BUY Feasibility vs UPDATED Free USDT (Cumulative)\n",
    "        elif action == 'BUY':\n",
    "            required_usdt = ideal_value\n",
    "            if cumulative_buy_cost + required_usdt > free_usdt:\n",
    "                filtered_df.loc[index, 'Feasible_Updated'] = False\n",
    "                reason = f'Insufficient Free {QUOTE_ASSET} (Need {required_usdt:.{DISPLAY_PRECISION_VAL}f}, Available {(free_usdt - cumulative_buy_cost):.{DISPLAY_PRECISION_VAL}f})'\n",
    "                filtered_df.loc[index, 'Feasibility_Reason'] = reason\n",
    "                print(f\"  Marking BUY {asset} infeasible: {reason}\")\n",
    "\n",
    "            else:\n",
    "                # Only increment cumulative cost if this BUY trade passes the check\n",
    "                cumulative_buy_cost += required_usdt\n",
    "\n",
    "    # Filter DataFrame based on the new Feasible_Updated column\n",
    "    final_trades_to_format_df = filtered_df[filtered_df['Feasible_Updated']].copy()\n",
    "\n",
    "    # --- Report Summary ---\\\n",
    "    proceed_count = len(final_trades_to_format_df)\n",
    "    original_count = len(trades_df) # Count from Cell 16's output DF\n",
    "    skipped_count = original_count - proceed_count\n",
    "\n",
    "    print(f\"\\nFinal Feasibility Check Summary (using updated balances):\")\n",
    "    print(f\"  {proceed_count} / {original_count} ideal trades are feasible.\")\n",
    "    if skipped_count > 0:\n",
    "        print(f\"  {skipped_count} ideal trades skipped due to updated balance constraints.\")\n",
    "        # Optional: Display skipped trades and reasons if needed for debugging\n",
    "        # skipped_trades = filtered_df[~filtered_df['Feasible_Updated']]\n",
    "        # print(\"--- Skipped Trades ---\")\n",
    "        # print(skipped_trades[['Action', 'Asset', 'IdealQuantity', 'IdealValueUSDT', 'Feasibility_Reason']].to_string(index=False))\n",
    "\n",
    "    if not final_trades_to_format_df.empty:\n",
    "        print(\"\\n--- Trades Passing Final Feasibility (Ready for Formatting) ---\")\n",
    "        display_cols = ['Action', 'Asset', 'IdealQuantity', 'IdealValueUSDT', 'CalcPrice']\n",
    "        # Formatters for display\n",
    "        def fmt_qty(x): return f\"{x:.{DISPLAY_PRECISION_QTY}f}\" if isinstance(x, (Decimal, float)) else str(x)\n",
    "        def fmt_val(x): return f\"{x:.{DISPLAY_PRECISION_VAL}f}\" if isinstance(x, (Decimal, float)) else str(x)\n",
    "        def fmt_price(x): return f\"{x:.4f}\" if isinstance(x, (Decimal, float)) else str(x)\n",
    "        formatters = {'IdealQuantity':fmt_qty, 'IdealValueUSDT':fmt_val, 'CalcPrice':fmt_price}\n",
    "        print(final_trades_to_format_df[display_cols].to_string(formatters=formatters, index=False))\n",
    "        print(\"\\n✅ Final filtering complete. Feasible trades stored in 'final_trades_to_format_df'.\")\n",
    "    else:\n",
    "        print(\"\\n✅ Final filtering complete. No ideal trades were feasible with updated balances.\")\n",
    "\n",
    "\n",
    "# Ensure the output DataFrame exists, even if empty\n",
    "if 'final_trades_to_format_df' not in locals():\n",
    "     final_trades_to_format_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f06ecb65-910d-4509-a6da-7d81c14ec1f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ℹ️ Filtered trades list ('final_trades_to_format_df') is empty. No orders to format.\n",
      "\n",
      "--- Final Orders Ready for Confirmation ---\n",
      "No feasible trades required formatting.\n"
     ]
    }
   ],
   "source": [
    "# Cell 22: Format Orders for Execution\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "# Need Client for exchange info and ticker/depth, client should be initialized\n",
    "from binance.client import Client\n",
    "from decimal import Decimal, ROUND_DOWN, InvalidOperation\n",
    "import time # For potential small delays\n",
    "\n",
    "# --- Configuration ---\\\n",
    "QUOTE_ASSET = 'USDT'\n",
    "# Strategy: Aim for MAKER fees by placing slightly inside the spread or at the best bid/ask\n",
    "# 'BID' for BUYS, 'ASK' for SELLS. Adjust price if needed just before placement.\n",
    "ORDER_PLACEMENT_STRATEGY = {'BUY': 'BID', 'SELL': 'ASK'}\n",
    "# Price adjustment tolerance: If our calculated price is within this % of the\n",
    "# target bid/ask, we'll use our calculated price. Otherwise, adjust to current bid/ask.\n",
    "# Set to 0 to always adjust to the latest bid/ask. Set higher (e.g., 0.1) to allow slight deviation.\n",
    "PRICE_ADJUSTMENT_TOLERANCE_PCT = Decimal('0.05') # e.g., 0.05%\n",
    "\n",
    "# --- Check Prerequisites ---\\\n",
    "if 'client' not in locals() or client is None:\n",
    "    raise RuntimeError(\"Binance client not initialized.\")\n",
    "if 'format_price_correctly' not in locals() or 'adjust_quantity_to_step' not in locals():\n",
    "    raise RuntimeError(\"Formatting helper functions (format_price_correctly, adjust_quantity_to_step) not defined in Cell 1.\")\n",
    "# Use the trades that passed the FINAL feasibility check in Cell 21\n",
    "if 'final_trades_to_format_df' not in locals():\n",
    "    print(\"⚠️ Filtered trades ('final_trades_to_format_df') not found. Cannot format.\")\n",
    "    final_executable_orders = [] # Output list\n",
    "    formatting_errors = 0 # <<< INITIALIZE HERE\n",
    "elif final_trades_to_format_df.empty:\n",
    "    print(\"ℹ️ Filtered trades list ('final_trades_to_format_df') is empty. No orders to format.\")\n",
    "    final_executable_orders = [] # Output list\n",
    "    formatting_errors = 0 # <<< INITIALIZE HERE\n",
    "else:\n",
    "    print(\"\\n--- Formatting Final Executable Orders ---\")\n",
    "    print(f\"Strategy: Place BUY at BID, SELL at ASK (with final price check/adjustment).\")\n",
    "\n",
    "    # --- Get Exchange Info (Once per run) ---\n",
    "    print(\"Fetching exchange information for formatting rules...\")\n",
    "    symbols_info = None\n",
    "    try:\n",
    "        # Consider caching this if running in a loop later\n",
    "        exchange_info = client.get_exchange_info()\n",
    "        symbols_info = {item['symbol']: item for item in exchange_info['symbols']}\n",
    "        print(\"✅ Exchange information received.\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error fetching exchange info: {e}. Formatting may be inaccurate or fail.\")\n",
    "        # Decide if we should stop or try to continue without rules\n",
    "        # For safety, let's stop if we can't get rules.\n",
    "        raise RuntimeError(f\"Failed to fetch exchange info: {e}\")\n",
    "\n",
    "    # Initialize list and error counter INSIDE the else block where processing happens\n",
    "    final_executable_orders = [] # List for final API order parameters\n",
    "    formatting_errors = 0\n",
    "\n",
    "    # Iterate through the FEASIBLE trades from Cell 21\n",
    "    for index, trade in final_trades_to_format_df.iterrows():\n",
    "        asset = trade['Asset']\n",
    "        action = trade['Action'] # BUY or SELL\n",
    "        symbol = f\"{asset}{QUOTE_ASSET}\" if asset != QUOTE_ASSET else None # Determine symbol\n",
    "\n",
    "        # Skip if USDT (no pair to trade) or if somehow action is invalid\n",
    "        if asset == QUOTE_ASSET or action not in ORDER_PLACEMENT_STRATEGY:\n",
    "             print(f\"  Skipping trade for {asset} (Quote asset or invalid action '{action}').\")\n",
    "             continue\n",
    "\n",
    "        print(f\"\\nProcessing {action} {asset} (Symbol: {symbol})\")\n",
    "\n",
    "        # --- Get Formatting Rules ---\n",
    "        if symbols_info is None or symbol not in symbols_info:\n",
    "            print(f\"  ⚠️ Rules not found for {symbol}. Skipping formatting for this trade.\")\n",
    "            formatting_errors += 1\n",
    "            continue\n",
    "        symbol_info = symbols_info[symbol]\n",
    "        filters = {f['filterType']: f for f in symbol_info['filters']}\n",
    "        price_filter = filters.get('PRICE_FILTER', {})\n",
    "        lot_size_filter = filters.get('LOT_SIZE', {})\n",
    "        # Handle both NOTIONAL and MIN_NOTIONAL filter types\n",
    "        notional_filter = filters.get('NOTIONAL', filters.get('MIN_NOTIONAL', {}))\n",
    "        tick_size = price_filter.get('tickSize')\n",
    "        step_size = lot_size_filter.get('stepSize')\n",
    "        min_notional_str = notional_filter.get('minNotional', '0.0') # Default to 0 if missing\n",
    "\n",
    "        if not tick_size or not step_size:\n",
    "            print(f\"  ⚠️ Missing PRICE_FILTER(tickSize) or LOT_SIZE(stepSize) for {symbol}. Skipping.\")\n",
    "            formatting_errors += 1\n",
    "            continue\n",
    "        try:\n",
    "            min_notional = Decimal(min_notional_str)\n",
    "        except InvalidOperation:\n",
    "             print(f\"  ⚠️ Invalid minNotional value '{min_notional_str}' for {symbol}. Skipping.\")\n",
    "             formatting_errors += 1\n",
    "             continue\n",
    "\n",
    "        # --- Get Data from DataFrame ---\n",
    "        try:\n",
    "            # Use the quantity calculated in Cell 16, stored in final_trades_to_format_df\n",
    "            ideal_quantity_dec = Decimal(str(trade['IdealQuantity']))\n",
    "            # Use the price from Cell 16 as an initial reference if needed, but we'll fetch live price\n",
    "            # reference_price_dec = Decimal(str(trade['CalcPrice'])) # Optional: use for comparison\n",
    "        except (ValueError, TypeError, InvalidOperation) as dec_err:\n",
    "             print(f\"  Error converting trade data for {symbol} to Decimal: {dec_err}. Skipping.\")\n",
    "             formatting_errors += 1\n",
    "             continue\n",
    "\n",
    "        if ideal_quantity_dec <= 0:\n",
    "             print(f\"  Skipping {action} {asset}: Ideal quantity is zero or negative.\")\n",
    "             continue\n",
    "\n",
    "        # --- Fetch Live Order Book Price (Best Bid/Ask) ---\n",
    "        live_price_to_use = None\n",
    "        try:\n",
    "            depth = client.get_order_book(symbol=symbol, limit=5) # Get top 5 levels\n",
    "            if action == 'BUY' and depth['bids']:\n",
    "                live_price_to_use = Decimal(depth['bids'][0][0]) # Best bid\n",
    "                print(f\"  Live Best Bid: {live_price_to_use}\")\n",
    "            elif action == 'SELL' and depth['asks']:\n",
    "                live_price_to_use = Decimal(depth['asks'][0][0]) # Best ask\n",
    "                print(f\"  Live Best Ask: {live_price_to_use}\")\n",
    "            else:\n",
    "                print(f\"  ⚠️ Could not get live {'bid' if action == 'BUY' else 'ask'} price for {symbol}. Trying ticker...\")\n",
    "                # Fallback to ticker if depth fails\n",
    "                ticker = client.get_symbol_ticker(symbol=symbol)\n",
    "                live_price_to_use = Decimal(ticker['price'])\n",
    "                print(f\"  Using Ticker Price as fallback: {live_price_to_use}\")\n",
    "\n",
    "            if live_price_to_use is None or live_price_to_use <= 0:\n",
    "                 raise ValueError(\"Live price is invalid\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"  ❌ Error fetching live price for {symbol}: {e}. Skipping.\")\n",
    "            formatting_errors += 1\n",
    "            continue\n",
    "\n",
    "        # --- Format Price and Quantity ---\n",
    "        try:\n",
    "            # Format the LIVE price according to tickSize\n",
    "            adjusted_price_str = format_price_correctly(live_price_to_use, tick_size)\n",
    "            adjusted_price_dec = Decimal(adjusted_price_str) # Decimal version for calculations\n",
    "\n",
    "            # Adjust the IDEAL quantity based on step_size\n",
    "            adjusted_quantity_str = adjust_quantity_to_step(ideal_quantity_dec, step_size)\n",
    "            adjusted_quantity_dec = Decimal(adjusted_quantity_str) # Decimal version\n",
    "\n",
    "            print(f\"  Formatted Price Str: {adjusted_price_str} (Based on live {ORDER_PLACEMENT_STRATEGY[action]})\")\n",
    "            print(f\"  Adjusted Quantity Str: {adjusted_quantity_str}\")\n",
    "\n",
    "        except Exception as fmt_err:\n",
    "            print(f\"  ❌ Formatting error (Price/Qty): {fmt_err}. Skipping.\")\n",
    "            formatting_errors += 1\n",
    "            continue\n",
    "\n",
    "        # --- Final Checks: Quantity > 0 and Min Notional ---\n",
    "        if adjusted_quantity_dec <= 0:\n",
    "            print(f\"  ⚠️ Adjusted quantity is zero or less ({adjusted_quantity_str}). Skipping.\")\n",
    "            continue # Skip if quantity becomes zero after adjustment\n",
    "\n",
    "        order_value_final = adjusted_quantity_dec * adjusted_price_dec\n",
    "        if min_notional > 0 and order_value_final < min_notional:\n",
    "             print(f\"  ⚠️ Final order value ({order_value_final:.8f}) is less than min notional ({min_notional:.8f}). Skipping.\")\n",
    "             # Optional: Could try adjusting quantity upwards slightly to meet min notional,\n",
    "             # but this adds complexity. Skipping is safer for now.\n",
    "             continue\n",
    "\n",
    "        print(f\"  ✅ Final order meets min notional ({order_value_final:.8f} >= {min_notional:.8f}).\")\n",
    "\n",
    "        # --- Add Validated Order Parameters to List ---\n",
    "        final_executable_orders.append({\n",
    "            'symbol': symbol,\n",
    "            'side': action.upper(), # Ensure uppercase ('BUY' or 'SELL')\n",
    "            'type': 'LIMIT',\n",
    "            'timeInForce': 'GTC', # Good Till Cancelled\n",
    "            'quantity': adjusted_quantity_str, # Use FORMATTED STRING\n",
    "            'price': adjusted_price_str       # Use FORMATTED STRING\n",
    "        })\n",
    "        print(f\"  ✅ Added valid LIMIT order parameters for {symbol} to final execution list.\")\n",
    "\n",
    "        # Optional small delay between processing symbols if hitting rate limits during formatting\n",
    "        # time.sleep(0.1)\n",
    "\n",
    "\n",
    "# --- Final Display ---\n",
    "print(\"\\n--- Final Orders Ready for Confirmation ---\")\n",
    "# formatting_errors is guaranteed to exist here because it's initialized in both branches of the initial if/else\n",
    "if not final_executable_orders:\n",
    "    if formatting_errors > 0:\n",
    "         print(f\"No orders ready due to {formatting_errors} formatting error(s).\")\n",
    "    else:\n",
    "         print(\"No feasible trades required formatting.\") # Message when final_trades_to_format_df was empty\n",
    "else:\n",
    "    executable_orders_df = pd.DataFrame(final_executable_orders)\n",
    "    print(executable_orders_df[['symbol', 'side', 'type', 'quantity', 'price']])\n",
    "    print(f\"\\nStored {len(final_executable_orders)} order parameter set(s) in 'final_executable_orders'.\")\n",
    "\n",
    "# Always print formatting error summary if any occurred\n",
    "if formatting_errors > 0:\n",
    "     print(f\"⚠️ Encountered {formatting_errors} error(s) during formatting.\")\n",
    "\n",
    "\n",
    "# Ensure the list exists even if empty\n",
    "if 'final_executable_orders' not in locals():\n",
    "     final_executable_orders = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a708f1df-f6f5-45ba-b214-b44ca46bb67c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ℹ️ 'final_executable_orders' is empty. Nothing to execute.\n",
      "\n",
      "Skipping confirmation and execution steps as no orders are ready or prerequisites missing.\n",
      "\n",
      "✅ Confirmation step complete. Ready to proceed to execution module? False\n"
     ]
    }
   ],
   "source": [
    "# Cell 23: Final LLM Check & User Confirmation\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "import time\n",
    "from decimal import Decimal\n",
    "try:\n",
    "    import google.generativeai as genai\n",
    "    # Check if it was configured earlier, assume False if variable doesn't exist\n",
    "    if 'genai_configured' not in locals(): genai_configured = False\n",
    "except ImportError:\n",
    "    print(\"Warning: google.generativeai not found.\")\n",
    "    genai = None\n",
    "    genai_configured = False # Ensure flag is False if import fails\n",
    "from dotenv import load_dotenv # Usually good practice to load_dotenv again just in case\n",
    "\n",
    "# --- Configuration ---\\\n",
    "# EXECUTE_REAL_ORDERS_FLAG is determined by user input later if REQUIRE_CONFIRMATION is True\n",
    "REQUIRE_CONFIRMATION = True # Set to False only for fully automated testing (Use Caution!)\n",
    "PERFORM_LLM_FINAL_CHECK = False # Keep OFF for now - reliability issues previously noted\n",
    "LLM_MODEL_NAME_FINAL_CHECK = \"gemini-1.5-flash-latest\"\n",
    "QUOTE_ASSET = 'USDT'\n",
    "RSI_PERIOD = 14 # Used if pulling TA data for LLM prompt\n",
    "DEFAULT_LLM_REC = \"APPROVE\" # Default if check skipped/fails/disabled\n",
    "\n",
    "# --- Initialize flags ---\\\n",
    "proceed_user_confirmation = False # Final user decision flag\n",
    "llm_final_recommendation = DEFAULT_LLM_REC # Default recommendation\n",
    "llm_final_rationale = \"LLM check skipped or default.\" # Default rationale\n",
    "\n",
    "# --- Check Prerequisites --- #\n",
    "execution_possible = False # Can we even execute anything?\n",
    "llm_check_possible = PERFORM_LLM_FINAL_CHECK # Should we try the LLM check?\n",
    "\n",
    "# Basic check for executable orders list\n",
    "if 'final_executable_orders' not in locals():\n",
    "    print(\"⚠️ 'final_executable_orders' list not found (Cell 22 likely failed or skipped).\")\n",
    "elif not isinstance(final_executable_orders, list):\n",
    "     print(\"⚠️ 'final_executable_orders' is not a list.\")\n",
    "elif not final_executable_orders:\n",
    "    print(\"ℹ️ 'final_executable_orders' is empty. Nothing to execute.\")\n",
    "else:\n",
    "    # Only possible to execute if the list exists, is a list, and is not empty\n",
    "    execution_possible = True\n",
    "\n",
    "# Check LLM prerequisites only if enabled AND execution is possible\n",
    "if not execution_possible:\n",
    "    llm_check_possible = False # No point checking if we can't execute\n",
    "elif PERFORM_LLM_FINAL_CHECK and not genai_configured:\n",
    "     print(\"⚠️ LLM not configured. Disabling final LLM check.\")\n",
    "     llm_check_possible = False\n",
    "elif PERFORM_LLM_FINAL_CHECK and 'full_market_state' not in locals():\n",
    "     print(\"⚠️ Market state ('full_market_state') not found. Disabling final LLM check.\")\n",
    "     llm_check_possible = False\n",
    "elif PERFORM_LLM_FINAL_CHECK and 'news_summary' not in locals():\n",
    "     print(\"⚠️ News summary ('news_summary') not found. Disabling final LLM check.\")\n",
    "     llm_check_possible = False\n",
    "# --- END Check Prerequisites --- #\n",
    "\n",
    "# --- Main Logic ---\n",
    "if not execution_possible:\n",
    "     print(\"\\nSkipping confirmation and execution steps as no orders are ready or prerequisites missing.\")\n",
    "else:\n",
    "    # --- Display Orders First ---\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\" !!! FINAL CONFIRMATION BEFORE LIVE EXECUTION !!!\")\n",
    "    print(\"=\"*60)\n",
    "    print(\"The following order(s) will be placed if confirmed:\")\n",
    "    try:\n",
    "        orders_to_exec_df = pd.DataFrame(final_executable_orders)\n",
    "        # Select columns that definitely exist based on Cell 22's output format\n",
    "        display_cols = ['symbol', 'side', 'type', 'quantity', 'price']\n",
    "        print(orders_to_exec_df[display_cols])\n",
    "        print(f\"\\nTotal order(s) to execute: {len(orders_to_exec_df)}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error previewing orders: {e}\\nRaw list:\\n{final_executable_orders}\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    # --- Perform Final LLM Sanity Check (if possible) ---\n",
    "    if llm_check_possible:\n",
    "        print(\"\\n--- Performing Final LLM Sanity Check ---\")\n",
    "        try:\n",
    "            # Prepare Context (Simplified)\n",
    "            orders_str_list = []\n",
    "            symbols_involved = set()\n",
    "            for order in final_executable_orders:\n",
    "                orders_str_list.append(f\"- {order['side']} {order['quantity']} {order['symbol']} @ {order['price']}\")\n",
    "                symbols_involved.add(order['symbol'])\n",
    "            orders_for_prompt = \"\\n\".join(orders_str_list)\n",
    "\n",
    "            # Simplified TA Summary for prompt\n",
    "            ta_summary_parts = []\n",
    "            for sym in symbols_involved:\n",
    "                 state = full_market_state.get(sym)\n",
    "                 if state and not state.get('error'):\n",
    "                     # Example: Just include RSI if available\n",
    "                     rsi_val = state.get(f'last_{PRICE_SOURCE_INTERVAL}_rsi') # Assuming PRICE_SOURCE_INTERVAL matches TA interval needed\n",
    "                     rsi_str = f\"RSI {rsi_val:.1f}\" if rsi_val is not None else \"RSI N/A\"\n",
    "                     ta_summary_parts.append(f\"{sym}: {rsi_str}\")\n",
    "                 else: ta_summary_parts.append(f\"{sym}: TA N/A\")\n",
    "            ta_summary_for_prompt = \"; \".join(ta_summary_parts) if ta_summary_parts else \"N/A\"\n",
    "\n",
    "            news_context_summary = news_summary.get('summary', 'N/A')\n",
    "\n",
    "            # Construct Simplified Final Check Prompt (\"Approve/Reject Batch?\")\n",
    "            final_check_prompt = f\"\"\"\n",
    "            Reviewing a batch of automated cryptocurrency trades before execution.\n",
    "\n",
    "            Strategy: Long-term rebalancing towards target allocations, aiming for maker fees.\n",
    "            News Context: {news_context_summary}\n",
    "            TA Snippet: {ta_summary_for_prompt}\n",
    "\n",
    "            Proposed Orders:\n",
    "            {orders_for_prompt}\n",
    "\n",
    "            Task: Based ONLY on the information provided, do you see any glaring contradictions or red flags that warrant halting this specific batch? Respond ONLY with:\n",
    "            **APPROVE EXECUTION**\n",
    "            OR\n",
    "            **REJECT EXECUTION**\n",
    "            Optionally add a brief comment AFTER the keyword line.\n",
    "            \"\"\"\n",
    "\n",
    "            # Call LLM\n",
    "            load_dotenv() # Ensure API key is loaded\n",
    "            model = genai.GenerativeModel(LLM_MODEL_NAME_FINAL_CHECK)\n",
    "            safety_settings=[{\"category\": c, \"threshold\": \"BLOCK_NONE\"} for c in [\"HARM_CATEGORY_HARASSMENT\", \"HARM_CATEGORY_HATE_SPEECH\", \"HARM_CATEGORY_SEXUALLY_EXPLICIT\", \"HARM_CATEGORY_DANGEROUS_CONTENT\"]]\n",
    "            print(\"Sending simplified final check request to LLM...\")\n",
    "            response = model.generate_content(final_check_prompt, safety_settings=safety_settings)\n",
    "\n",
    "            if not response.candidates or (response.prompt_feedback and response.prompt_feedback.block_reason):\n",
    "                 reason = response.prompt_feedback.block_reason if response.prompt_feedback else \"Unknown\"\n",
    "                 print(f\"LLM Final Check BLOCKED: {reason}\")\n",
    "                 llm_final_recommendation = \"REJECT\"\n",
    "                 llm_final_rationale = f\"LLM Response Blocked: {reason}\"\n",
    "            else:\n",
    "                 raw_text = response.text.strip()\n",
    "                 print(f\"LLM Final Check Response:\\n---\\n{raw_text}\\n---\")\n",
    "                 llm_final_rationale = raw_text\n",
    "                 # Check first line primarily for the keyword\n",
    "                 first_line_upper = raw_text.split('\\n')[0].upper().strip()\n",
    "                 if \"**REJECT EXECUTION**\" in first_line_upper:\n",
    "                     llm_final_recommendation = \"REJECT\"\n",
    "                     print(\"LLM signaled REJECT.\")\n",
    "                 elif \"**APPROVE EXECUTION**\" in first_line_upper:\n",
    "                     llm_final_recommendation = \"APPROVE\"\n",
    "                     print(\"LLM signaled APPROVE.\")\n",
    "                 else:\n",
    "                      # If keyword not clear in first line, default to REJECT for safety\n",
    "                      llm_final_recommendation = \"REJECT\"\n",
    "                      llm_final_rationale += \" (Keyword unclear)\"\n",
    "                      print(\"⚠️ LLM recommendation keyword unclear, defaulting to REJECT.\")\n",
    "\n",
    "        except Exception as llm_err:\n",
    "            print(f\"❌ Error during LLM final check: {llm_err}\")\n",
    "            llm_final_recommendation = \"REJECT\" # Default to REJECT on error\n",
    "            llm_final_rationale = f\"LLM API Error: {llm_err}\"\n",
    "\n",
    "        print(\"-\" * 30); print(f\"LLM FINAL RECOMMENDATION: {llm_final_recommendation}\"); print(\"-\" * 30)\n",
    "    # Handle cases where check was disabled or skipped\n",
    "    elif PERFORM_LLM_FINAL_CHECK: # Check was enabled but skipped due to other prereqs\n",
    "        print(\"\\n--- Skipping Final LLM Sanity Check (Prerequisites Missing) ---\")\n",
    "        llm_final_recommendation = DEFAULT_LLM_REC # Use default\n",
    "        llm_final_rationale = \"LLM check skipped due to missing prerequisites.\"\n",
    "    else: # Check was disabled via config\n",
    "        print(\"\\n--- Skipping Final LLM Sanity Check (Setting: OFF) ---\")\n",
    "        llm_final_recommendation = DEFAULT_LLM_REC # Use default\n",
    "        llm_final_rationale = \"LLM check disabled by configuration.\"\n",
    "\n",
    "\n",
    "    # --- Get User Confirmation ---\n",
    "    if REQUIRE_CONFIRMATION:\n",
    "        print(\"\\nDecision Point: Review the prepared order(s) and LLM recommendation above.\")\n",
    "        try:\n",
    "            # Loop until valid input or EOF\n",
    "            while True:\n",
    "                prompt_msg = f\">>> Type 'yes' to EXECUTE, 'no' to CANCEL (LLM: {llm_final_recommendation}): \"\n",
    "                confirm = input(prompt_msg).lower().strip()\n",
    "                if confirm == 'yes':\n",
    "                    proceed_user_confirmation = True\n",
    "                    print(\"\\nUser confirmed execution...\")\n",
    "                    break\n",
    "                elif confirm == 'no':\n",
    "                    proceed_user_confirmation = False\n",
    "                    print(\"\\nUser cancelled execution.\")\n",
    "                    break\n",
    "                else:\n",
    "                    print(\"  Invalid input. Please type 'yes' or 'no'.\")\n",
    "        except EOFError:\n",
    "            # If input stream is closed (e.g., running non-interactively)\n",
    "            print(\"\\nCould not get user confirmation (EOFError). EXECUTION CANCELLED.\")\n",
    "            proceed_user_confirmation = False\n",
    "    else: # Confirmation not required\n",
    "        print(\"\\nSkipping user confirmation step (REQUIRE_CONFIRMATION = False).\")\n",
    "        # Automatically proceed unless LLM rejected (and LLM check was performed)\n",
    "        if llm_check_possible and llm_final_recommendation == \"REJECT\":\n",
    "             print(\"EXECUTION HALTED: LLM recommended REJECT (and user confirmation was skipped).\")\n",
    "             proceed_user_confirmation = False\n",
    "        else:\n",
    "             print(\"Auto-proceeding with execution (or lack thereof if no orders).\")\n",
    "             proceed_user_confirmation = True\n",
    "\n",
    "\n",
    "# --- Final Status ---\n",
    "# This flag now reflects the final decision based on order existence, LLM check (if applicable), and user input (if applicable).\n",
    "print(f\"\\n✅ Confirmation step complete. Ready to proceed to execution module? {proceed_user_confirmation}\")\n",
    "\n",
    "# Ensure flags exist globally\n",
    "if 'proceed_user_confirmation' not in locals(): proceed_user_confirmation = False\n",
    "if 'llm_final_recommendation' not in locals(): llm_final_recommendation = \"SKIP\"\n",
    "if 'llm_final_rationale' not in locals(): llm_final_rationale = \"Not generated.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545a1dd2-5042-407f-8342-6b9db8c0683f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
